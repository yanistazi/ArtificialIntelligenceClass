{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Configuring and Training a Multi-layer Perceptron (MLP) in SciKit-Learn\n",
    "\n",
    "**(Notebook prepared by Pr Fabien MOUTARDE, Center for Robotics, MINES ParisTech, PSL Universit√© Paris)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understand and experiment on a VERY simple classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 0\n 0 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1\n 0 1 1 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 0\n 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0\n 0 1 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0\n 0 1 1 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0\n 0 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1\n 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1\n 0 1 1 1 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1\n 0 0 1 0 1 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 0 1 0 1\n 0 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0\n 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 0 0 0 1 0 0\n 0 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 1 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0\n 1 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 0\n 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1\n 1 0 1 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 1\n 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 0 0 1 0\n 0 0 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0\n 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1\n 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0\n 1 1 0 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0 0 1\n 0 1 1 0 1 0 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0\n 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1\n 1 1 0 0 0 0 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1\n 1 0 1 0 0 1 1 1 0 1 1 1]\nNumber of training examples =  270\n\n  first  27 training examples\n[  Input_features  ]     [Target_output]\n[ 1.28460718 -0.94952062] [0. 1.]\n[ 0.79893755 -0.25743179] [1. 0.]\n[-0.20164508  0.61937754] [0. 1.]\n[ 0.68945236 -1.58819417] [0. 1.]\n[-1.35705254  0.94773838] [1. 0.]\n[-1.02916225  1.37715034] [1. 0.]\n[-0.66837735  1.30693253] [1. 0.]\n[-0.34198002  0.36359111] [0. 1.]\n[1.76275104 0.23248687] [0. 1.]\n[ 1.52394734 -0.91758401] [0. 1.]\n[-1.64655821 -0.92233374] [1. 0.]\n[-0.96352511  1.4772172 ] [1. 0.]\n[-1.39279076  0.98035204] [1. 0.]\n[-1.53763501  0.23782849] [1. 0.]\n[-0.26338189 -0.12683968] [0. 1.]\n[-0.21140754  1.41593419] [1. 0.]\n[-1.19609512  0.88969891] [1. 0.]\n[ 0.34879117 -0.90097132] [1. 0.]\n[-0.33478178 -0.192839  ] [0. 1.]\n[ 1.44378714 -0.90324487] [0. 1.]\n[-0.02145466 -1.02559593] [0. 1.]\n[-0.49510682 -0.21244696] [0. 1.]\n[0.23507857 1.06121335] [1. 0.]\n[-1.36997478  1.21173125] [1. 0.]\n[ 1.58519866 -0.88353215] [0. 1.]\n[-0.37792244 -0.74786555] [0. 1.]\n[ 0.17568441 -0.89820239] [0. 1.]\n\nPLOT OF TRAINING EXAMPLES AND TEST DATASET\nDatasets: circles=training, light-crosses=test [and red=class_1, blue=class_2]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXlYXdW5/98zH+YhjCEhBDJA5oEMkEmr1jF1qEOtvY71au1gW6tt7XT1drDe2tvB1l8HW23r1FpnY681RmMSCAESEpJAICRAmAkQxjOf3x+fLPfhnEMCGdHs7/PwAGfYe+219/qud33XOxj8fr/o0KFDh46zD+PZboAOHTp06AA6IevQoUPHOIFOyDp06NAxTqATsg4dOnSME+iErEOHDh3jBDoh69ChQ8c4gU7IOnTo0DFOoBOyDh06dIwT6ISsQ4cOHeME5rF8OCkpyZ+VlXWamqJDhw4dH0+UlZV1+v3+5ON9bkyEnJWVJaWlpSfeKh06dOg4B2EwGOpH8zldstChQ4eOcQKdkHXo0KFjnEAnZB06dOgYJ9AJWYcOHTrGCXRC1qFDh45xAp2QdejQoWOcQCdkHTp06Bgn0AlZhw4dOsYJdELWoUOHjnECnZB16NChY5xAJ2QdOnToGCfQCVmHDh06xgl0QtahQ4eOcQKdkHXo0KFjnEAnZB2gslJk717tf79fZMcOkZqas9cmHTrOMeiErAP4/SK1tZCy3y9SUSHS2MjfOnToOCMYU4J6HR9jzJnD79pafkREZs4UmTHj7LVJh45zDLqFrAMYDBopK+hkrEPHGYVOyDqAkikCEagpny7s3StyySUiEREiycki//VfIm536Oc8HpGhoeGvud0iDsfpb6MOHWcIumShY7hmPHOmyPTpbPIp6SIv7/Sc99AhkeXLRfr6aIPDIfLooyL79ok8++zwz5aXi/T2ihQWikRGQsZFRXxv9WosfB06PuLQLWQdkJnNpmnGSr7IyuL1Uwm3W6Slhb9/+UtIOHDjcGhI5OWXRQ4eFPnVr0RycrCcf/5zvrdli8iRI5BxXx+ThU7GOj4m0C1kHSDYCjYYRObOPfXn2bdPpK5OZP58kZISEZcr9DM2m8jdd4t88IHI4CCvvfiiyL//DYlv3Mhry5aJpKSc+jbq0HGWoFvIOs4s8vIg0YoKkcmTRUym0M84nSIbNmhkLCLi9YoMDIisW6e9Fh19+turQ8cZhE7IOs4sjEaRJUtE4uLQfi2W4e/b7cglERGh33U6RfbsEcnN5XtbtgwnbR06PuLQCVnHmYfLhZacni7ywx9CwEYjZHzrrSK/+114TwujUWThQjYdCwrwvCgp0YNXdHxsoGvIOs4sHA425JxOPCxSUthIzMsTyc6GdEUg3m3bhmvMNpvIt7/N33FxkLLXq2/q6fjYQLeQTzcOHw71le3oCL+ZdS6grg5PimXL8J5YsgRSrq2FXBXeeEPkiitErFaIODtb5M03hwerxMWJJCae+WvQoeM0QbeQTye8XpGyMhGzGf9Zu12ktVWktJQNrfnzz3YLzzzy8kQmTRKJjeV/pSkPDg7Xk+PjRf75T5H+ft5LTtYtYR0fe+gW8umEyQTZOJ1sQB08CBnHx4vMnn22WxceDQ0iPT3DXztwAJ/fUwGDQSNjBaNxZI+J6GgsaJ2MdZwD0An5dCMhAa10YEBk1y6s5OXLsZrHG7xe0m0WF2ukXFtL1F59/dltmw4d5wB0Qj4TcDq1v30+vAPGI0wmpBWLBVIuKyPXREbG+LXodej4GEEn5NMNpRkrS9nrRb4Yr0lxIiIgZbdbpLlZJCoKjwddMtCh47RDJ+RTjZ4ekR//WGTFCpFrrxV57jk04+XL2ZhavhyLubr6bLd0ZDQ1aX87neSO0KFDx2nHOBQyP0Lo6tJCeS+7DCty0SKsYoeD/9etIzHOypV8LiEBso6KOnvtPhZU1ZCMDCLiioqQL5YvZ2IZrzhyBClowgTtta4uNgzHc7t16AiAbiGfKJ55BtL6whf4ycgQufNOjYxFiCAbGhK5//7huXxjY8PncDjb8HpJwZmRgUwRGckE09vL6+MZlZUiW7fi9y0CGRcX87oOHR8R6IR8Ijh0SOTzn4d4+/v5cThEXnopvDZsNFIwdLzDZMJ6nztXZPduka98BXK++WbyTvzwh+HDlAcHIcPAzcv+fsKaw4VAHwt+P54egcfy+8kSd6xj5eejf2/dqnmK2O28fiLw+9mADURnp8jzz5MedGDgxI6rQ8cxoBPyieDFF8eWPyF4KT1e0NSEVVxfr0XJtbeLtLWJ3HsvOSWGhiDHnh4I+fnnQ4/jcGCZbtnCZ/v7+bunZzixjgb9/RCqCq/2+0W2b0dzb2sb+Xs2G5uRXq9IVRW/VTDOiWDHDiYURcpPPsnkdMcd5NtISyMdqA4dpxC6hnwicDiGh/kqGAz4FwdaciYTWuzprE/n8YT6NYd7LRBHjkB0NhsWblMTQRgHD/L+xo2h7nlOp8jPfiZy443DX09MJBR661aRt9/mNZuNXBNjTZEZEyOydClkuGULVm9bGwQ4aZL2Oa8XWSI5WXst2GodGDhxQp4wgRShJSWEaH/xi4S7B4a8X301nijBgS46dJwgdAv5RLB2bWjaSBFI6N57IZG4ODTYzEyi3KxWkalTRf7yl1PbFpcL8qyp0V4bHBR5772RgzmcTkoipabyt8EAmT7+OBp4dbWW5CcYDQ3hX58wYbiv8qJFkOuJICmJCMf+fvJ+WK1Y7up6vF4SD5WUaNq80oyjopBXoqOHa8pjRWYmoe0dHSIPPRReLjEYRF599cSOr0NHGOiEfCKYPVvkS1+CcI1GfiIjee1//odSQy+/LPLYYxBcTQ0D+uBBNgB///tT0w6/n+CNt94S+dOf0H0HB7EsXa7QoqA+Hxad2cyk0doKKbtcvG40QmhxceEnHBGIMhz6+4e78u3aFV6u8PuRA1pbh7errEwr7eT3a5uIHg8TXUKCyM6dJCfatg2inDdPy5tcVYU1XFhI+wsLea+q6vj9OBKURT40FKonq3brWrKOUwiDfwxaaH5+vr+0tPQ0NucjhuJirRjnZz+La1ggFiwIreQswjK7re3kgi1cLiz1zZshe7MZS/KRR0SmTCF5UV2dyLRpJPTx+bAoOzpE1qyBeLdtw1JubsaSTE+H5KKi0I9ffXW4bGG1QvaLFw9vi9KMRZApXC6sUxVkEliXz+NBHz5yhA23lBQCZ/bv53uf/CTE3NTEe0pCSU5G/unt1fp28mTtuG43lnOgRKGsf6t17P2rJonWVnJ5PPBA6ARjt0P4U6aM/fg6zikYDIYyv99/3B1mXUM+GSxfHkrCgQiUEQLR3Y0lezK+yL/4BTXnlBXscnHM++8X+fWvRS6+GIKqreW9vXshyIUL0TxdLqzQpibIJyMD2cFohKAXLxaZOJE0mIcPs3y//nqSwwfD48Gizs/XZIply7CSg7V2s5k+Ky5mQlDIz2eS2rSJtk2bhldDejrnLC2lnUpKCbZYLZbhVr3LhcwRqDGPBeXlkPHcuaQBffddkX/9SyP5iAhIWidjHacQuoV8OjF7NiWHgpGYCNmcjIU8Y8bIhG82a1U4srIgwN5eSG/tWgj0zTdx05s5E3JLTub9Q4cg523bmDBUvuFVq5BlRqpC7feHXk+41xScTm0DUEUwut1Y1m1tWLUqCb3RCFH39mLBt7XxM29eKCH6/QTiPPSQNhl88YsiP/nJ2Hy/m5sh9aws7bh//SsTVEICnhYFBaM/no5zGrqFPB7wox+J3HTT8LpvkZEi3/veyeeGOFaCIo9H83uuqCBa8P77sYY3b6Y9e/aIfOITIldeqfn+lpayDPd4RP72N0hv5kyIz2jER3kkQg68HrcbD47cXM0DweXiNVUvT0k5TU3osFlZeFJMnIhl7ffThhtv5POXXSbyjW+w2TZ5Mm2trETWCKy/9/TTIt///vA+/81v+MxDD42+fydODL2+m2/mR4eO0wTdQj7deP55kW9+E++E5GTI4otfPHlC/u53cUEbrZ/vggUid9+N1ZiRgRdCfj7a7cAAm3Vbt+Kd8d//rVmXRiPW6s9/jvY8a1bosQOlBBHI8IMP+LugAJIvKkJrXrIEXbiyElLduxcrfO1avCveegvS/8MfOI6SJiIi2BB97DHtnD09oRVDcnLQzoMRFYWFPZL3iA4dpxGjtZB1Qj5T8HpPbbh0Xx8W65494X2ig2E0QnIHDyKlZGVBju3tEGNcHP6/ubnaRlogli+HVAPh97NJuGsX7ytNvLkZCz0w2s1o5PiJiSJPPIH+6vViOdts/Nx8M5NDczOabbCrmd2uTWwjISJi5GjJ9vZjB+j4/bjPBX5mJOLXoWMMGC0h6+bCmcKpzl0RE4MXwA9+MLpk95GRLO9vvhmrtb0dnTglBUu5qwvrNBwZi/DZ5mbtf4dD5P33mRi6u0U2bNDItLycFUBgiaq8PIi0r0/k4YfZjFRBFk4nr+/YIXLDDWw2hvP7tdlwfTsWFiwI/3pa2vFJ9cABvEWUy53Px7Vs2aK7t+k4I9A15I8yLBb0aJMJfdRuhyjDFVD1eikUOm2a9tru3cgISUnkirDbkSfCfT82FnISgdhUmLTJBLlu3EjgRmYm/w8NYQlPnYqvc00N5+nqCp/O0++HbF0uyHPv3tDwdJdruKtbODz2mMiFFw73wbbbRX71q+PLRFOmMFEp6769HRe82bPHb3Y+HR8r6IT8ccBVV0EmR47gInbVVcM3tUSwOB9/XOQ736F46OCgyOWXoyWXlLDUr6/Hkt2zZ7iFqiIQExOxykU097WEBNziiorYqFOuatu3Y5VfdBFEvGULn5k+fWSJpbcXK31gAIkh8HMmE9F/xwtBLyzEe+OrX0UfT0tDw//0p5E7Xn+dtl91FRNFIFQNxJISbdNx9mwmMh06zgB0Qv44IC8Pa/XQIZbZ4Zb7Hg9BLE8+yf8+H1b1jTeSk+FTn8IanDCBjcjKSojY4YDsp06FDDdswDPivPMgYxEmAp8PQu3tZVNNeWVMnIglX1iI7JGQgF7d1RXaRqOR9nm9w8lYyR+//W3oBmIwnE6u9eGH0awbG+mXb3+bjUmDge9/7Wto6osXcy4V9q3eVxgpYlGHjtMAnZA/ShgcxOoM99qCBeiwTU0jZ6ILlgoUSX/qU0gN6eks09Xm2s9+BiHt24eHg7J4bTZ8mEUIALHZILWyMohWRc2VlyOBXH89S/41ayC82bM1L4xA+Hzh5ZLMTKzan/5U5IILRG65ZWRNvqGBPlm2jMklMRFr/ec/Dz32HXdAyvPm0Wd+P21ub2eS6+zU3AePJ5W0tQ23uJXkEWyFj0M0N9NNgUGOhw7RdH0+OrPQCfmjAlWbb9EizUd2/35Cd1eswKobHESCmDMnfJRcOLhckPLy5RBXQwNk/Je/aGHKIhxbJS3q7NSs8KIiRq3TGRo9t3MnARSVlVis3d1YyUuXEqk32lzJ9fX8lJQQzj1/fmj4tsL06UwsKstcQwMSRji/bZ+Pyeamm7SNRKUZZ2VB+n4/8kVi4sg6clsbbcvO5rt+P/1fX88GalLS6K7zLMDl4vLsds1Dsa6O7YXp03G60XHmoHtZjDccPkye3Z07h1u6SUmQgso9UVGBHpqSgtVZVMRGVnIylmRGBrrwaDww+vrIdfyvf+G9cdll4X15RSCsQCL1eEZOviPCe488wibd1q1MHBdfzGhX5tdo2qgwMBBagSUYgSk/MzMh0nCrBoMBjbmzk/7s6kJDzspicqqsRKpZuvTYm3qpqXxOMZki42nTxjUZi7CAWbqU7iwqYvtg927mtNOZMVZHeOiEPJ7w0ENkGLv2WsyVhQu1DGhmMyMnIUHktdewyPx+CLGxES8GrxfCWrWKbHO33nrsiD4R5Iblyzn+3LlYn3PmnFo3PaORaEGbjbYtWkSAzE03cY2ZmWM7XnHx6NfSRiNyS7gEQ34/pJmcjCnY0gKprlsHoc6eDWGnpBz/PHPmaKSsyDgvb2zXdZYwYQIKT38/i67ERG6RHkNz5qF3+ZnGSPruK6+QutPhQCoYHMRUueYa7TMqbWZzM1adCux49118aN1uLe3krFnHz71sMGCtGgwUYU1NxVoW4f9gUh6LJRsIr5dCo4sXswLw+bBi16zRstKNBXY7IudosWiRyHXXae1XGeDuu08L6e7uRrr5xCfwyPiP/6Bu4mgDp4JLPo20YhinCNxecDrDS/k6Tj90DflM4Y9/JIijpYUl8U9/Ckko/OIXocEHHg9L6fp6PB3272fTbuVKXn//fWSA//s/yDguDjK/6y6Rp546fjDDV7+KObRrF8dXnhB//rPI5z7H+To6IFSLBWvx8GEi10YLkwkL2OEQeecdyHDaNIJRfve7EytCetlloZubI0Gl0bz+ehLXr1vH9eTni1xyCVZ7dTXudi+/rDGRy0VCorg4agseC4Ga8bRpHF9NMoFJ+8cplNKSns6jWVKCfKE0ZR1nDjohnwk88QSJcZRv8IEDyAkWC/6wIli84WA2o21arQh8Eydi8c2ZI3LbbZCcssZ6evAXbm0lsdGxMH8+1qDy+a2r0yqFNDfjo1xXB1HV1fH5hARkhmBCNhoh9r4+yMnl4jWDgVH+gx/gBVJcDAHu20eSo61buT6DYfSWaGwsE8loZAQRNvVaW+mvtWvxrNi+He+JDz7gWmbOxDc72CwcGhL58Y+PT8iqmkmwTFFXx6pjHOvILhe3Iz1dkylUNa76erpGx5mDnstirKivx6rLyTn+FnRfH0vz1FQszWCoIAwRkQcfxDUrOFlQXBwD3myGyLOzIa/33sNSDJdcyGZjpI10b+PjOddnPoMVvns3kklXF25l8+dr19bYiFW/eDGbjZ/6VKh3hMmE/HDhhby3aBGa9uHDnGv6dKzr2lrINyOD83d0YJm/8EJoWw0Gkv5v2AChms2Q+sqVyCwrV47OSvb7mewC81/4fLTlySe1CMVwxVtVO0YjP3R0hObYCPfaOMTAACpXoGbc388+5snmwNIB9PSbpxoeD/6vL72kEV5BAW5Y4Qp5dnURnZaVNXJdtwMHtL+/8Q00y/Z2lvdGI0Tx299CRu++K7J+PTswc+dCJCNlejtWBrjsbJbvubkc/+23Re65B+I1GpE6vvxlfJD9fmSL8nI0VpcrtIirCEv0lhZt066kBGkgIwMf37lz2fCy25nQtm5ldZCXh6W7YIHmVaLIb9IkmGLlSqqIKNezoSEszzVr6IOEBEhPbXAGb/YZDBopquRCBgPSTlYWFnJjI+wTTuIJlBwcjtA1vHotHPF+BMhYJLwDyVhr0+o4NdAJebR45BE0RodDyya2eTOpNJ9+OvTzCQkQUl0dVmK4yDQVktvVBdlUVCBlvPGGlh2uuVnk0ksh9/5+SM/vZ9k+YUJ4so+OHp66UsFgYDPs17/Wcj7U1JBQKPCzjz8OmVxwAW2LiiJBfGNj+N0eg4G1bXw8m5C9vUwKVqvI3//O8SZPhpjffx9izM7Gm2T9epH//E/au369Vila+Vw1N+N/PXEiBN7Xx88vf8kqZeZMJIGdOyHXcJuRIhy3pITPGo34Dit5we/HUg9XTOCOO/jd3Y2wOnu2lhS/pYXJasmSY0soO3cyEQWXndKhIwi6l8Vo8ZvfhPq+Op0st0eqSLxgAZZecLJzESy5n/wEktu8GVJ86SUsVhXQ0ddH7okNGyBjdU6Xiwiz224LTRhvsYj87/+GunmZzRCRywU5ud0QYF1dKHG7XJD2hg1cw623ct76evyUg/2hbDb02WeeQR5QFrrLxeT14INY+Dt3sozPyYEYm5ooj6TKNF1yCbr2XXfRb7Nn048Gg8iddyJ7JCVpMkRXF8S+cydacWrqyO56UVFaFenWVv7v6+PziYm0IRx+8APue1wcE6Ai15YWNgvj40fOItfdjUthQQGbpDNmiNx+++gCdnSck9At5NFCEWIwVE7fcH6xBgMWaLhSSwYDy/u4OAb3rl0knQ8m/ZH8j9xuwpitVkoLtbUhC9x0E8fdtInBv2uXZjEHE8GxfJv8fizVgQEyuRmNEOn8+ZR/amzkms1mqmgXFpIfIpxu3dmJ7t7QANFOm8ZqYONG+nXiRK4nIkLzr776aojvmmsgzspKdpveew8SVoEv69dzjtGElSnrdMcOruv//o9rcTpHdrodGuIz116LJbxtm5YCNDGRNo3kDnjrrWwgBvbzCy8wyR1vo1DHOQmdkEeLCy8kICPYmszLGzmK6+BB5Ixwmq7VigfDZz+LC9Y772C5jRaKRFShVasVXbW6Gm116lQs5bIyLLs77xz9sVVmtcZGogEHBjjfJZcgC8TEIBXMnYu/s/KoiIgYHm4diNhYjudw4PR6ww1Y+V/7GsefM4cQcIsF4v7Tn7iuykoIeXBQ03o9HtrgdGoToap9dzyo1cyTT2rS0PE+v3EjhGw0MqG0t/NeWtrIZNzXR+Rj8KQ3OEgqUJ2QdYSBLlmMFj/7GdaskggsFsjh978P//nDh7FORyJrlVWspgZ3sKGhsVWlcLsht54e/Hy9XjTOmTMhqooKiO6mm3htpCV5Xt5w2cNkwqLOydGO39CAJZucrH2+qwvL1mjEqt2+HakheKVgNJIZ7tZbub7+fqSKH/1I5NFH6SeHA534979nIuntZVJZv57f3d14grS28l5sLNryG2/wXbMZjb2ri74MVzFERHO4VZPhaKWDqip+t7RwnXFxXMuePVjx4TA0NLKLggq+0aEjCDohjxY5OQzAb3yDza577mHpunx5+M9PmMDy/qtfDe+e5fFASPPm4UVwww1sSI02Gs5iwSKdOJGNuqlTIYGnnyZvhPIV7uuDwO6+e7iubDLRrhdewJ3tiivYrLr8ciIGzWaNqKOikAgSElj2z5rF+R0OyFi5t61cyfXYbHzfauWYTz3F5zIyIKn9+7GAg7V3hwNJYPZsZI2+PghdVftISGBiSUzEQk5OhqDnzMHqfvJJ2qJWJE4n98znYyJ44QWIe/36kYu1hoPRyCRSVkYbCgvRhVNSeAba2kK/k5zM9QbDbMZdUYeOMND9kE8FenrQWwNdorq6sDStVnLx/vKXWGRKq0xPZwkemGsiMhLd96WXWBZPnw6BBVfPMBohzn/8g7+LiyGmgQH8iZOTCQvu7sarobKSPBgibFI1N0OoFguE+e9/Q6gHDvDT24vlp6LzcnKwCuvq0FFdLnRYZQEuWMD3+vsh7L/+FbnGZtOCWJxO/o6IQKZ5++3w/r2ZmXi07N6t1bIzGrHMIyI0WaOtjQ2+khLa09fHOa65hraK0L87dtCOr34VS9/j4bxe7+j8i+12JrNLLoFgc3O1SVP5M+fkhN9MfO897pPLxXntdiaS8nKkDx3nDHQ/5DOFPXvwIMjNxUK029lQKy/HWly9Gm+KW25hiX3gAAR2772hiX8GB1m6//a3WHzTpmHdrloF2QwNQfA+HyT9X/9F5rPly9ErOzshmrQ0rNC4OPGXlonhcCdt2b1bpKtL/CJicLuxUPftI4T761/H2lu2DAu4rg7L2+PRogOTk7EKvV6tooYIRLV3LxPPrl1a9N3cuXhN1NaiwaemYqHOnk17w8FqxevE5+MYbjeTm9/P9zweVh+xsXx+/nys6pgYpBFFxiJMDm43ftf79o3du8FiYQMxK0tL0B8Io/HYKdHOO48J4Ve/QttfswZyP1ahVR3nNHRCPlmocCZFUAYDm0BRUSyfS0vZtMvNxdp77TVIayR9sbsb74nubvRKETTMp59m6V9bCynV1rJp9/zzLMVFIKCCAkht504ZjE6RbUNLZN51kyVh3jyRe+6RfodJSmWNLJJyiZU+LbH85s2a1djfj17r9zMZ9PVBpIWFfKakhPZPmMAk8MMfogmrDSwlRVRUsHH3859jiXd1QZ6TJmE1KzlBwWplcpkyBUvZ7WYSMZu1hELFxXwmNZUJLDAXxu7dEHKgbp+WRjvCkbHJdGyS/vSnuebzz0fr37GDv5OTw1cuCffa9Om4EOrQMQrohHwi8PuxdLOyWDZHRCAxvPQSpGu1soxNTmZpXVoKwZSVYVFNmIBfczjU1mL9rV6NG5zBwDluvhm5IVB3dTrZaPr977G4c3MhrE2bRDo6xGjrEe+EXCmOvlCWd4tYejyyRQpFRMQgQRJIaipSQmkpFv/06WjlubkQdHExS/6uLq516lR+2toIwQ7nQufxQGIpKfRJczOEaTJB0r/5DS5lIsg1DzwgcuWVtKW3l1VCZyc+ztOm8X9rKwRbUEDEn8dDX3k8tF1NHFFR9FVv78gh5Ooz4XIrG43ISg4Hk5LPx3HcbpLtL1nCPVaudIOD9FFeXugGqt+vxyDrGBV0Qj4RdHRgjR0+TI6Hiy+GTFpbGaCZmViBS5eixe7aBXHFxEAkXi+baOHcrtT/GzZgaX/rWyzVS0shtWAPArVxNXcu/2dkQDBms9hnZUthS5ts2bVNNm23i+R+QWz1r0mBZ6PESIBftdWKdv3XvxJV5/FAxjfeyLI9IYHldmQkpDowgDa9Z8/I3hsKZjPX4nIxGXV3c8xly1gJHDqE1jp1Kn2jLExVeum667TNscREvj9zJp8zmyFGJRMlJWkJjvr7Oe6RI9yPwDB1ESaFa67h9fffD223zcZ5v/e9UMJ+4AEtcdLDD9NPRUX0S3Dk3uAgE8e8ebpUoeO40An5RJCSwpK7spIl+PbtEEB8PD/9/Vr4cKCHhc8H2RUX4xc8bRobc7294VNaer1scKnipOGW10ajRsZuN8StdOekJLG7t8tcV7UU9+SI5OVJXukfJaYtKMglIgKdtbhY81B47jmIZPNmiFBdR3w8lv+kSRBya+uxSzG5XJqMEBGBrqrCwkU4zk03QaKBy/2hIazj7m7OabPRvp4eJI3AGn1+P2Tc0IBlL4Kl3NvLOZ9+mglQRQ7abBzzkUdof0HBcNI1m5FhzOaRrWu/n8npnntwoWtv51pWruT9JUvY1N2yhXt+ormkdZxTODefErc71F823GvHwtSpEOybb0JcM2di9Sm/XZUsR+UpjowkEdGWLWzq5edDAv39LOuDI7oUVOJFo8ZZAAAgAElEQVSeTZuQSKqqhhOz0cjGlqoWUl1NW1atEnn7belv6JLtfXNZXnd1SeXAVImWWkmQgAmgsxNrPJB8XC48Jf7wB5FvfpP3/uu/8Mc2mXj/E5/gOpKSNM05EGYzUsuyZcNzOAR7JKjw6EBERyM9bNlCmkwV9r14sVY4VH3HYMACFdEiI1U4t93Ofa2pISd1dbWWa3JwkL5bt45N144Ojv3wwwSC/OQnx08L6nKRulO145VXSG6vtHGLBcIP3GzUoWMEnHt+yA4HS9naWu21vj6W1Y2Noz+OzweRxcayJJ4wAZK+9FIsuOhoCFLJFIsWQSb793O+TZvQlDMyWMofa3PJ4WDQ//jHHMdu16xJnw9Pi+xsXMkmT8ZKs9mk354kW+rSRHp75bzLo+Sif94ttv5OKZbl0i3x2vG93vDE43BoPra/+x1kPDiouZitX4/efP31eGJERGiTWmoqy/2rruI7Y0lqrxAbi+zjdnO+cPqsgsHApKOgfJVVe1JSyKnx9NP049SprHA2b2byvOkmPE3uvpvvPvnk8eWYYPj9mi94dzevKZdBHTpGgXPPQrbZIM+9e/lfuWKpJOujgc+HVNHejvXn9WLpejzs6l96KWSbkkLNOEUKKo1kSQnk5fHw3awsdOLdu0cm5uhoSOdHP8Lb4h//oB0+nxZW/MMfMtkcvQ7r6uUSeyBKZtevk5gfrhPZXSaFYpXtslBscowUnQoREVpGup/+VEuwr+By0Q9f+IKWatLlwgJWCYRqa5mELrwQmSAMmprotkDD+dAhkYkpHjEGZmCrq+OD4aIf+/u5j1Yr77e0aKuFYBiNTI7r1om8+CITzJe/zLNwzz0Qt8lEf0+dyorH4Rh9En3ldXP++bjbxcWNPqG+jnMa556FbDBAksp39r33GKBqZ340OHyY5e2sWbBJZCQ7/e3tWEbp6UgGS5cOl0EiI0maExsLcViteC3Y7RT9vOKK8OeLjITMzWbO99probqtKiP0u999uFy29h2W5QudEjPQyvdMJrGLUwqkWCIlaKMqnMZpNrNhJaLlbwiC3+OV5kVXcK1Go0hUlPjEKG2dRghdyREjTDS9veyDbdumfWTvXpEdpR7peP2oZpyfj17s9WLRBuctdjggYxHu44oVrFr27Ru5Xl9nJ32Wmso9qq8nb8err9J/bjeTS10d5H3XXfwebYTfggVs9sbEcHHH09o/BlAek2OINTsj8HhCu97tPn7937OBc4+QRbS6bgopKaMnYxGswfh4pIhPf5plbmEhOqXaSQ+3TG1uxtpasoSBXVfHk5GdDXlMngwBpqZCwnFxkPV995G+0etlgB/riX/4YVzgbryRTaY1a3Av6+8fOTLNaiXX8/TpnDcqCkJ7+23tepYsCfvVxonLpKwmVqrSzhO58UbxTZ8pFbNulJLOHOltGWDSuvDCET0MYmPhro4OeKuyEqM6K90pqXEOSDA9nQ+mp2P1BhJydTWbi1OmcD9iYjRNedo0LOpgtLdzsrg4kc9/nj7avBlLP7iP3G4++/DD/P7FL7RrUWQeDLMZ6WL/fiQmlfeiuHj8sdUpgM/H4iwhQUsD/uyzZ7tVGkpLcYJRpOx28/+2bWe3XeFwboZOq0AHlaGspwd9MpCkjwW3G3IITg4fEYE2vGiR9prPR2jyBx+gg156KQO5thbtsqaG/9PSkDKWLGEzanAQ4sjPh6VcLj7z8sv4OwdGyoWD1Tp8kzAigg2s0tLhpoGKjMvP1yqEeDws9QM32kpLIa6hIY1UjEbxT82Wndc+LI0LPyWz3TvE1dYt+w05MjuuSaakDLH0X7bsuC5fKspZhHlpwYKjfedwaB4eBw9y3QkJ6OQ1NUxkmZkQsGqvz8fKI7CWndfLfZ4wgWNUVBCwoYJGEhNHrmtos9E4ld7T5eL5GRjgHn7/+5obns1GvpMnn6S9IqzI7r4bz5zMzPD5sccJenqYjwPnma4uzX28tZX/Z83S3r/vPoJLAz0yVZqUkRZ9ZxJq/o2JYX4vK4MC8vO1/eHTjdGGTp97hDw0pOX3LSzkydm+nSX93LmjS+P4r3+RDCg41aTRSPWLJ57g//5+rdTQ4CCDNSICd6ulSyH1xx7DahbRduQzM3lf6bK9vWyelZZC6g4HlaGPV1U6GJMnswH33HN8Nz8fa3rt2tF9f9cuLMV33qFNR61Jv80uNSmF0n3Tl+RIzCSZmXpEpixL43xFRXxOkbLKghZUCmnvXm2fNSmJyzd1deDBkppKX2RlMeG9/TYfiolh8gskYxGIuqoKIpw0CcLdto0J9IILuBc5Ofgoj+b5t1gYwUqu8Pm4p4cOcT29vUyaNht7AXffjXSljq1kG8VyeXmw1bHCrs8CPB72aSMjCYa0WFi5lJRwK+fNw9Dfv59F3ezZzDmzZoWPrVmwQAs2Pdtob+dRUli69MyRscjoCfnckyzsdq3kvQp7XriQATraO6SCD4Lh82m76yIiDz3ERp2SC4aGMC9++1ue7poarfJFUpJW2bm2lqARZbH5/SzNd++m/VFRpLOMiBjbtXd14ZJ16BCE9dWvcr5w+q7ybAhEdLRWQSNgae93OsTf2iZH2hziNEbKUHKmyJw54ttZKdUNEeL1GSDDwUHxfrBFqv9ZOUwZUGSclcUg7uw8qinHJdIvH3zAhLRpE/1rNDLCDh9mEg12mcvOhsC3b0cb3rYNZpk3j/575pljF4ENxsqVCN1NTVx3WRn9p9JoqkrYixdzrsHB4cdWtQKdTi01qspPUlU1XJ/3+7WgozMMVUe2txd1pbkZMo6O1hYHs2bRvXV1zIvKzToc1AJhPCAhYfj/Y8l0eyZx7hGywcDTFagZGww8aaMluPPOC79BExVF9JfCM8+ET06/axcMtH4957ziChK15+VpCeA7OzWXs6oqSMDnY7nr8TAqxjLFGwxYxA0NSCilpejgy5aFz1S2bRvWrWr/0JDIq6+K939+Jm1mbcntE5GDMkWa3Ukyp+qfknnRTKkxzJCqKpGuSfOkpiVattYkijcuUbybiqRkd5TUmPM+LDHY24vFlZUFtyq5oqNDpKnVhISzfDn98n//Rz94PKyhp0/nOrZvpxr2xIls6L3zDt9LTNTKRgXWs6uuDvUYORY+8xn649lnYaGmJq2g6pw5EPKLL2Jxt7SMnI9ZQbnHvfKKtp5ub9c2Zuvqzgohi/BI5efT3WVlGP0qPYrC7Nm8ruKeRiqIGlgf9mxCacZGI8+Z0ThcUx5POPcI+VQgOVnkv/+bp1FZZ1FRkEAgIR/LAtu6le/feCOFUrOzIZ7MTEhyzRoG5rvvYmrk5WHJR0Vh5Xm9bEgF184TgWCVh4P6Pzoayzw6mpHk93OekYJhZs6EtIqKsAS3bhXJypKWuFly0J0hLYIbV5ckyptymRyRBEmOHpJ5tmrJzGS+sU6IkYU3zJCubpEtf66WLeV2OTxxrixcESlJziYR0YIK5872QXQCb65eTVeIyYS0k5PDJHX4MJuwX/86KwqVu+L11yHDLVu4B8G7SoFW9NKl4VnEag2fc+Lee7U+dLthI7ud+zF1KhOoSn969dWhlanDQeUhKSjg81u3MkHX1zPRnEU5IzBgMlzMTlOTNk+bTDy+wSm/IyNR5sYDtm3TNOO5cxmmfX1Y/+MNOiGPFl4vppwi2W98Ay35059mEP7hD1iege5jV10V/lg2GxbelVeG5m9YvRprPf+o3NTfDzGvWMF5EhJ4qnJyNI000BXLZiMvxTvvoA3n5REtV17O8ZXurHJIqOvx+9FBlVU+YQKE3dfH5/r6RFaulIk/+qLE253SJmnSJfFSKzmSIoelIGKHWP7zNjHUH5R52f2yYgVkm5FpknlZfdIzYJGeAYvMmz4kGW3ltOeoj3GcHMHyLC/HypQAJ5X6etrl89F+p5NJqbERc+ef/wy1SAcHIdHOTvpKyReHDvH+9dfzWuBkZLeP6CctIshLKodxTAz3JyODfvP72az99Ke5p6NZD5vN9K/yJd+/XyumerzagKcRSjOOjeXxcjiQL5Q12dREV06YQJ797Gwe169+lTkkMpL57tlnx49EPnMmJKwWlCkp/H8Wu3lEnHuBISeK1lYIpLeX5a/Hg+lwyy1asVKFxkZ8hRsbtVwLgXC7OZ7RGBo0oCw35T+rXPRiYj60ID+0zLOySHxfVcX5EhOxDlX+4ldfHd5+JVMsWQKRffAB711wAbrlwYMQhXpyg63ImBgxtrXJ9J/cJlXffUbq+nKlx5wq5xm3SepvfkC4cX+/GKKjJUEEzXhTkTQdif4wwKL72XWSsTRSTEmJWtTi1q306003De/Hjg4p/v1Oefkln/R0G2VawWVyy81+STlQgmeICO0Oh74++icrC5N72zYIPylJs0i/+12kBosFTb6ri4k1GF4vTDV7Nv1TUQHjPP009yknB3NwwQI+n5SEADsSrFZYbN48LPp9+7QN3L4+5IuzEEji8SBTREdrMoXFwmOzdy/NHRjQaruaTHTJrl0Q9Pr1zFkqEr+6mstSQ2BoKHzxnNONcA4+4zVO59zzsjgZqN37tDStWGd+/nBf19/+Fj8gg4GNo3AbZtHR+AZnZTEACwqGW1X790P+EycyyNWGVm4uVrJK9eh287QVFmpWdmcnxLp48fC1Zm0tpKxkCq+Xnf6mJkaV1wvx5+XxeacTuUJ5JCjytFjEk5ohRX1zxPTaS2Ia6JOMe66USctCyxV5N26WkjITMsXKKJG+Ptnx7B7JHNgrs1Ynicng03zdrr12uC+ViDz6iE/+9nCdmIeOiFXcUm5aKgnxftn1yn5JsfZwzbfeGp6ULRYyucXE8H9lJRbyRRfxXuBk09HB+xUVZNcL1v1NJiYtu10LBb/vvuGfi4igP9euZRUzUqi4wcA58vMh94MHuYeLF9PPSiIKzBh3BtHdzQIkUAk7fJh5MrBQSqCs4fHQbJVYb9s2HsNbbmFoqMVXUxPbL6NRdD5u0N3eTheU348Igyow30FdHeR2vE2dyEhSPs6fD8Hn5Q2XOsrLeYoXLWIAd3djyc2fr5Vi6upCSjAYIO4lS3itpITjq1JHgQg3kt58k9ciIgjgUNi8mRG2dCkWX0eHyJ//LJ6YeCma9Xnp7TfKwjyHHHlri7R7EmXq1QskM5NT7NqFDOro7JfirQaZvTRKuruZTw4f7JOdFX5Z4d8ksYf2cI65c9kcCyDk/iNemZPWKfWOVBHxi0H8YhSfpFm65IYvp8hj/3PUTePvfxe5447hm3QWCxr87bdDmh0dmGfLl8MQTU1MTImJWoIoFRizdSvyifLjUtVPRJgAIyO1kkzBmDFDC9fety/8vTcaaevbbzMJVlezqTt7Nuc0mZhsMzIg6KGhsXvTnGYMDdGtgQrPkSMoeKp7oqM1b8emJuadwPn+XINOyKcCbrcWXVVQwGtbt2qubZMmYcGqAfs//8MyOFzWNgWzmbVfaenIScsD/VcVVEmj4O80NGDZGY18T603jxfiq8wW5Zt01P3PPzFDvF4Rc38PpJOU9KHXlqmjVfYdtErN4cQPnep9Dpds226Ww91GueACumzTJi6zsJDT7NhBl6nFhLP9iNj+9iQvqvJIAwMQ0FFS3vniPvnRzdVSPDRPGmSKmMQjy6VY4uSItM+5QLbtCjCzfvlLgjPcbkhu9Wr8xLdv57iTJ9OYCy7gQrZsgVGWLsWKbmmBJFXl74oKJqTkZNbhLS3H7ksFk4k++8Mf8EcPh+nTKSgwOAjpHjyIJTx/PhJSejrkbDJhZRcXw2SjDVo6Aygu5tYtX85iYGCADKT79jGvGgyaj7LashgrGQ8Nka5lxw4eic98ZmRvjo8C9Jp6J4v33mOTRllCRiM+uJMn86S9/z6Wy623UgBT5Ws4VuFMs5lNn0cfhSwWLNAs1tZWfubPD0/UwaWBFDIzWR82NGhRcYqMA/MOByKQjKdNgyRKSkS2b5eqvSKdtgxZvjxeLBY+un07Rn9mZpr8/R2+5nZj2JntVlmyTIubsNngvpK3e2TjxngxmbT6pmn2HpE+k9j+/QabldddxxfVOrmuDpKKi5P4/GnS7O2RebJTzOKRdGmReOmRMlks+VlBa9577yXsubmZ/t+9G3kpIoLdqTlzmATVOrywEMJV+S/mzGFSKCvjGAsWkEGvs1PLrzwaREfjP37zzUzONTXD3zeZyIkxOKgFykyYQAfv3o1/vPrO5MlM/hZL+OrVJ4Hgx0LtS470iAVjwQK6rriYxU1xMRrz4sVIEupyAs8xFg/N1lbmyu5uHpOoKJHvfIfzTJ06+uN8FKFbyOHQ1QXRBUfC2WxYTd3dvGex8BS/8gqkXFUF8wSHLVksWHAuFwNt0SIGfloaT3F7O2QQG4t1O5Zk5p2dmKSVlUgXs2cjXyidec6cDzXuujoe9rmzfRJTtY3zKbPF6xXZulU6jSmy9fA0iY2FM5T219WFe5PHA8FGRzMY3303jCbY3S19b22S0u5s6c+cTVS66YAcfr9S3ttilcEhg8y9YZYsuGISB9y6lYMuWDBMS7/oAp+4NhZLrAef3FLJl97IdHnrLYzgYVBlkrq6sGpLS9GMp0/H6szI4IJUPbwtW/isw0FeZ5XBT02oycmM/szMY694AmEysWZPSCCd629+Qw7moSEmvt/8hv52OtnwXbSIzzc10f+NjXSsityMjGTyOIWSRWUl8sKyZVr+fTXhivC7oOD4p3Q4cCoSYQ7JzUXxslqZrJ97joXFRRdh6DudmkoUiJ6eUOeWa69lPzpQFTIaWeC8/fbJXf/Zgi5ZnAx+9zv8XIODB9SUH7xRN2UKS1+DgdDiRx7RBrHJpMWQGo38+Hyke1y1iu+ovMOrVmEhi2A59vQMT+wejM5OLFu7ndGlYo+nTmUEGI0iBQVy2BUjV1+tVYFyuUS+/12ffOvB8EU629rgpt5emnHeeQSrBad6sNtJLfy1r/H/wACDc9Yskd0vVIp73wEZSMsWS2ykeCsq5buPp0m5b4EYPG7xR0TKjTeyujd4j6bjCmKBnk6P/PiKLVJbdkTMZpEq6zy571dT5JZbgvphaIh+yMhAwK6oYCeqr08LQe/rYwI67zxM/KeewlPiyBEu5OqrqeJSWAiTVFTwva9/nWMH3nOLBb34wIHhuT0Cn5MVK8KXhhLhnEVFmq7j8TBBmM10XlkZn0tJof2nsB5fSwuHT0jg0Lt2oZT8+MdaVLvPRyqO668f+TgDA0zGInxe1Z0V4TGsrMQlbt48LRmf00lGUjWB9/RwbhWGLcKtyc0NH0+lVlvhFn3jHTohnwweeQQteLRl4yMi2OxTeTB276YadFMTZP3II6EbfRYLeSwSEhDKLBZGyFVXsU4rKmJ0nH/+yBZzczMMqBIPlJTQjo4OzNdVq0RiYuTCC3nwAw29yEismE99KvSwfj+a4P79It2HBqQgsUqu/+F86emnHdHSJ9OlRnbIApmZa5Rduxgo//oXXaFK/y2NrBTXgUNycJ9bHvh5mhR7Fos/wPU9MpK9tE9+MrQNzgGP2LaTfrNz8kLp3dsk6cY2iVg2T9tcU0l6nE7Idd8+7kFcHEuBCRO0ycpgYLRPmkQQyQsvDB/1JhMVUb77Xf5vaMDCTk/nHnR1wTxeL6R58cXcu5/+NHxUndXKJDuSb7MiZeXgGxHBcXfu5F4mJnL+KVPCh4efBFpamJxFOP0dd4Q6hagUL+F8iQcGIFifDyNf3X+lKbtcPPqB8oLDwfNUUkK3rFzJnLV7N/NadjbnrKxELw4XSGk2a3bGRw26hnwyWLNGcw0bDXw+zbrr62O6//73efrefDP8jrzBwLosKYlz5eTw2s6dPLEGw/Hli4kTIQw1WGfNgoyTkiCmmBhpPuCUzZus4nJpA9omDhkctMljjxlCCFktYb1eAgOqe/vkwOYWWeB0yAeyTCJkSApli/jEKHZxiNEYKRs2wEnV1az+HQ4G6uHd8bKvblBa9nWLwxAxjIxFGHR//SuE7Pcz2Gw2uLD+33WyKLpHotcslqT0dOm0pEvFO6WysGyX2OIjtRE7cSJaTFwc193bS3/k5WF9Ohyab3NtLZbv66+HmmBeLxPkd76jZQHMzUVC+NOftNSpcXHID62tsNixPGqO9fzExfGcKLe/vDyNjJVMERGhaeFj0bKPg7Q0baGm7nUw3G6s5J/+NPS9Xbv4bmEhXoWq0lZFBUPHag3Vevfs4dnweOgyux174bXXeF+53ael4Y7+9NPDDQizGePho0jGY4FOyOGwfDlL2w0btIFrtzP4m5uHD0JVfSI1FQtt3z6e0MRETIB//zv8Rp/Ph6mxejVL4/R0BrnBwDHPP3/kbeW2NtzghoaIEFu/nkoinZ1YVPfc82FGNcf6A5JvSpBNslBEDBIl/VIoW6RBMqWtLTRUaedOrBuVjXTatDR5tnuRpL5bLhe63xGj+MQtFimSAjFGRcrtt2sZMs87D47KyRE5svuQ1G5slqmzI8VpsEv2ugPiFIPskeEJDoxGFKLvfQ9SnzABTpwze7oUdydLfkSCtFaJ1Ow3SuaqfLFm9YrERKM7l5ezmzQ4iGn16KNaIdlFi9hgUwEXIppbXXCWPoWeHi0RlOrfK67QynFZLMwYR71PxGrlXq9fH3qPc3O5GIeD9gWKpwMDWNyB/tN79zKJTpmiTe65uZzvFKbrVBOuz8ecoArdBMPtZm4Ph4ULeV89nnY73eD1hjfk/X72x48GYYoIXbBxI5LVpZdqr0dEsB9aUoJF7XbTzWlpWhLFjzM+5vPNCcJgYDD/8Ic8fTNmiHz2s+zMX321lsvAbmfAP/YYRFxdzZI4MLWU+nwwlJ/xnDl8x+MZniVMhTAH46WXMD/uvx/mWrAAnbO9nVF24ADs1tYmsnu3TMqxSoY0yULZLtHSJ4WCZ0G7OUMuuST08BkZGG7Ky8poFElZMFFW3jZdYiPcEmXzyi77UvFFRMvatTRfdZlKO7G/ol9qNzbLlLxImXvDLLn82/PkoGGqZEudTJSmD88VFQUJ33MPg9/n4/eDD4pU7zOIITFBPvgAIzEzU2TeAqMYEuK1sGO/nz6rqqIg6cAAJKqqb192WegFpqRoIdDBiIkR+d//RW6qqoKg33uPRu3dy2sHD/K30Qgjff7zWlVsEa2wwF//yv87d7K5qmSNgQEm6aefhqwvuIBJ2ePBTFQZ5BSmTh19lZJRQE24ubmc9rOfDU/IkZGhuYyVHWKzaWTs95MJdtkyJvF77sGuCERVVXhyHxwkjqqyEsLNyuLxPXSIufaVV7DQX3iBLh+v0XWnErqGfCyoreSKCiya22/nSf7tbyHnZcswDTo6sJyzs9lqDjYTvvlNkccf155okwkR7YorcP1qb0faSElhhNTUcLxZs4YX7jxyBGtpNJnKLryQoqTTp8tLv26SZ79fJU6XiEusUmopFHNCjFRUhC+ooaASkcWb+mSpZ4scqHZJUZGIJzZR5t25THr6zeLzoaz092upKKKiREw9h2XGsgSZmcec/8orIl+//pAc8meIz2/4cF9s587w5544kTlRpZ9YtSpIjt27V9xV+8Vi9pPmtKxM/CLiEZNY5Oga3GplLb14Mf+rTVCVVD4w3ZeKwvP7ucfx8TCLxwP72GxYuVYra/b0dMi0tRWyLSuD6VauJMWpyujudNKGoSHuZ00NpHzwIAz0iU+w2djWxkSQm4uGcwo140B0dHCPAt2av/AF5gflHKRKKT77rFbMu7ubeSUvb3jK8HvvRdpQDkkWCwuD3bu1RcGePWyPhEvfnZ3NZS9ezBxXWQkpL1p0yr39zir0Tb2ThRpIqnLH1q1Yw0uW8GSqJ/vAAcyJ2bNFLr+cn3AoLxf5y18YeCrgpLtbMyv8fqyh3FwGe3k5FtqaNZqO/MILeAIEW1HhkJ6u5VPo75c9v9kgL78scrArViZcvVq+fp/huBbHnj0i3Q19ssy7RcxWo/iXF8juol4x7iiXtLwEKbcsk6WFZomN5fPvv88y9JOfhL8aGyHdqVPZv2pqIudRQwNqzk9/Gn43XUQkQw7J//v7BEmaHPHhsrogo0HiZqSK1NXJvvdbpNGUJYWfyZSI/Nni37dPdsss6ZAUWSUfiFm8NOK112jQ0BASlN0Oa2zYwP2or4cQP/lJ+vrIEWaX2Fh2v9T+QEQEqyWbDdbweLh3ERHMFm1tHDc9HdI/dAhyTklhIv71r7mfc+bwjJjNWjLhhQthsMCdsTMItYn7+99z6TfeSJOamrAH0tN5XJWPufKSaG1FYQn2CrTZWKR95zva8adMCS3qHhlJFPl3vjNcG25qYkI+TXPSWYG+qXcyUG5IKtw2MREr6cUXsZTNZlwUVKJ2lWB10iQG3JQp2rGUf+yiRfz9+OO4FigmKitjm1vtbpSUaBGAHs/wTb2x1GNT/sVHqzHPWmiTWRcl8bRnbBdJRlM+FmbNEvEkOMS8xyyexcvEHBMtsy+KFl+eiHFflaxZ4hZLLO1ra0OaXbtW89wTYblaVcVlXHQRg/3111nmjnQ5ZnHLqvhKyeu2SPblheIwRMj2F/dLbfEemb02W+yefkmZkyJ1fVNlS4lBCi6/Tmrr3pJ6z0SZJrWQsQh9fPvtzBLKtyouDjnjttuwkmtqPgyKkX37CNyprGQ2amri/is5KDIS0jYYOGZHB2zV0qKZjcrFoLycife887jH5eWwjM3G67Gxmv6s8kCuXKmRcXCY+0ivnQIYDKg74RSe/fv5iYoanjJFhNWT2RxKyE4n9/grX9FKHL74Ivff42HYqGy13/xm6CV9nCzjseLcJOQjR/BD3bwZE+6uu0L9fdPSsG4mTGC3YuJE/o6LwzsicP2lUig+8QSEHBMDiXd1sYs+Zw7mREYGRB7OLLzmGhLaWywsrQ8dggACoy4uuWR0pXIjIljGq6wvIloB0JgYGFKVGzoOzOnJsu+cbxsAACAASURBVLvzfOnaZfzQu844aaLsaE+ToUpeMxq1xOZpaZplM38+r3s8rN7V3LJ2LW54I3GL32SR1d8skOzJRWIo2iIRqamyOOKAtC/MEPuiWSJ+v8QbDLL8iEGKikTWL7pfJLpepvVulzxf1fCDtbSwo7R9uzZRnn8+DVJZ92w2iNXthogTErTgn7g47rvTyayjfLwyM5lkN26EwK+5BnNSOcpGRbF62rtXS9157738vXUrcpeqWKNmJuVgu28f51IdLoIF3dvL986Aq0FdHc33enmc4uN5rbkZ7dlqZQ4Kt19tNDJc3nuPS0hORrKor2eR19rKouL88z9eVvCpwLknWbS0IFgdOYIcYbHAFBs28LArOSE6mnWbz6fFhppMDM4bbghfRMxiwWyYPx/S/ta3MC/i4jhnY+OHOYDD4o47CFOaMQPSjInBagp8ap99lo0k5U1gs4nMmye9Vc3i6hmQpJlJVEa+5BJSbhxqlISseC3rmQgjTVW2Pg48HiTS0lL5MHqvooJBlZt7fG8st1vkgQfwpHC74aCvfY0uuvNOjh34CBoMBLR94QvCPdq4kTcSEtA5AvrC7ydIsadHRHp65ML75ktER0NoI+x2+nPKFPqtpQXGUAmU8vO1shK7djFxKrJUVbjNZr4XE8NrM2ZAyg0NmH9WKxf1+ONakMrSpRzfZCJh8KxZmhTmdPK8DA5yrMZGOruwkMmgtBSDYPlyCLqubngExWlARwdJ7F5+WZPSr7gC4qys5DOrV+MWrbBkSajrnM3G9kV+Puranj0s2F5/nXNccQVdN3fuGVdnzhp0DXkk3HorlmiwpZmdzZNTUoIlEliSdsMGpneVOD49fXgdNAWLRSORK68cWSAdCUuX4vPT369l+g5Hmo2NZDkbGODpXrRIiopEujp9snS58cPo7uJiuEQFBI4VAwNc+rx5DDJVeWHPHgbmJz6hGXUdHSxdd+7k9/nnM2d997sif/tbqLvu4sVIuGvXshhQHmVPPRVQc1WlIRXBTFux4kOXMFXtqL4eC6ynR8Tyn7dJYePzEiFBJ4uIgOByc5EOWlo4looyUPd5/34ONHEiDDNpEmWjOjpgHjWpqRJQn/gEx25uhszvuov7H5j/ZOVKZIu8PH6npWmpTYeGIHKPBzKvrOS8ViszVaB3xWkmY5eLJjY2anudJhNd8atfafrv5ZfTFIXOTiL63n9fSxr4ta8x991/v1aaMVDWsNuxrt95Z7g8oZxjZs6EqA0GvltaqlXK+qha1LqGPBLeeCP8sr++Hpey6OjQkrTKYsrP54n47GfxtAj2XD//fJ7IBx4YOxmrsOo330ReyMpiabtiRWiZpsmTMWUCsHixSFGRUUpKMLhqaxnPS5ac+EPc0sJxBgYw1JxOpIb+fviipISu8vnojkce4RKUrnjbbZBuuFQQ5eUQfG0tHhi9vXTrhxlDFRlnZLAruHWrVq4pIkKqqrhlKotYT49I8eoLZMvfW2WN+9+ajiwCAzidGhnPnh2+qkegR4sIB73wQr63bx8nqq3V/JyVv3BMDHsAvb3Dny2fj8m5oID2798PaScl0aEOBxesoiry8phlvF6epR07NI+a01x+Q5X3C3Q88Xq5z9u38+hnZoZ6DNrtFNletgzC7O9nQfiVr4xcFN3hYGHx9ts8I4HnGxriGTMYmKMOHKALenuR4lUBmI8rzj0/5JGypgSWaQ++4zNmwGxGI5979FHCiVQpJpV/+O9/5/PV1WNvV0wMhHDwIE9kURHHDQ6jCjY3jsJqZdz7fKzOPZ7RJYk5FtLT4YjmZqTvf/+bAbtoEV3V2gopNzVp0eFq8Dgc5NU5VobR//f/+H3ZZSKf+5zW/V6HWzzV+yHjhQsxlwoKOHl9vYhADLm52t5lfLzI8p9cKVOn+MQcZdc6JSqK9fOhQxoZB5p4I2FgAEmjooILTkpCH3n3XRqamorZ2NuLFb1168hVMx97jI5IStKiBhsb6Ti1W+bxYCw0NsJura10pqoOE1hH6TRg1y7INBgOBwsEmw1ZO/DRc7mYS6KjsWqHhiBtpcgcC4ODuHz/4hd0sYgWYBIRgUL45JPctrlzGVIuV/gSkh8nnHuEfNddoSxlMmFiqk2fwKxfCoHMYrEQTrt/P06UZWXsYCgr+0Q82GfMYF22ciXL3s5OBmVRkbbeV0vdEaozBlsk4QbYWBAVRXNUiK3JhBJz440MHp8Pq+qJJ8ITr9d77Ohhh4PjFhVpn/N6RbaWW6TEulL8CxZqB46LQyeZOVNEmL+C9ev4yTGSXfka5vrNN7NSqazUnGlF6JRwMl3w/Y6KwvxuatLSctbV8f1Dh0jW+/zzlMJStYpGgspveddd2qzjdHK83btZUjQ2MmG43byuNOMLLsA87e2FlI+V3vUkMGNG+MBQu51FgkoHrsi2t5fHNCeHSTEujoVbWhpW9Wj2nvfuZZulsJDb5fNxvuXLaU9UFM/0jh2agRFY4evjiHNPsvjmNxGl3n4bhvF6eYr+9Cc0YpXwvbxcKzQaCOXGJoIFl5HBk7lyJexiNmtps8bipmazoTF2dCDcxcUxOFWqrPx82jQ4qFUNCUCgZrx4MQ+xkhROZomnNMC0NIzCgQH+z8+Hq5qawic8E2GALV5Mdwe/b7OxyJgyhXa+8QaGsPIkXLgwUgzB5sJoCrLZbIxuNcIDZQqXS8s3HJiwx+tlVkhK0ipfulxMiFYrQvrAAJZyYiIrGJuN1/buxYpXCR3CEabXG+oZoUIcq6vZAHY6NbH/wAFkGqUZqzStvb2nzcPi2muZv4aGtMnRZOLZWbuWeaSgABXp6qvx1jMYIOGnnqJrPB504U2bRndOj0cj7pdeYjvkyiu5ZWYzqt3evUy+ixd//MlY5Fy0kC0WBLPSUjzhn3+egaTyHGRmIl6Fy4St/JNVsVERBu7atSxZ1Xrd7WbgqHzJkZFM+yMRis2GmNbRAaNGRjKwV6zgewMD7JqodJJJSSGHqK7mMMqKKCjA4qmqGtu8EIj+frrH58Ora/FiuK2oiKa2tjJYrrsu/Grabhf59rclJF1mRAR8+MUvojs++SQZvq64gmC5F144dgThqNHePlymUG4h9fVa1RcR7lFMjFYz0eXiIvv7+XtggO9nZHBPzjuPSTg5GcJubub37beHb4fNBrsELxfmzEGicjoxCS+6CGJPSOBe+/3ad9LSNB15tEmvxoCICB7hCy/UXBQvvZRuUEZ9dDSFUN55h25xOpHUL75YqwH8yisjG/Fq0y8cBgYYjqqM44IF3BKLhdtSXh4akv1xxLlnISvMmhVSVPNDZGaGf12VUFJ+Ptu3Y4pu3hz6FHqPRoodPAhDvv020/3+/eQ5UKkczWYIPSlJqxbd28uTuW0b2nUgRkg4tHgxh7MHyKcFBcMN+rGiuZljXnIJFrGSRGpruZTkZM5RXc3vzZs18ld+qipar6gI+fXQIVbhV17JpX/jG+xjut0aqb/4IsvgBx88sXZ/iLS00Jjr3FxeD3zNYNBkjZoafoxGzL/6ekgyK4vXKyq4oA0bIHWXix+jEbJubtbEdhEm2GXLINm//pWwauWasncvSwSnE/bZs4fJo7BQW5ps3sxkoAwElfty1qxTHkGRmUkKVWW1BicaLClBSQmefB0O8ilfeSX7oOEI2W7HDTsyUnMkCobbDQHPm8e8aDTi4bl3L5Z7aSnDYSzVRz5qOHcJ+USgSiQ99RQmntJ2RzIJlLzw5puwUFUVfmFJSZiG06djba1ezROrCpIpE7euDv3SZOKztbWap0FQmQ6LJbSm6YlsgCjf3hde4O/zz9eUG6UpK25KSWHOSUnBbzgri0vs7sbCWbgQSzo2Fku5vJzBtHQpl+T343McvAHkcLAPd9KELBI+H3G411TKTlWtw2Lh7wkTtJr3JhOT5I4daNnvvstqKTGRi379de7l6tW4VqqAoqwsgoSSko4WJzTBMrW12t7B7t1aDkolVfh8dJ5yAk5J0WQRFa9+GjBSxteDB0feK6iq4n6vXs0jHi7dyt130wU/+1noexEReNmsWMHx2tqQ8OPieGbcbro9KuqkLm3cQyfkscLtxqwbKYVjMJqasHqVv6kyP9rbeeq+9CXWYiofskJcHGbB0JAmU0yYwLpy2zYsv9OAr3yFsObBQZrz1FMMsIcf5v2oKDikvx9j32bDkLTbMeRWrYJn+vog1uho8r6rAdrbi1TR2ko3jpROuLdXC3BTy9yBAeqZPvcc5/vCF3ArPyFZtbISUlOrIacTh2mLBRIdGuIeKDIWYVLcswdi7O2lM1QtKYuFe6TW8CkpaM179vCeyYRrnJo1jUaIWkVZKE05sByGSu1aVqaRskr5GRjoc4agdOJgKKnMaISUU1JYCanPRkbiRSOCG+SllyJtKD/jiAjmwsCyXHPmDHfDtlhCF4sfR5x7gSEni+eeI6IuXKTeWGE0svl03338HSyh9PayHA7UjLu6+OxIlShOAmVlDIpg68Zuh5QDvRr8fixeVXlo8mQt8PHll+GqpCT0xuLi0HNFR2M9L14cPnhx3jyyn86cyQTgcjEvVVdrJB4Vheb8t7+N8UJ9PtbfHR1IGCkpeE00NBD5MHcuBNjWpjVAQVW27u7GE+bgQWYfu529h64ujvXLX4a6JyYkaEmIFFpbMQGPpSv19eHFI4LEEeg1coZxww1swAY+I0Yjk+zKlSg62dl0wbZtXNbFF+NN8Y9/IOnn5/PMbN3KvZw+nY3CKVOwT154gW5esABdWSXr+yhjtIEh596m3slgaAgr51Rtqvh8bFfPmRNez46NDd3AS0w8LWQswqWFs1j9flSXQKhS7z4fiwBlCK5fD0eJwHV79458vsZGXOYiIjQ+OppXX267DQNSceFLL2GRB7ZvYIDXj3WOsDAaNfeTl18mFK2/H4foefM0V8Ps7ND+t1i0PNi9vYimhw/zu6qK+7huXfhomKEhZg9lBFVVwUrNzZrfsYgmgTU3c+ziYs4bHY2mfeDAGC/41OGZZ7AfAucPnw+f8z/9ifmmsZHNv3XriOJracF1v6kJSSI1lQl87Vo2hC+6iCGwdq1WWUs5yJx3nqYinQvQCXkssNl4okbKqDJhwth30MbRDkVERPgCkiZTaGVplwsuyc6GX5Qrdnc3m4CXXsrcMdK+k8fDUrahgQ2hNWs0B5c77mAJG5gz4Z13wm8EGQzse40GAXEl3K8lS8Q5cao0dkdzQdOnY/K73RBzYETfwMBwl5XychgmMxOivf9+agwlJGgzUjD8fqSq7duZRfbsgXCHhjAtVSXs99/HvCwqws9ZedysWcOGZGXlMJY6fDi0rF97e2idvFMBs1nbfAvE0BD3aM4cmhoTgyNKYSHfqa/nflutzCuBgZJqD1sVHw+E08k+w7mC8UnI1dU4RqamMiqfffbEfbdOJYxG1lSf+9zwHTOLhcH70ENYr8FP60iIjMQv+lSgr4+BGthPPT1jMh9vuCH8ho7fj9ubgkoi19+PV95XvgIx2+0sOx94AAN0xgxyHgdvLtrtuLm9+qpW9PInPyEn7zXXoCRs3Kh5dbjdaMnhCmeYzVqitmAEv1Zfj/RSXc1FOUt3SVFDhuyyLpahriEaNDjIRQWvQlpaELV37aJDUlNZKZWXi/zgB1oRVLd75AICZjOSSFMTWvPUqVjUO3bw/QMH8AGsreVn4kTEWaUZK005K4vJ/yj27IHMFCmrwgJjXjmMAr29oQVzFaxW1J81a7hXhw5xT+PjIeHt2/muytOUnc2msQjuleFsGbeb750rGH+bevv3o94PDGihYHfeidVxSrbdTwGeeIJB8eqrDKRLL8WXp6YGP52DBxl0paXDn1yV6MFuh9W+9z0mnlOBjg4GtBLfjhzRlro5OaNyuZg6FWvknns0YvZ68dYKDD40mbBwGhsh0Pp65qOCAnbG9+//MKBOcnJYyn7lK1ris5Ur4ZeODpapHR1YV93dEPqkSXDUHXeQQqKigvaEC56MjGRgv/8+vKVcvXfvhuhXrdLmx5wcHqt91X5x7qiSrv2DMpg8RZbeFC8Rf9+qSQHhJtRp07hnNTWwUn8/csYf/xiq8wT6/rlcNN5koiNNJi3Ptc/HM3L//VyM283s8p3v0MF2O0sFdTMcDjpkzpxhO5lLl2Jcb93KPayro3/DxTWJICV861tcSlYW5RgDJ9yRMDCApGC3a0VSA+HzaUO3oYHzmEz4NpeVMcfs2kX3/ud/as4khYUMl5E2DAsLj9+2jwvG36be7bezFRus00ZGQs5ny++lpwffreef58lZtQqTUmXzWbECBti3jydy1iysp3/+k82fxYtZm6eloQ2qisanEiqwITqawat25MeY0OLwYW0wXXYZFo7PB2Eqw+znP4c3AqtSxcXRPQ5H6F7Y4cNIGi4XXdbczED9/Oex8H78Y2TZdet4L1xiGsWTVivtmToVCTg1FYvdbOZyDxyAlKZO1ZwXFPx+kdISn7Ru3i8SGSkFlydK0r6j8cBuN/c5I4PZJfhZczgIf371VT57xRWcOLgUhghMctllPBPx8dQ9fO01CHxwkHOcdx7PR3DR3JkzsbqV+b90qRaU5HRqM1oAnE5c3RUuuST8vPLGG+i6gXvSkZE068YbQz8fjNde4x796U/DVyAmEwT7zjvcx7feIldJbCzd2NGheV/k5GCLBBj5MjRE8rySEo3oDQa6rqrqo19P76ObfnPmTEgtGLGxrGMDy1GcKXi9aIo1NdpTaLFgNf3tbzDNwACDcNo0nrh587iOjg4Gdzhx9nRg2zYtpOmCC0YXbjwKVFdz+YsWQbzJyaGOJhYL1vWtt/IZFcvgcODbbLPhuqtSO9TWYlFFRbHQKCuDYI+VByEykvl6wYLQcoNFRdrtCUfGIlo6kL5eImZm9JfLzIR2ZIq4OKSfoiImsUA/LBH6c+PG4ek1VaL7YBiNRErExWlucn/84+iSPNhssJkqNxUfryUGGaHEk6oyplBYOJzwFGbNCi9lTJ48fPPs8GGaPHUqj3ZUFHOLyj/y6KPYGyom5sorWdFYrRCr0ci9vv12SFi5ccfGImNNm4YNI8IxPvlJFguBE/HcuTwPOTmnrVjKGcNHN/1mdnZ4QnY6T2k59DFh3brhiWJF+Luxkaft4ou1rO3V1ZgnBgOTy/TpZ+5JUjv+CtXVMNcpSCKbk4OhX16uBSwGw+3Gy+IXv9Bea2/neyIU0oyOhtRrayH4t97S1CmR4/OV2QwvBWfKjItjsKvLD5fQTZHx4KDI8gKDNDeL7Ns3S2TCNJkZfzTQIjaWCTT4AjdtYvcwOL2mIuXAFZ3yA1QeGQMD1LsfrXeO0Qgpx8drlbVFaNcIZLxtG32waBF/q6IkwaRcWxv+lI2NnKaiAluioYFHu6GB5mdlsfKoqsInPdAN32xmnvJ6IdG8PJr98stIEYFJppxOnFoCN2L//Gcs4+AJvq6OiValAF269LTGw4wLjD9CfvBB7m7gxojdzg722UqEWlERfg2tUlGZTGTl7u1lIP/3f+NA+bnPhZJx8Ba1388gH+1G4Ejo6dE04zVrGE1VR8sZKVIeGgqVL8K9FgS/n80wdXnBeXMDoSphdXezBH7vPU0CXb2a2+jxMCiPHBn7Zbrd4S3f3bsZuImJGLkqoDFwgXDokBY8mZSkPNrsUtdsl8zAbgg36ouLw89CqkhpZCTPQnQ0ZqjdzgkiIngGxrIprUIkLRaYSE0C+/ZB0kE7rzU1KBgFBXxF5TmqrQ0l5EmTwnvNJSdD4kNDWMHz50OiDQ1swJWUoJ48+GD4GnpOJ0rOunX4jwfPUQo+HxJVV5dmXz3zTHi3fpVn+5OfpH0qBej+/dzDkSIKP8oYf5e0ahXhYV/+MiPW70erfeKJs9emadMYcMF+V1FRDLz/+I/hyWpEEEfnzx/uu1VVhUCqEhX7/ZB9Tw/XHShr9PfDPgkJEH9rKwPcYIAw+vpgIFVc88gRbTRGRGhRHCpkyuViolOVrUUwXUtKaGNwTcGjaGhgAdDYSPMcDjwkZs1iYAUSc2QkHhYiOPoXFWlJaESwhidPRsU5kdSgdjtzTbDLtqpwpGQKJV9s2cLnAzf10tI0aVilsJg2bRQy+/Ll4WUnsxkx/IEHIO2GBgjY5eKgra0wyEhQm62K5axW9Ob4eM0Fb+VKGKu8XEvhF8BGKvmfuk61ERauuQ89RAhzoL1jtbKp19PDpKlIfNEiCDA9nT59443jp2RW7x9rMaBsA4Vw3jMiWrqX5mb2zXt6kDViYsaH09XpwPhUZa67jruwfz+k89RTJ5dp/WRx1VU8BYFPuMmENRQZGT6awu1GBwxEaurw8j0VFTBdenro6Nm5kwHe3c0g37aNUKcdOzQTMFDTnjKFTaLAfpo+nRFmsdDOiRO1jb/OTkyiyMgPfaH9fk4V+LBfdpm2T6kCB//xDzaG5s1jMMfEsFx+/HGaUFcHb4RzjfrDH1iujmX1brVi+X75yyyDgzFxopYSQkRLBTJlSujCI3ifzmAY5T7xihXoIMEHVMJ5RQV9OW8enXbLLZijKnH09Omh99hmY1Pvlls0TwyDgcztn/scz4rSjFXiqf7+kOctXB4Tmy28Bfkf/8EGalwcfZuQwOmXLcNqDbwvHR003WLRKlWdCiJMSBguKd15Z/h7EBXFQiEpiZVWScnwlcDHEePPQlZQpWvHA+x2yPHWW/GvEmGA/uUvWkXIYCiXvUAkJDDAiovZjhaBSZSPWCAWLYJ0i4uxaLu6mJxyc3ndaAx9MkeK6hAJn9EsJgZT6qiV1tICr3R389Hdu1n2Brs3qTI7v/wlHn6zZrHDPjTEXNHSwiHDLUP9/tEHLFitWNqpqVi27e246d5003A3YVWxIhBxcSPnz1Xuwzk5WoCC281rubkjfM9gIMPb5z9PEiG/n5N+6UtMksrzQZl7hw9D0F1dIk6nDF70KdljbJahmiaZ4G2T3CynGG+/jWdCzVCB6Tb/9S+WJoGa8cSJbBCe5Fr9y1/m0dm/X3Odrqsb7kLf1oY1GhcHMdbU0F+7dp144RKbjcfxueeGqz/XXUeCvGee4X/1yD70EFLFwYP/v70zD4+zLPf/PVsmk6RplmZrlqZZu6XplqTpAgVE2UQFXA4oeupRETiioh7PpSIiIIiAinDA34UHjopY4SBwZIcWaJu0SZe0TZo2TdMsTZNm3ybLZGZ+f3z68MxMZtq0tpC27/e6eqWZvPOuz/t97ud7b7pC6tKl5y4Zi0zFKIupDpXKarWytquuZooPHKWRkbpzhS+8XqZ7tWb/2MdCW/8jI4xU9b2ICM1yF110amFzHR26uESQugj79mERp6VhlH/728GJtbgYHikrI1ktI4O5amwMcs7JCV046GRq91ut/n40hwOi/vWvSbk9lQqUqvHz8DDz47RpLBZ6e4ndPW4t5h07EGHnzYO9Dxwg0iYzk2dtNnMDX3nlg4vc686VW38SK2tcb8ghd5qY7A4xz8uX3/1vqoRteIMqScFu1rJlPIQzgOFhFp5tbdgEycl6CK9YAQn29sL/O3di0Y6N4Rdoa5tcsIiC3S5y7bUsEr76VX91rL0dyzcpieH8yiu8YmvW8K+tDaIeG2P+U7kyZ1srp7M3ymKqIz6ekfLOO5iCs2ejH/7619rx53Awej7/ef09lwt2qarSSQU9PTCar6bsazr45pEODzMqlQV2+PAEs3BsDL71JamREQ6TkiJaM542jQmjsZGRrTRlYZceDzwTrA+oiNYc9+7lpVUZ48uWQXTV1RSbefDB4N8/mWVv4IuvCuD9279xOz/zGaI3TuYFVdXJNm/W3n6TCevrhIXxs7N5dopVcnKYGerqmM0sFn7Oni0yd654p0XLpUXJcnhEpE2mi1MiZGQ0XJL2DsjvX0ySW9csDh0SeToKWIWAckW8+CI5TaOjLPrWruX5FxRgrKv2Xb29enH36U8ToiiCBRsVxavg9U6cV6xWJJFbb/V3p3i9OAh//WsdV56aSs2U3l7kp95ekk+Lixmy6em65dfZSMqTwflHyN3djJ558zT5dXRoOeBEGBnBOabI0+mEfVTmXmcncsMPf6jJs7kZloqNZd2dm8t+xsd13Ovq1brg67x52jOlHHQqIeXGG7kGFRroQ8p1dbqAeGam7v40NiYywzEkti1bdFNNmw2duq6OYxzrJ+jxcEoinP4PfkDM6cgIl2y3Q9SZmVhR2dnayRYVxa7Xr8eZVlPDytuXgNVqO5iFdTKWswqlevFFkgzuv39y31Oor0eJGhzkuJmZPJquruBRHB8gOnpiFMbKlXymYsrS0j6IbKmp1hJNjbDjGdIh6SP7pfKxbpGbl3HjAqN4VIHgM4SuLqTq3bu11v/++xBeXp6uQSFClMM//sFwvOMObAr1nHp6IMv33mOur6nByj1yBKv3Zz8j1ry+XjfSWbgQpe+RRxhXisQPHMA3ocjeZmOsLVumZQqbjX2dzTHJx8P5R8idnbCWCppUVmNUFNbOifS5TZtguQULqEvwzjus/fLz8XaZTIzc3bt5qYaHIdqEBEZ6fDzHUWZHTAzrsJ07sViXLOE4qvnlihUQumKJQ4fQK0WIoPBxNM2dy3u9ezeDvLVV+4VsMZFMOOnp2rRYuBCCPqbVq0ze9nb+pF6U3/+el6ytDX9VRoZWWQIjHnwdeTfdxLEfeIDPPR6237Vr4m21WnXkxvj45Ml5eBjf6ckSsggEFB6OMbthAy//KZd69A0VsNs/mOzN42MiXqv4+s87JUF2yGL5rHsHJucPf8g/r5cbpRqs3nbbpA8frOCP72cjI7pAVHc3BLtrV/DuHw89hHYcFcVQqa3llCorIePAcPy2NvT32bM57ZISjhsZqTM2bTYub98+xqTvglLB7WbVpfq7xsXp5qoKCQkfXfTrh4Hzj5Dz8mCGujosY1VFvbQUVgjWKsBN3AAAIABJREFU80h9pphi6VKm6KoqvW1Ghh7xpaW84X/8I6ZXSgpmwsgIoQodHUgOERGQcm+vdmmrlNhly3RJtPx89qMYSjnoxsb83kKzma9t3Kh7ea5a5eMXCsymMJl4g46hvV2TsWrALcK+Hn2U/eze7V/M7MABvYvubvglKop9bNsGITc0MOe1tWHY19VNXI07HMSvXnUVL3l6+kSfaCioRtKTzX9xubDsYmI4rsvFgiQsTCQh3iMTgo9OlCa2fz9Mk5aG/KDC3NatkzkP/EoSh/dIg2SIiFnsMiLXyvNSZNkuxYtmirTP4rm89x7OwvZ2Ut2uuWbSa/LOTshy6VJNVq2tEG5pKde6dy9EGRfHczx8WFdu88X4ON9VxaMcDp5FYaHI668HL3Q4NERK9a236jonS5fyvFVWYF4ehNvdzXP1bUvpC6v11OLTzxWco4b/CTBnDm+j08kIU4LU4CCeKd80pL4+PhscZLSsWkWeaFoao0sET4VvJRe7nVHf06NfVKUfqJSopCT2qQrI7t2LN0wFgYaF+Wc12O0QviJ9kyloAKdq8eZ7+pNFSgpSgy8Z5+cTOedLxtnZEGdqqu5EpJJHHA5uZ3y8LgpTX49lXVDAdoHcpurtr1mjY1S//e3QoVuBKC6eJBmPjPgVfLr6apFYx4iENR2QObluWRjbLObNG/1v4MGDsNP4OM9txw4YS6GzUz/jRYuYiTIz6VP0y1+KyTkkz3s/IzHSJ9lSJ/slTx6Xb8i33Q9J6f/9iCo7HR2Mg6Ii0uC+8IWTEkijo7nvquZ+aysWq3IVJCdzL7dsYcju3cuzDlVFtrmZCJpduximeXmsXLze4M9D9fJ9912kCqXFm0yc044d3LqmJs5PJLQsZLGcQDI6x3F+EnJHhz/pqjq3ZrMu4tLfr3Xc8XHNImFhjC7fFOXAAM3mZl6wRYsY9fffj5jW3o75WFMD6/X2Yi4qc8RnqXsqUJzvckGGSUkTLdoTIToai0elO6vP1O1QmrHJRIJaaqq2TktKIGM1Z0RFIa8qFWbZMrjqiiu041FF7z30EBa118txiop4kX/wA6RU324lvrBa0TUVxsYgHd8OxR/w67EJ0FZZJiuWjcnRxmGefV+fhMmoRMaHy3TzgM5oOXgQ6chuh6ESE5k1srPJVOjvx8G3dKl/iroqwnBsGbBYdkqLpMlbcomkSotME9bqptFRxsB//zfRFK2tHyxnRkdRwj73OSan45XSVA1to6KQYR5+mOI/77+PTRAezniw21Hc6uuxKy65ZGKda48HJWzPHoJHHn2U/YSF8byDJXGYTBA8qej8vmsXBn9yMuMiIoJnP2MGz3nz5uDX8uMfn9thbSfC+Rf21tGhNWPVSLSuDoIsKOAlUjFRIpgevjm4quuvsqyPHGEUqnVdezsvV0ICLPLxjzM6Vfrs9dcTSFtTw1vX2soar7CQbf6JFj1790K+KpdAacI9PayCJzvQlaWlmmqoPBSbjWg73zljslKB1wvBHj4MIVRUQPSf+hQv+8iITmkWYXlrNnProqNZ1ARLNLHbRZ54gkeUkkI24OAgeuaFF0LOW7fClykp8sHzrzo0XZqOhkte+rDkf65Q6g6YpLY5UjKndUnB8LGSY04nYmZrK8/NN73Nbie64uWXg1/syXidzGaRdeu4EStXijM8TlasEKmv84jN2StOS7RY7FZ5+unjV2vdvRu3hlLiVG2it97i3qqa+iJMlKoc95NPMtxV0afA+3vXXdyOrCzu54MPav9lSgqT5uWXI1dt2IAhYLPx8/rrdbTOwAATwttv49ALLEZvsRBB+lEm5Z4pGC2cQqG/X5OxCvnKzeVzj4dRqgq1irBm95UOOjthhtJSmEJ5LTo6GGHx8YzcoiJiiHbt0qnLLhcv3vvvYxk1NWEqrlqle+UFFo85iQlzzhyCNdQulKa8atXJWR2LFnGLVNt3lYdSUjKRfCdr0CsynjsXEl66lEtevx4C9SVjEV5Oj4f5b9264GQswi3/+tdZ5q5dyy09fBjLrLubZXp4uE8IX0KCyPz5Mi1sVPKS+yX/03NF7HbJbd8oC8e3S0R6PCfS14d17HDglQwsOj86Soy4WoMH3pTJROz4bj9/PpN3XJw8/rjI6urHpcGZKEckRY664+S7zrvkq2u9Ie9DayvE2damnbEjI5DgDTfge371VZ2ZuGULl/Sb33D//+Vfgg81lwsS3bWLZ3DddUTdfOUrrHTuuovozvx8wuF8g5cuvdQ/dFJFtERFBZ+vVO2M8xnnHyFnZ8MsvhrdnDkwl8XCi1hVxefj40Sl+3bpVPUklMdpeBhCv/BCbZLMns2L+sorwQNpH38c3TE5GTKPieFNevVV3hKnk2VzezuM1dfHaC4rm2hW+EANdl+YzSdXQtrj4eVLSeEFra7mxbbZJpbrCIa6Or7v+3LX1HC75s7lFldV4QNV86BqL79xI7da3YLf/x7r6/nnj585r3TzF1+kJvDKlfjINm/WC5wPltpDQyIHDkhWslPy04a4wGOV+WaFHZHs6pd0cQxVi8JXM/aFzeav7fji4YcnnrRqUOALi4WxU1eHViAiPY8+I/eN3y4zpEvsMibRMiD/IffLd8d+ITvKR7nBPjnOHR1Yv5s2Bc+iO3iQpL/77iMr7tFHuWRVTMjj4f4FC4c2m1n8rV2LXfL006zEVMU9u10fs7GR4amUN+WjVEhI0A0FgqXOR0RA8uczzu0oC7eb9XFOjp6SW1oIjv3Up7RLuqkJ1liwAPHMatW1cLu6aJOgOhJv3szIHRzkxW1qwlJWTj21vh8dDW0+Op06DXbnTt6moiKs5QMHGNFHjuAlWbAARlSThMsVuhrLaYKSFwYGuEX790PQwUpaBmJ8XPetKyjg5a2vRz9MSIAox8bYp9vN50eOwF/Jybpo3f/7fxBJqGy/YBgbwxK8+momgNhYSN+PjJVP4MILeUZbt+pMg+Zm1vexsSwr8vN5PvPn85wDWcRimRi5onDZZfS6/+53GXMZGZihTz/N76qBwMyZtChraWEMOhzyjSN3SqT4W+RR4pRvj94v3XXLRVJG2N+x/PGYGO5jqDwSj4d/Kjn0hRdoDhsXR8+F229nEfDiixMvUTVD37cPwuzr47Ply5Ek9u1jf6Oj+AHa23kdbriBy/vjH7GmZ8zgEvv6SE697TYmBrXwsNu5FV/+8qQe9TmLc5uQ29sZMf39eJbcbl00fv16hNXBQbwMaWm6o/PChboV8vXXs67bsQNynj0b5mhuZpQNDWlrOT8fEa2xkbVdSkrwNVhJCSPvb3+D/CMjGe2XXKJjmFXg7vAwpKFKeJ3uLiMBMJsx2svKIMfISPjL5Zpcfae5c/l54IAm5sxMnaVVVEQYXEsL+1eRhqr/59AQ+vKBA6FliuPBZNLzraqlZLcfK5avVhcrVujkjuJiHZCbksIzzcxktZOSAqvYbJifqgKfCM/r4YeDR0N4PDhxVQB2bCy6SnY2E/fQELNOaSnhKhYLk/P06SJJSZLsCR4TFiWDEh3bK1JyoV8xD5uNr6uEnhNBrV66u2lM0t+P9PDcc8gP6nmYzdgy3/kO99XjYbKbN49X4BOf4Jjl5dTeV2Te349T8cYbsWvULcrM5BVTRepLSohH7unBeXnbbWd8eE95nPtOPeUpT0jghRwchHBra/EsvPYaL1leHt6hNWsYqbt28bKqsptPPsnydPp0iDc1VVs3XV2MUrsdK6evj7WzWtsp2Gxs86tfwUTt7Yz48HBMjsRE/9YPyck6XKCk5EPrY1NRwSUNDHBqERGaOC+8cHK6sfJ1VVWh3Bw4gLF/991o1N3dlHNsbORFT05Gmti27eSs4kDYbJBMcTHz7fbt3MIlS45FdgSLKfZ4uGDl7E1KgslTUvii2cwMcv/9mODp6WgpF18c/CR+/nO6tgb2SXrsMcbMsmUTfAWNjTz6pUtFTCVFYqqslHrJkn6JlkWyU0wiMj49Tqx79xzzTvrjlVeIlpssKfvC4eB5HDiA/bJzJ5e7fTuvie/EGBZGUMj06TrE8aKL/LuV+O63o+Oj67o2lXD2tnA6E1AVc0R4GVJS6K75xhv+o83h4LOBAW2Rut1IEOPjyBn9/bywt9wCM9XXswxtaODz3l6i5Lu6/AM9TSYqrFx/PX9raMBkSE7WpRcXLNDltIaHOefZswkojYg4pf54pwJVfMe3ZnF+Pjw0mcPX1HBbysuZe3xvcUQEWWIrVrCYKC/npd+3T/s/TxUWC46l731Ph2h5POw7Jye4Y3NwUOSeO0al5ak3JXH8iER+9gr53sOpEt15UD+Liy8OXdgjEG43ZBuMGefP1xE3AWhoYHglJ4ssHdggDVfcIjWjWTJTWmWJbJdxc5h0fP5WmfnNTx9LvfS/mO3bsUaD9VGYDJ57jmGYm4tL5YknsFiDadKf+ARJIDU1rHi+/OXgbQWjophgVW/FE2UTnsswoiwUXC7/lK/DhzEBX3tt4pp4ZITOnb4VvlWIW0oKIzU5Gcv2tdf4TmKiDsYdHNQOuMCo+7AwSHnPHsyhoSG2nTcPvdLpxKw0mxnlDoduAbRwIdfhG453hqCKyQwOEol35ZVc8r59/g4aEYj73nt54bKzsUwrK7Vm/MwzE2+x08kSuKyM2z17NhbUZMhY1Ua22/l50UWco8PBXPjQQ3RQ7ujwDy2fOzf4S+/xsCB6+DG7bOhZKDsHZsuu/9kpV5V0yHhaJs/Laj05lhsYCG3iq+L1QaCK67e1ifxjaI2Uf/ev0muOkzyplYOSKf/qeVJW/v0H8t7/9TOLBTDl4sXsI9AxN9n8kuuuw1Z4/nkWlP39oZNy9u+HgLOyePahAkrcbh1v3tCgI2oU9u7VPgUD4NzWkF0uBm9/P2vYoSFCzrZtY6QGMoCq0L5woY6Yz8riJWtuZnRdeSXEOTgIuTY0wABpabz1jY3BzYrRURht2TLMEOUd6enhTVqzBtZbsACm6O5m7fj005g+N9/MZ74rmq4urDHfl7yzU5dfOwWoBMDCQvxGIiyjt2/nlrW2MidkZWEp+fZC++UveaH/9CdeUqUhB2LPHj1nHTzIsY63UFNF8L/wBayu2FgWODU1RGYUFqIg+EYrNjRwm4/X4/Xtt3VthRbJkHZJltLxMkluLJfKn4ksX25CsgjRTSUooqPRd33C4TxiEpN4xeRzgm73RPKcPZvJbHhY5C+7FshW08PyJ7leKmWZdEu8yLDI155YJjVrqsQyPOw3y5hMpDZfcw0ykc0GoU6fPvnEIKeTCXb3bizgUJl86elM0sXFTKZXXgmx+gYAhYdTd1nJFTNmoAKp1lrNzUgkwZoInM84ty1k1Tp32TJMqKwslnsZGaHLjeXmwj5qKs/OZsSkpmKGmM14NmJiWHO3tzNyly3TzTFD7bukxL+gz4oVjGKPh/2VlPC3qipq5K5bB+s8+SRWdHy8f4JKWRmTi3pzGhv57GRS88SfDFUGni8HqXjmmTOx4GpqKD5XWelvsI+McAotLZoMQiE2lrljxgy88L4F532RkUGZxltuYdvly3E85eSw/6Ii5kLfa8jPn9g8JRiUXu0QpxTLFjGJV7ZIiQwPizTWDjMBHtNrh4Ym3tb+/iA+W7MZrfnYc/KISbZKsVSFLxfvL+4TEYZHWRmWqC8UGatz63DHyVtyCWR8DE2jSVKXcUnQvn8zZ2J/7NvHRFVdHTpiLxRGRrA3wsIICvGd0NSC4Ytf5Gd0NM97wQICSlRD+JgYHHr33KO/qzp9iGApl5WhAhUUaNuhoeHUWnudSzi3LeTk5In5ofn5TMsNDeSm+gb8R0TgGW9v11N5VBSml29Kmir+29XFyC8tZb+HDoV2E6sOE6pyTlsb8V6qqJEvApueuVy8xd/9Lhq3CMQ9fz7m5rZtsNWePUw8vsUoTgCnEwWnsFCT4sAAc9KSJbrWkcLixVzK734XXD0ZHIQUrroKLffuuyeu4N1u7Ry0WPC0f+MbBC347jMsjP2o+U3VZpg5U5cVTUpiH6+9xrykkhwtFgIjcnM/6FAlIv6PcfZshkbY4LDES5eskE0yLlaJsQ9LrrtWpMmExJWZKYcOYc2rjDarlSFksXA+fo/wX/8VtrrjDjE3NUlcVrrs+8JPRWIWyHyXLobvGzFXX89Epzo1JSUxRDwBr+jIiMhb6y0yZ76EhGoYoEqtnCzcbu7R2rUM1RdfxKJNTmaiGxnhFXnySdwic+awqpo1i3uk8qR8F27btvF6pKZyXYcPM6wjIhhTBw4gYSjp5nzFuU3IIhOT9dVnjzyC0PnQQ8gGJSW0Qi4shFWqq/0FuEAJIDaWWNPwcN7SQ4eI5AgliEVEIL5dfDGjTtXJKC9nlKv168hI8MIFXq9/73SRY7FcAhG3tXH8ZctOKm1XGfTl5bqPZ1lZ8EtWny1ZgrGuUp59ERnJS1dRQRH5559Hkw68FEWyLhcv4yOPQPK/+hW3MjMTy3lgACN12zZIt78f6/jrX+fFdzp5gbu7sdJiYti+rIzvBqZ5b9/OI5s/HwfgbbeJHB2KlwrvMvmi/ElipVc6rZky70tLRSLMjIPISJk3L0FeeAGr0ePh/OfPh6yCaq3XXss/EckTETlWEK65WRcM9A2WCAvTizCTiZoOn/98cNngZz9jARWqrn1XF3N9Xx8RLZWV/vtR+SnqOoLhr3/FndLSwn3r6mKR5vEQBXrwIBZuY6PI97/PsZQEERbG9hUVrGCUfXPoEEN28WLIfeNGnSDb2sr1zz/ORHM+4NyWLI4Hs5mRdOQIrPLuu3rNFRU1MZsvGGJikEGUVVxQACEGmwQ8HiLiFYmqTpz5+f5vls0W+rjB2tP7ku8pVO1WmWw2G/L6hg18fryQ5+bm0B0bLBaIsq0NkpxsDsv4OPNgTQ3W05138mjS07Eo/+d/eGkHB5HWb76ZpIPnn0fSUNGMVVUQ98AAZOAbKaj0cRUJabNRN2HOHJEBS5y0mjPEPDtT/uNXCRK+Zjmrq+hoEZdLtmxBXx0aYv51uZgHJ1tD3jepxmKZ2JkkPV1kycJxMe2rFfF45NprGUZWcUm+1IqI1mSGhiY6WH3R2sqcvm8f9ykuTj8Hu5370tOD0zVwMgkLwz7o6eH6zGbGQVoaVvzXvw7BqzC5xx7Djlm/XpeDmTWL7XfsIKKmshJbIT2d16C/H/skMZFraWzkGHPm6Kpy5yvOX0I+HWhqYjSp+oPl5YhnKqlEITycIhOXXur//enTGbm+sFgwDQNJPSJC5Fvf8v+ssVHXSJw3j7fUV1OeJBwO/3pG8+aFJuOmJkgvNRWrJzeXl9pm41J+/nOs1sJC5pqLLpocKQ8Ps++6Ot18OT6e/apmKYF4+mmI+uWXsRpvvVWXG1WJkIFYsIA58eBByMJqhcCPNo3IH/42TX78mwQiA3bvhhlWrRKZOVMefHCiRDM+jsWtCu2EglqBmEzILi6Xf9cNj+fY/zs7RerqxLu1Qp74L7qPlkqZZEu9REu/3z4DS54EXmNuLsfq6mLSKCwkpfzZZ3luVVUc7r772N5i0c7ST32K7auqGAerVmHd/va3E+/B2BjP4cgR9mcy6RKgvj1bL7sMJ3Bmpk40Sk1lf6piwZtvMtmfaujeuYBzX7I4U2hpYcQmJOBu7j8WjlRXh6n5/e/jxg8PR4y7997J7/vhhyHXV1+FzUZGWCv/4Ad6G9UaJClJyxRmsw6rU5b4JDAw4C8r7NnDixjM0dbToy/ZbMYKe/11TtFs5oVMStIRGj/6EcvflpbjhzdFRbGUffllbtmaNXxeVXX8cDhFak4n/tG//pX57PBhHZEYiHnz0H9FIOSMuEFYKsoksuIiLsY3pdpu/2D7QFgskI9vkf6hIe0U9Xh4jD09zMdtbfxfRcAtWMAcareLLFyYLLJwofzP7bvkuf/bLEWucYmUIamQIukXPKQOh57zQ8HpRA5paWFCa29ncTY0BFm+8AKrC6uVekbl5Xy2ezcWckEB227cqElz7lyy8YJBNUrdsEE32x4aYhWgFn/79jFulJ2icrRUMqRKlvzSl87vbD2DkE8V06czWhct0hXWlyxhVObkkDp1qggPp9hAczPrxLlz/T1TIoi1JSWYkUqqUEG9J9HjRtUsUh2XU1LgpvJydhcf71+FbeFC/+qSJhNEs3WrrrNz9CgvaXIyp/P221jOmzbpuvx792pry2bDwZWZqc9JEXNKyuQj+NxudMuvfU3X4xDxJ2W3myW0inAcGhJJcYzLIpuNtXxUFP+Ki5mZ3G6Rzk5ZmmuTXbuixeXyP5nRUX/ds6pKpGlXr1x8TYykp0NQBw+KxEiPJCfHytAQROh2M2Fs28a9Uo6svphZ8suXXZI1hh+hQoqkQzD1LRbm5d/+Nvj19/ej27/wgp7ErFb2HRendduXXtL6+quvEg1x2WWQvMPBc7rySqSH2lqG8+c+R3q16g8YiHvv1Y1RVZ7ThRdilbe24ovu7WWhuGQJ/vSoKCz58XGev9l8flvHIgYhnzqmTdOV10WoCnfLLbp0VlYWCf3Ll5/6MdLTjx8DG4x4TzK92mZDJjWbIUnVA/Xtt7GYUlP9Cdlk8idIVXO5s5Nlrgq9qqyE0P/8ZyzoggKWx6oez1/+QnbYwAAv5Ve+gnW5ejUksWcP1tvChXSWfu65yV2PatZSVKQ7mCgcPEjtIJeLYJrOTs7/DneM/OzONfLDi3wubMYMkfnzZf+lt0hG5f/Kz80x8sJ4pfSY42Xcw2zkcLBoiddRaTLN1SXOnfXy/kC8zLkiW/btE/E2NUlaTIt4jubJ8PCMDzLiKyp0xIaSIA7sdUmGtVXk2GpiljTKUUkUr5glKwtS9NXuu7sZbsnJ3Kf33vNfUYyP8xzdbiSkjRuRB9TKYnwcS3rbNiRzEfb3298y2bz+OpOK1cpYGBwMvmKprWVxmJ/PBJ2UpBulZmQw2TY388rYbFj5O3cyac6cyXOLiZnQSP28g6Ehnw5s3Yq3o68Phhkdhd1WrMCVf5ySmR817HbmjAsvhJgrK3WWeXKyf2eqYFCFaFQiidXK/gYHsY4eeACd9ZlnSLHt6yMyIS8PEti7l8CThgaW2r4JjNOnQzgPPBDcTxoIq5UwOVUbqKgI0rvhBixL1U3ljjt0suTwMAT00ztNHxTUU+i99DqpK++SzWNLJXqkXaq8BXKd6W+SkuCSJUtIgLnzTv/vLLkkThZfNF2O7O6SLesOyaH3m2TB9BZZdfk08cTGS1cXEkJ/P/etvh6C6+kREZdLstrLxD42IFukRHbJQkmUo1IkFWIWj6Smci+PVen8oN5zbS3PTBWyC4TbrbPv2tsnOs08Hshx+XIWY2lprB7++lfd6nFsjHt2PPnI7cYpl5qqK8QpfOxjPH+VBKK6m8+aRd5TYSEWdGBEyPkGg5BPBwIDaBW8XjxGvj2GpihsNl5Ij4eX0evV3YOPB4uF7ZRmLAIxPvUUxOob3tbfD7nGxEDC4eG8wHPmsKTes4cayFYr1t7KlRDCs8/yvVDBJ+HhnMe8eVhgO3dy7JtvJvLsmWfYx003YWkHe1Tj4zgGFRm4tu2S3fvsEunpk1GxyyZZKYdktlzv/Yu8e/Fd8vbbOL9efRVr7+tfZ6lvtpgk7aI8aZVkcTYclbCuNsldMk288xdIy2GTlJRAqPv2QZIq+TIzU0S6uyXWNigJVxTJQHiiNMks2SULJU66JcExKL/4BYuiHTsgrj/8gfu6fDnP7HjPyuvVPViDwe3WtbTCwnDiBSacTpYon3uOVU9vr39tLd8goL4+/lZaynjIyICU+/rOeHWAKY3zo7jQmcaqVRNjhH0RG3vqUfofItQyWqG4eKJ0PVnY7cGdeCYTmmJyMsdqa+NF7OlB6nj3XayptWv1Oa1bB4Fv2YLU0dEBMc2YoYlj8WK00q4ulswqqjDw5VbF04OVm1DlIBctEqn4bZn0/+xhKXCWSZQMySZZKSIimXJIZq7Olve+83e56y7I3xcXX8xwKHutVy7MbZU426BEZMyQ8HlZHyTZ7Nmj46XHxrRD9AtfEDGNjcqI1y633UYEiccjMit5VH79X3a54gpI7LXXIOWNG7nm229nEZaXFzxrXwSSvf9+JAhVhiUQX/oSK4mCAu7FyWb5KahGqSppJ1iauNsdvGnq+PjkGtuebZhscaFz8NI/AnziE8evG3kWeCra2rC6YmNJWqis5J/KOj9ZhCJkqxXyTU7GKkpKgkyamnCOKWu3vx8JJTkZ69NkQqO8+mqsSbsdbXRwEHJbtAgtV+X0HD4cfHk9NhbcSRgZiTXd0UH4lSTlS4arQfbIAnGIZvUq2zJpmHW5VFaiUQfinXdETJ0dsiynW3ILI8TpjJAdZcMyve2IfOveFNm7l2szm7n2sTGOmZoKmYbZ7RIuVFt75BGGTkyM/YP2i2YzkSu1tWy/YQOrivvuYxi++eZEhcxmIwFm/nzuVShCfv55qoampkLKR46cekzwE0/oMH+VkKos+OpqrOdg7pVzkYxPBoZkcTpwyy2hC/qYTDqGawrj0CFdTsPh4GWJjj7pshgfIFgotUqFPnAAQklK4oWvrYUEVq6k6lhysn9hu/BwCHj1arKSTSaIt7MTmaKgAF36xhtJ1f72t7Eug73cFgvk7St/qK5bN93E70eOiBzojpOcf10tLbZs2SBrJEnaJM3SJgfsC6R10ZXy+uvBl/CR0i/t+/vkM58xS87FsyS2cJakzo2WpTOaJMbVIQ4H/t7oaN0i69lnkVfy8oh4UBOZzcYEaTKhEW/YALHu3atLoIyOosXefz8ZdPfcowNvVAjiN7/JamJwcGJCii9GRpj0amqQYyaj2wdDfDzjJyqKlcqATyPv6upjUScxoeWT8xnn+Xx0mhAXxxrye98jwFOEt81uZ1T/5jcf7flNAkVFvODKilGa8ikk/4kIBFFTg5LlscqKAAAf/UlEQVSj5qlly3Tp6IMHtYWck4OOrBpwpqXhfPIlhIYGfm9owDLctw9LOzaWSePdd7GIlVWsEhOC4d//ndC89evRc/PzIa3t2zmuasZZ/tkHJTnsTQn/+wYpG7xSpi3JldU3XSajkZEhnVtDEi3dZrekrI6R+oMm6eoWmT53pqRn2sQTnyDOOhyofX3cg9//XpfO7uyEUMvKSAPfuhWnl0oprqhAcgi28mht5V5ffz3PbdEiPdk5nSzgvF6uLz09eP3iOXOQYGJikF02b2ZIb94MyX7mM0x0bjeWu8OhF4UeD/fMZsNav/xyPk9M1M7V11/ns6wsI0U6FAxCPl1ISIBt7r6bmKGqKhjo1luJ65nisFgmWiz/TFlEh4NMuJoabsWiRfwbGcGqzcrSlcRU2ycRSKOnB6tK1Teor2e+Gx7mpV+wQFe53LgRMg7UTt1urGCrlX+KrG+9FXJZswbScLkg9XXrIJmcHAjTahV5+WWTlFz9ccm+6eOE4rWKuLpFrrsYrTgwKkNh5rxYKT/W1Tk8XMRkMknzYKzY3mySlZdlSHc3E8r7b4+Jo69bPB5ttg4PM1Hs2sW17tjBftLTg9c7VrBamTy3bYNMf/tbYr9tNu55QQExys3NRDX85S/awrdaOc/vflfHTV9wAc/o4YeZ8HJyeE6/+AWdx1paWE3l5VEO5o03dOjdddf5n1tiom68I4LDz0BwGE49A2cEXi8xsRYLFpvVCtls3swyNlg43cAA24WF4cDr7ub3vXshlpwc7dCLjGR/ZWUiDz4YvEHHtGkkQdx1lz4XtxvCWLmSvxcXM0GsWwdxxcbS+XhkBCu1pwdCcTjI9Rke1v1QX3iBCccXYWEkpvT3c4zCQo6x941maS4/LPNXTpfdrrkSYR2TTQ9skjffEimTFTImOr88MhJC/fKXuV/r13P8zEzO8+9/n6iP5+bSEuvll7mu73zHv2Cg1Qqhr14NcXZ1YQ0fPcoE9PnP6+prO3bwf5Wskp3NPQr1nHftwgeQmqqt/dJSXXpFyRRRUZyTKsV5PtVBNjqGGPhIYTIhBagu0qoZt8ul04x94fWyrFVlNUtKIOTyciyrWbMglexsnFqXXooT6/HHiVYIJa2sWwdpu93s1+2GSN96C3JISMACdzh0ckZlJYS8dCnncPgw56cK9bW2Yi3u2kUsclYWi6Brr6VbdmYm31VF3M1mkZyL0uXCq6eL5XCzRDbXSqlnk2Qkjcl+e6EfGYtoh5/JpOs9q0qvn/ykrqgmgmUbHY0OnZrKBPDgg/5kLAKBHzwI2a9bRxp0RQUS0N//TghdairJIV/6Ete/ezekGYqMRbD0m5qwlFV7SK9Xa8ZbtmA9Z2ZS16SoSGvKgR2uDRiShYEzBJdLJ5ZUVOCQGh/npQxWI0OV9Swv112zXnsNsi0sJApk40Y0TF+0tenkBV/YbJSwvPPOicEvY2Mc4+67Idz9+3Ud4qYmCHnTJsh0+XK+39UFMcfHY2lPm8ayPSMDa7aoCEJ/802s5uFhCG7vXizDykoRk2muXJE/Ihd01En7UbuYV62Q/r9PE/GJirBadbiYauWYkICzraqK4z7yCKT2yiusNu64Q2cLlpaGTm82mZiM1ASj0NtLhMXQEDLT0aMQ7MAAxz98OHhNEBEmB9XVu6EBh62SV5xOnRyiZAqlKff1GU69YDAI2cBph9MJeebmaq/+0BDEt3Rp6O4gMTEQ4F/+oks2FhVBHuXlE8lYIZilpZpLh0qSHByENGNidB1ir1fX9o+MhGDa2zmPTZv4+623cl3V1VjI6hyjorC6y8shpLg4LOnqaiIcxsZEBrpdMrdvRGItdqk8MF1mZR+Vt9+eJmvX6opxq1fjF3Y6sWTDwqgr4XRyLm43cshVV7FKsNu5xspKSNRshpRfemmiU9NiCZ6pp+7X+vV8T3WNycvDsRisJoiCw6HrWA0N8d1Dhzin4WEmzLlz/SNeEhM/tAbqZx0MQjZwWjEygtPn5ZchtdJSSGtgALJQ1miwkLTaWiynjg4dsjU0pAsgmUyTj4t1u4kJTkgIXjt46VL9uVpGb9nC57Nmce7PPIOFm5yM9exwsOyvr6fGhsmEBT8+zrFsNrZNT2f5/tJLWJcmk0jRojGxe/bIgcYwkbxSic7ulBzTfkmOcEp1dYHU1jI5hIVB5h4P+xkfR+s9eJAs/LExyO6ZZ7iPq1ZxjxoatD6/cCERDaOj/vfL5Tp+1IzZTKTJ5z6nZYqSEu5LoAQigiXtS6xz5zIJ1dVByl1dnItykho4MYzbZOC0obubZb4KHbNa0Tbvuguiu+QSlvM7dkCCgejooKhRRgbk88QTbOvxQFRm88npju3tZPw9+KAOFbNYINbHHoO8VKJIfT3/xsaYREZGmCDCw+WD2OGCApbgHg8/585lf9u3o+POnQv5vPEGE098POSamCgyL75dLL29siOlSGTaNBm2TZPKgxZZtvuAxGUMy7ZtDjl6FOv7E5/Q9S5cLt0Z7OKLsYjb2pigDh/mZ2Eh2x08yD0fHCQW+6GH/EPkPJ4Tpz9fdJG/ZqycsoFEfuQIVnluLuFyKqa6o8PfCo+IOH6jWQP+MAjZwGnB2BjxvU1NOgRNRQI8/jgRACrUzWKBvOPi9PeHhvhs5kzdPDMlBctPSQrbtk3+fKxWJof4eJJU9u2DKIqLcQrm5flvHxWFNd3czHlXVWE1f+xjHHv7dva5bJkOR9u5E4KMi4O0Kyogs+pqJo76eqzeiAiRJ7akS2JssiwutonLBWm6kzKk0pQsC3rCpK6Oa01LQ5v+85+RSUpL0abj4riHM2YgEZhMyBbbtkGM06bx+/79Wi45WY02NZVwt0AEs6qTk1lJ1NVBvi6Xrs0RFcWzHhxkPGzZgqVtWMknhnGLDJwWtLXhZApWS6G5GfKKiIBMKitZ7hYXQzBOJ5ae2Uxiw/r18kGsbkkJ2/T2Epr17LO6wpwI0sLs2Wzre2ybjSiPnTvRYsfGOH5urq677AvldFK1oBsaIKcbbiD0rb8fzdjpxAoeG+N39b2BAaz/rVsh6T17+Mxu5/PmZpGYGJukpSGDeL0Q5oFDYdIzxEQUE8N17NnDNop8p0/n885OJqu6OiYJVci9tZXzSkvT1VojIkKvJqKiIEfVz85kgkCffXbytadNJlYMIlr/TkjAap8zh3tXVwdJNzcHXxEZmAiDkA2cFmRkhG7VZDZDOHv2QJQFBRDw1q1aBhgf5yU+dAiyg8CQORob2eb666mRvHs3S+aCAgrrvPQSGu769ZDW3Lkss194AeeiWqYPDJAs0dJCLz1FPo2N2hHX0MB1pKdDcP39fD5vHkR94ICu1paWhhX75JNIKspSvOyyYz3ylkBKtbVYixUVaOTFxSSlVFXxr6OD609MxKpWsborVnB8ux0H2bRpSCiDg9zHrVuZ2MbHOS+Xi9XA6CjV9oJl9Kl61Nddx4TldLKKSE6G5P8ZDA8Tu7xiBRPH0qV83tNz6hmf5xuMxBADpw0//Skp076RDRYLRPvWW1h92dmQyugoerGy4i64ABJuaNBFghwOLGPV3fjIEeJw6+qw8kpLIdm77iJsy+HAog0LY/+//jWEFojISEjCZmOSaGjAan7vPT5XmYMdHZqoZ8zASbVpE0QYEwPh3HLLxCQNi4XkkIgIznndOshfddMoLuYYqppbVBQk1tMD+ZaUYGkuXoxE0tfH0j8xUUskZWWapJV17XZzzIMHKcgUzEI2mbSUUVREWODoKDp0VxeTjOp74PEgzcye7S8viTD57N7Nc8nJ0Vp3ero/sat6G8drOXU+wKj2ZuBDx3e+g7WqluRWKy/3H/+IheRbvyCQLFQEgKpzoJbSqutHbi4kVFsLgaakQOCXXgp5KWvwvvuwnH/wg+CRASLo1SoiobmZSWJgAELs6SGWePZsyElNCLW1EGdODtaoxYLzLhi8XtK5s7L8Jx11neXl6KqKyHt7iblevJhzystjH42NulPHe++xz4EBzuHaa7knhw4xwRQWYpVu30494lByhderj7t9O5PLBRegRavSqEp7r6jQkRSBhNzWxvmpWhuqtGhjI9tHR/OZ2WyQ8cnAIGQDpwUjI7zg99yD5bl5My//VVdNLOXhdPJ3sxkrrboaYlCasohe4hYW8rOzEwvuxz/W1q2qBudroY6OohtXV2OtBWtOOnMmlnN/P4SSm0skxi9+wTkPD0MiYWEU/ykpwaH2j39gufsuKoNFLSir0GwO3cEj2HeOHoUcbTZI7tAh/v/222TTqUln1y506Z//HL22txdCDQ/n3ubnUzj/RBgdhej/8z9xBmZm8hxUh2zVCSZYF7GUFO7LoUM8y+XLmQhjY3UyyEUXTV6TNgAMZcfAaUFnJy94aSlW609/inzQ1TWxSHxNDUSlYpRLS1lqV1UFJ7jOTizK++4jUmJkRGeRBSO88XGy5668cqJn324nuUNB1cB48knITJ3r8DB/++//xuobHNQdMOLi0IDz80Nro42NEOfJ1BN2OrGQTSasy5wcymD+6U8T9eDxcW3JR0YiaTidWPE33zz5Y6qol7lzmYRKSvjc62VS8O0EE4jEREjYZoPE29uRk0ZHsfYNMj55GBaygdMCpT36OvZyc4M7+woLITxVfMZuh5SDJS643Vh/AwPIC5NtI9TTg+NuzRodjpWSgsNNBDkhNhar/s03g9d99niYCJ56itoPHR0Q5tq1ENi8eZzbm29OPC+3G4JSHaYng9mzkWuUU/HIEc49VBeQqiruZV2dnpicTiaOjAxI+niIjKSGtO/1+lawO3JEF3MKBYcD/fudd3S3mVWrdF0QAycHg5ANnDYEi7II9pnNNrHSl90efFuLBSmjvl6Xkpws3G6I9nOfw+K89FJIRtUXVnj//dDWXF8fMowi1c5O5I2wMM7ryiuJuqiunvjdkRGW7eXlWJwjI8gKSUna0lcID6eoz+LFELPS0y2W0FZ4RgZOSbudaJTERFYfbW0i995Lckh/P+eunIrK4RkZSVW7T3+afXk8WjMuLCTqQkXCFBcfn5QD751hGZ86DEI2MOURG0st5VAdQBwOXWs3EM3NkHBxMfHDAwPaASWCnnzFFWigmzZNtHSDWeRuNyT9ox+hQa9ahQYbaMmaTBz3q19lYnC72TY+HkfnP/7BuWVnE652+eX8XwSJQq0gbr6ZzEJfJ2VYGATe34+00d9PZMXu3ZD7l7+M7vzmm5D/JZewCnn2WVYLl19OeVBFnh4PVrbqHi7C9uXloS10ESYV5Q9YvBiHbnk59zNUzRIDoWEQsoGzAlYrJSJvuAELz+2GiGNiCLX7t38LHnc7fTrb2O2QZmCGnojWlWtq0LwnA6+XDMTaWuKNn3oq+DZuNyQbHc2k0t9PWNpXvkIn7ffeo/1UeDhSgwon27kTiz4lBWfj4CAkPj7OhPKFL0CmUVFc96WX6kmpv1/kd7/Dev7mN/msoICVwe23h76/K1b4W7dhYRQ7Op7Fu2sXz2P5cibO2FgIevt2w6l3KjDikA2cVaiuFnn0USzfFSt0Dd5nniERxDcG2mxGM165EkdcUZFOVvCF1wsZV1fTsy9UuFwgrFaOe9VVRCgcPTpxm+hoZI5t29BjRbRWvH078dlPPEE0iMWCU23WLM73Jz9BhlAF4Bcv5lrj4pBw3nhDh9E9//xEB6fNxv4dDmSMgoKJWYovvUTkSnMz9/LOO4l9bm5molGRIqHSnlVVN19reHiY81IWvgEjDtnAOQi3G+fho49CfqqGw9KlWIoREcTg9vfz+3XXQbBHjkCK3d1YjQ6Hlga8Xj6LjoYMJ+s0FIHwGhuxXPv6gm/jdGLBRkZCyF4v57FtG5byAw/wu7q+sjImhvvuIyb4yBHIMS+Pa1fIzYVk33jDP6bZF3Y7Es2qVRxv927CClXK9VtvkY6utOzKSpFrrsHR96Uv6aL+mzfjZAzWeimY9u9wGLHHpwqDkA1MeXi9aLYPPID1FRuLLnvZZboVkNJDr74aLTg+nigIpe/u2oWjanRUxyZnZelsM5WQctVVaLu+oXqhyn5Om8aSft8+bfEGIjYWx9jgIKT9/e9DwCYTVqXT6b9vr5dzDAvDWSgCEebn+++3pYVIkuhoyLKpKbj+nZmJlbt0KXKMImMRziVY8f7nnkO3drsh49FRXQDfwJmFEYdsYMrjnnvQUVU5yqNHSYtubdXRGirqISaGJfeaNXy+dSvW5eWXs2RfsgRHXk0NyR6NjUgIvb0Q95//jJ4cEQFpLluGJOBbZN1iQTr485+xqleu5BwDLcXwcOKIq6s5r5tvxqpVNY3b2yfGaItAkq+84v97by969fAw92H7dog9NxeLNli89ZIlOprEbCZSwjcEL7AfoEJvL07IN9/k2CUlEzP1DJwZGIRsYErD7cYyDtR1h4fJVBNBCvjWt7Byb7wRki0qImKgo4PluoqsUN0went1evb8+UgKW7ZgPd9zD/Un/vY3rOW0NCaE22/HKr/6amoNx8VB4jU1RCa8+iqkr+on3347tS6uvppzCCYrhMILL0C4s2djySYlcU0JCUg2NhskP38+Ds2nntKtn8LCOM/bb/dv59TWRrzw0BC/p6QEP3ZUlHbGRUUZZPxhwpAsDExpDA0FtyJFWKb39WEJtrfr8Kw776TexBNPQCy+lqvXC/Hu34+ckJ2tOyJ3d1Mdbv9+LMrVq3GqHTqE9nr33TrM6/Bh5I6YGMhYJYrs2KGtW7OZScFkYvtQ1xEMHg/SQUUFcdJjYzqK5O67Kaj0qU/phrH/8i9Y88PDuhaGKiWq+gJWVuqIExGchv/+7/7nZbdj8dfX68JGe/boDtQGziyMKAsDUxpeL9pvsAiG4mKSPn7yk4lkFx4OsaanIxm88w4EnJvLvsLD+U5vLz9NJtoNHT2qkyjmz9eOLK8XUnW5IMudO7WVuno1zrcZMyD3ujp9HosWcQ4vvijyxS9OjJe2WkNbzqmpTBLBiHzOHGJ+j4fhYUhZrS5iYyFnJW94vZD7L38J2YeFiXz2s4SrJSYSu7x/P+SsOoMYODUYURYGzgmYTMQZ33KLv2zhcPD5r34VnLDCwrAI77yTpqmqILzJRBr0Jz+JPLF7N86u1FRdECgsDL22rY3v5eUR6fDOO1iktbVY5Pn5OkuvoQGibm3F0VhQgHVbWQmhXXEFhFZdrc/XasW6bmwMnl6dkaFD5QIRrE9gIFQDUpVFOGeOv9ZsMjGZ/ed/4iCMieFc4uIgb5MJq99i0c1qDZxZGBqygSmPr3yF2sHz5iEtlJQgC6xZg1YbLEbW7ca6++tfIcCREd0w9bbb+LvSkDMzdVeQ4mKSLFavhqDXr4eI33oLcuzrw+EXFYVkUlZGLHJkJMTlcuk+fYsWQeq1tUwm774r8h//gcWcnk7B/fvvJ4MwLMz//CMiRH72s+DRDSYTlu6J0NaGvh0ejjVfWemvKSuoMqk2GxNOXJx/Qkd+Pgk2Bs48DMnCwFkLJR2sWuVvJVutkHdKCt2XAzFtGll/djsRF7GxOORyciBjs1lnzO3Zw/ZKOnnjDUhydBSCTk3l2PPm8Xl8PCQYFwc5DwwwgajuzOPjIhs26JA1sxmSf+opymx6vZDfww9D2M89Rxq0Wh2YzZD1xo26NGkwHD2qC+kvX865bNgA0a5cqZ2co6OhO70YOH2YrGRhWMgGzko89hgkt3w5lun06SzR7Xas2zfeCJ5KrXDgAGS8ZAlW9hVX6NZRIhBXXJwmro4OSO7jH8eara/XCR0qnthqZV9z5vC3gQEiIxQZi7CdywVxX3ABVn5ysshNN2HRNzWhR19/Pdtfdx2RHpdcgiV/7bU4JY9HxiLcj9RUrRn39LBKsNt1F+j6eqz/UHVADHz4MDRkA2cd/vAHQsGU1ehyQTI//CG1G1RlshtvxEpUYV4KZjNWZ3KyXprPng35KomgpYWIiYQEog1efBF5IiYGCeKllzhuQwOkPmsWpD4+DqEq7NkD0ZaUQIaRkUgIqqOKzcbfqqt1iyYFlbJ8wQVY+haL/mx8nOswmzlefDznO3culndXF/+vrETPjo9nJeB0Qs59fVjyM2dyTgper1F/4qOEIVkY+EjgdtO2qLIS59VnP+ufRXY8ZGRoS9YXSUmEqD39NDHE0dFk0e3frwksLEzkf/+XRJHjobpaW7gWC+f7y19SyF5VbhOBHNPSkBiystBo1fecTrIGOzqI4Fi5EiKsqID8VZZhMLhchLvNnAmBqnjpLVu4/vZ2JqGsLOSLuDgmHq+XSePwYSSdiAis5Lg45ImyMl2UX60QTCYSTW65hQksKkrkG98gAiNQ2zZwajCiLAxMWQwO4sjav5//R0Zi8b7/vm4wejy0tgb/vL0dPXnvXv+IDGXxqZjkwDRkBZdLE6Tq6+d2Q8iHDyMD+JKxiLaIt2/Hkm5pmShTbNmChKF68E2ffnwyFoHoZ8zAEehysb+tW7Hk330XB+TnP4/VO38+E0hsLFbvxo1Y/7Nn+2fZ2e1MWoqQMzK4J/X1PI/AanGNjThFDXx4MDRkAx867r0X4lAEMDQEYX3xi5P7frASmiLICyqiwRdqEeh2Q0Y/+tHE79bVQXS+362pYZJwuSCv1tbgxeJHR9FiN29G2/UlY1Wk3rcg/pIlxydjEYiyoAAL+OhRnJednVpnXrRIFxtSdTh6erBuExN1sopvlEZ9Pdq5KjBUUaEL7gfWtBgeRpYJthIxcOZgELKBDx1/+tNEAlBV10LF3frigQcmVhOLiMAiDNSLA+HxIJX4KnV9fUgN4+OQ6tAQ59LQgKVps0FkIljLgbBasUI7OiBO5ezbsweir6sjYUShstK/TGgoqIiIrCwmgpYWzjMxUdfqUFAlLw8d4jq8Xsi7v5+/t7RozXj5ckqXRkRgdYdK67bb/ZNcDJx5GIRs4EPHP+s0uvJKdODFi5E7Fi5kab14ceh2R75wOHCAeb2QcVkZP5cuhZjeeQcyzs4mnE0E6/qTn/TvNqJgNlNX46tfheTKyyk839CAntvby/cuuwwidDo55olIWXXnTkiAWFUpz/R0rFslnVRXo5X39SFJJCbqWOKyMr6blMTKQmnGqo9hTg7XHSyWe3Q09GrEwJmBQcgGPnTceCORBr5QqcvH693mi8suQ7cdHKQx51VX4Yg6UUxtRATbHT6MRLF5s+6WkZDgX1Tdt5h7fj5JI+++Sxqxqvk7bRoWf2Eh11RaClH29UHGBQWQo9KM4+PRdcPDg1vbCqoO8fg4CR7Tp3OMsDCkk7Y2LNueHqzvzEws6U9/mmP19PC73c6qwGbjGnwnQ7sdwv3e9yY+D4eDWhm+NZgNnHkYURYGPnQ4neiqNTUstRW5bdz4z1tkf/gDBXOsVohIFRwKD8fi+9rXRH7zG8hcOQcvvhhLW8kUCQlYtYqoVdyuQm0t5zo4CBGmp+NQy8jgb6ressWiIxxOBfv36/C0tDTO8913kUasVog3ORnyjY31D1nr7ua4kw1j27GD+1ZerqMsfv5zI8ridGGyURYGIRv4SODxkJlWUUEM7zXXnL4uE4ODLNWjo4l4OHQIR9j8+ZCtkikUWaemQrp1dVqm6O/X1vOFF2onXHc3VeQsFiz9oSGy/FwunGguF5ZpdjbHGB7+50i5vR3H2/z5HCsigolkYIAElMHByYcLGvjoYBCyAQNBoMhYWb/19RDq4sVMDHl5EF9VFfrqwIBu9ySC1PHee/w/NRUyrKxEppg9G2tZRVSMjHCstLTg7Y9OBsPDpD6npOiSnh0dOOXmzPE/RwNTD0YcsgEDQRAoRcyaRRjYzp3EEQ8NYRl7PFjsviFsIpDwNddA7Fu28LOkBFK0WPydY+HhpHGHahB6MlBF7/fv1+ehkjjS0/23VaU0feEbY21g6sIgZAPnFWbNgswUSUZHUy9i40b+iUBmK1YEj6gQwRnmW5+5r49Ii2DEezrIWEEltOzfT3ywyvbzJd+eHnTgwkJC3ERwAO7YgVPS6I03tWFEWRg47xBIktHRSBYKhYWhyVhEO/+ys7GOBwb8NekzCV8tOjJyotU7bRrXo5yWKhojKso/gsTA1IRByAbOe6hEEIXdu0MnmAwN4SBUzr/ERByHAwP+RYXOBJRmHB2NXt3Whtbt6wayWpkkYmMh4ooKtl++3JAszgYYkoWB8xq+mvGaNZBbWRmfrVjhXwlNhN8vvND/c5U5F7jt6cTwMOQaFaVlCptN9/8zm3EmmkyQcnw8unh6OjKNQcZnBwxCNnDeIyyMDDYlU5SWQmahEIx4zyQZi+DUW7gQ8leacX4+n4+OEv88Nob0cuAAXbNVfPeuXZC00pQNTF0YhGzgvIayeH0RHU0N4qmGYFlzGRn8NJmoctfSwmQSFSWydi0/t2xBUw4LI6LEwNSFoSEbMHAOICeH6BGvF7li7VpSt5WmnJWFrmxgasMgZAMGzgH09+P0M5uxmg8e1M4+1WPweLUzDEwNGJKFAQNnOfr7cUSazdS7OHIE+UIETdloyXT2wCBkAwbOcvT2Yv2WlqKJ5+TweVMTjj6jq/TZA4OQDRg4y5GRQQSFb8JLTg6xyoZMcXbB0JANGDgHECxF2yDjsw8GIRswYMDAFIFByAYMGDAwRWAQsgEDBgxMERiEbMCAAQNTBAYhGzBgwMAUgUHIBgwYMDBFYBCyAQMGDEwRGIRswIABA1MEBiEbMGDAwBSBQcgGDBgwMEVgELIBAwYMTBEYhGzAgAEDUwQGIRswYMDAFIFByAYMGDAwRWDyqj4vk9nYZOoQkcYzdzoGDBgwcE5iltfrTTjRRidFyAYMGDBg4MzBkCwMGDBgYIrAIGQDBgwYmCIwCNmAAQMGpggMQjZgwICBKQKDkA0YMGBgisAgZAMGDBiYIjAI2YABAwamCAxCNmDAgIEpAoOQDRgwYGCK4P8DuRR/81tRX9MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###########################################################################################\n",
    "# Author: Pr Fabien MOUTARDE, Center for Robotics, MINES ParisTech, PSL Research University\n",
    "###########################################################################################\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# Create artificial dataset (classification problem within 2 classes within R^2 input space)\n",
    "X, y = make_moons(n_samples=900, noise=0.2, random_state=0)\n",
    "print (y)\n",
    "# Preprocess dataset, and split into training and test part\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7)\n",
    "\n",
    "# Encode class labels as binary vector (with exactly ONE bit set to 1, and all others to 0)\n",
    "Y_train_OneHot = np.eye(2)[y_train]\n",
    "Y_test_OneHot = np.eye(2)[y_test]\n",
    "\n",
    "# Print beginning of training dataset (for verification)\n",
    "print(\"Number of training examples = \", y_train.size)\n",
    "print()\n",
    "print(\"  first \", round(y_train.size/10), \"training examples\" )\n",
    "print(\"[  Input_features  ]     [Target_output]\")\n",
    "for i in range( int(round(y_train.size/10) )):\n",
    "    print( X_train[i], Y_train_OneHot[i])\n",
    "\n",
    "# Plot training+testing dataset\n",
    "################################\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "# Plot the training points...\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "#   ...and testing points\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], marker='x', c=y_test, cmap=cm_bright, alpha=0.3)\n",
    "\n",
    "# Define limits/scale of plot axis\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "# Actually render the plot\n",
    "print()\n",
    "print(\"PLOT OF TRAINING EXAMPLES AND TEST DATASET\")\n",
    "print(\"Datasets: circles=training, light-crosses=test [and red=class_1, blue=class_2]\")\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building, training and evaluating a simple Neural Network classifier (Multi Layer Perceptron, MLP)**\n",
    "\n",
    "The SciKit-learn class for MLP is **MLPClassifier**.\n",
    "Please first read the [*MLPClassifier documentation*](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifierMLPClassifier); to understand all parameters of the constructor.\n",
    "You can then begin by running the code block below, in which an initial set of parameter values has been chosen.\n",
    "** YOU MAY NEED TO CHANGE AT LEAST THE NUMBER OF HIDDEN NEURONS IN ORDER TO BE ABLE TO LEARN A CORRECT CLASSIFIER**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.001, batch_size=4, beta_1=0.8,\n       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n       hidden_layer_sizes=(10, 10), learning_rate='adaptive',\n       learning_rate_init=0.003, max_iter=100, momentum=0.8,\n       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n       random_state=11, shuffle=True, solver='adam', tol=1e-07,\n       validation_fraction=0.2, verbose=True, warm_start=False)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-81a4374cd36d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Train the MLP classifier on training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_OneHot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'here'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#########################################################\n",
    "# Create and parametrize a MLP neural network classifier\n",
    "#########################################################\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(10,10), activation='relu', solver='adam', \n",
    "                    alpha=0.001, batch_size=4, learning_rate='adaptive', learning_rate_init=0.003, \n",
    "                    power_t=0.5, max_iter=100, shuffle=True, random_state=11, tol=0.0000001, \n",
    "                    verbose=True, warm_start=False, momentum=0.8, nesterovs_momentum=True, \n",
    "                    early_stopping=False, validation_fraction=0.2, \n",
    "                    beta_1=0.8, beta_2=0.999, epsilon=1e-08)\n",
    "print(clf)\n",
    "\n",
    "# Train the MLP classifier on training dataset\n",
    "clf.fit(X_train, Y_train_OneHot)\n",
    "print()\n",
    "print ('here')\n",
    "# Evaluate acuracy on test data\n",
    "score = clf.score(X_test,Y_test_OneHot)\n",
    "print(\"Acuracy (on test set) = \", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the learnt boundary between classes in (2D) input space**\n",
    "\n",
    "** THIS SHOULD HELP YOU UNDERSTAND WHAT HAPPENS IF THERE ARE NOT ENOUGH HIDDEN NEURONS**\n",
    "\n",
    "Optional: add code that visualises on the same plot the straight lines corresponding to each hidden neuron (you will need to dig into MLPClassifier documentation to find the 2 input weights and the bias of each hidden neuron). YOU SHOULD NOTICE THAT THE CLASSIFICATION BOUNDARY IS SOME INTERPOLATION BETWEEN THOSE STRAIGHT LINES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "#   point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "h = .02  # Step size in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "# Compute class probabilities for each mesh point\n",
    "Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "# and testing points\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], marker='x', c=y_test, cmap=cm_bright, alpha=0.3)\n",
    "\n",
    "# Axis ranges \n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "# Print acuracy on plot\n",
    "plt.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                size=15, horizontalalignment='right')\n",
    "\n",
    "# Actually plot\n",
    "plt.ioff()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, **check, by changing MLPClassifier parameters above and then rerunning training+eval+plot, the impact of main learning hyper-parameters:**\n",
    "- **number of neurons on hidden layer**: if too small, an acceptable boundary cannot be obtained\n",
    "- **number of iterations**: if too small, the training does not finish to converge; if too large, overfitting may occur\n",
    "- **learning_rate, momentum, and solver**\n",
    "- **impact of L2 weight regularization term (alpha)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### **Finally, use grid-search and cross-validation to find optimal set of learning hyper-parameters (see code below).**\n",
    "\n",
    "**Because the values of learning hyper-parameters can DRASTICALLY change the outcome of training, it is ESSENTIAL THAT YOU ALWAYS MAKE SURE TO USE OPTIMAL VALUES FOR THE ALGORITHM HYPER-PARAMETERS. And this ABSOLUTELY NEEDS TO BE DONE USING \"VALIDATION\", either with a validation set separate from the training set, or using cross-validation. CROSS-VALIDATION is the MOST ROBUST WAY OF FINDING OPTIMIZED HYPER-PARAMETRS VALUES, and the GridSearchCV function of SciKit-Learn makes this rather straightforward.**\n",
    "\n",
    "**WARNING:** GridSearchCV launches many successive training sessions, so **can be rather long to execute if you compare too many combinations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_train_OneHot' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4ad8cff53e50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m        param_grid, cv=3, scoring='%s_macro' % score)\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_OneHot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters set found on development set:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_train_OneHot' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp = MLPRegressor(random_state=0)\n",
    "mlp.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. WORK ON A REALISTIC DATASET:  A SIMPLIFIED HANDWRITTEN DIGITS DATASET\n",
    "\n",
    "**Please FIRST READ the [*Digits DATASET DESCRIPTION*](http://scikit-learn.org/stable/auto_examples/datasets/plot_digits_last_image.html#sphx-glr-auto-examples-datasets-plot-digits-last-image-py).**\n",
    "In this classification problem, there are 10 classes, with a total of 1797 examples (each one being a 64D vector corresponding to an 8x8 pixmap). \n",
    "\n",
    "**Assignment #1: find out what learning hyper-parameters should be modified in order to obtain a satisfying MLP digits classifier**\n",
    "\n",
    "**Assignment #2: modify the code below to use cross-validation and find best training hyper-parameters and MLP classifier you can for this handwritten digits classification task.**\n",
    "\n",
    "**Assignment #3: plot the first layer of weights as images (see explanations and example code at http://scikit-learn.org/stable/auto_examples/neural_networks/plot_mnist_filters.html)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number_of-examples =  1797\n\n Plot of first example\nCLOSE PLOT WINDOW TO CONTINUE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size=4, beta_1=0.9,\n       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n       hidden_layer_sizes=(100,), learning_rate='constant',\n       learning_rate_init=0.01, max_iter=9, momentum=0.8,\n       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n       random_state=11, shuffle=True, solver='adam', tol=1e-05,\n       validation_fraction=0.1, verbose=True, warm_start=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.60245669\nIteration 2, loss = 1.91282255\nIteration 3, loss = 1.56894408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.38931224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 1.23724866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.12925272\nIteration 7, loss = 1.05757699\nIteration 8, loss = 0.93233232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.82826293\nIteration 10, loss = 0.77296109\nIteration 11, loss = 0.72955845\nIteration 12, loss = 0.68255663\nIteration 13, loss = 0.67662542\nIteration 14, loss = 0.64930542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15, loss = 0.60087464\nIteration 16, loss = 0.57953023\nIteration 17, loss = 0.57531636\nIteration 18, loss = 0.55561014\nIteration 19, loss = 0.52538684\nIteration 20, loss = 0.50759061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21, loss = 0.47210162\nIteration 22, loss = 0.45006489\nIteration 23, loss = 0.42632562\nIteration 24, loss = 0.41497385\nIteration 25, loss = 0.42646829\nIteration 26, loss = 0.39783063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, loss = 0.38049660\nIteration 28, loss = 0.37316252\nIteration 29, loss = 0.38870030\nIteration 30, loss = 0.35568552\nIteration 31, loss = 0.36141007\nIteration 32, loss = 0.33759916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33, loss = 0.34521178\nIteration 34, loss = 0.38053737\nIteration 35, loss = 0.33090776\nIteration 36, loss = 0.30507417\nIteration 37, loss = 0.31713021\nIteration 38, loss = 0.29534978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39, loss = 0.30995652\nIteration 40, loss = 0.31147022\nIteration 41, loss = 0.30085968\nIteration 42, loss = 0.28706768\nIteration 43, loss = 0.30624299\nIteration 44, loss = 0.27105256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45, loss = 0.31466281\nIteration 46, loss = 0.27916413\nIteration 47, loss = 0.28614175\nIteration 48, loss = 0.27177687\nIteration 49, loss = 0.26917394\nIteration 50, loss = 0.24666177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.58793954\nIteration 2, loss = 1.82743832\nIteration 3, loss = 1.59096569\nIteration 4, loss = 1.45004459\nIteration 5, loss = 1.34910144\nIteration 6, loss = 1.28114558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.25066898\nIteration 8, loss = 1.19814203\nIteration 9, loss = 1.16135246\nIteration 10, loss = 1.08957136\nIteration 11, loss = 1.03766446\nIteration 12, loss = 0.99675803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 0.96167176\nIteration 14, loss = 0.91014208\nIteration 15, loss = 0.86330666\nIteration 16, loss = 0.82615413\nIteration 17, loss = 0.78488877\nIteration 18, loss = 0.75672856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 0.73970986\nIteration 20, loss = 0.68557741\nIteration 21, loss = 0.66743104\nIteration 22, loss = 0.65088454\nIteration 23, loss = 0.62550409\nIteration 24, loss = 0.59345725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25, loss = 0.61581389\nIteration 26, loss = 0.57511610\nIteration 27, loss = 0.60454010\nIteration 28, loss = 0.58029093\nIteration 29, loss = 0.55161795\nIteration 30, loss = 0.54185358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31, loss = 0.50783475\nIteration 32, loss = 0.53501058\nIteration 33, loss = 0.52843692\nIteration 34, loss = 0.52378368\nIteration 35, loss = 0.50624157\nIteration 36, loss = 0.51810350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 37, loss = 0.52886371\nIteration 38, loss = 0.52265997\nIteration 39, loss = 0.49855609\nIteration 40, loss = 0.51432216\nIteration 41, loss = 0.48674705\nIteration 42, loss = 0.48153983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43, loss = 0.47046772\nIteration 44, loss = 0.50041356\nIteration 45, loss = 0.47419660\nIteration 46, loss = 0.46960825\nIteration 47, loss = 0.45511665\nIteration 48, loss = 0.47008843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 49, loss = 0.45187837\nIteration 50, loss = 0.46371752\nIteration 1, loss = 2.73507141\nIteration 2, loss = 2.14691012\nIteration 3, loss = 1.98259582\nIteration 4, loss = 1.76971636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 1.67562640\nIteration 6, loss = 1.60792674\nIteration 7, loss = 1.52106660\nIteration 8, loss = 1.46686917\nIteration 9, loss = 1.42550943\nIteration 10, loss = 1.37914926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 1.33845552\nIteration 12, loss = 1.28510262\nIteration 13, loss = 1.22641936\nIteration 14, loss = 1.16812194\nIteration 15, loss = 1.13266255\nIteration 16, loss = 1.11113149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, loss = 1.08591517\nIteration 18, loss = 1.05264707\nIteration 19, loss = 1.01123192\nIteration 20, loss = 1.00959764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21, loss = 1.01326665\nIteration 22, loss = 0.97561207\nIteration 23, loss = 0.96901634\nIteration 24, loss = 0.94402696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25, loss = 0.97534165\nIteration 26, loss = 0.92804396\nIteration 27, loss = 0.91991732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28, loss = 0.91208931\nIteration 29, loss = 0.91300208\nIteration 30, loss = 0.89989057\nIteration 31, loss = 0.89703898\nIteration 32, loss = 0.90969859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33, loss = 0.87338320\nIteration 34, loss = 0.87594097\nIteration 35, loss = 0.85147384\nIteration 36, loss = 0.84617164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 37, loss = 0.83290257\nIteration 38, loss = 0.86309921\nIteration 39, loss = 0.82502687\nIteration 40, loss = 0.79846572\nIteration 41, loss = 0.81024263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 42, loss = 0.80412068\nIteration 43, loss = 0.78900182\nIteration 44, loss = 0.77699566\nIteration 45, loss = 0.78026256\nIteration 46, loss = 0.78152797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 47, loss = 0.79702446\nIteration 48, loss = 0.76233301\nIteration 49, loss = 0.78560771\nIteration 50, loss = 0.75917561\nIteration 1, loss = 2.28054766\nIteration 2, loss = 2.04248352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.96121029\nIteration 4, loss = 1.93301868\nIteration 5, loss = 1.89054109\nIteration 6, loss = 1.86087276\nIteration 7, loss = 1.89101810\nIteration 8, loss = 1.86124124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 1.84021949\nIteration 10, loss = 1.83205532\nIteration 11, loss = 1.83500885\nIteration 12, loss = 1.81013217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 1.77365635\nIteration 14, loss = 1.69820068\nIteration 15, loss = 1.67284849\nIteration 16, loss = 1.66463265\nIteration 17, loss = 1.68222723\nIteration 18, loss = 1.66011795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 1.68437440\nIteration 20, loss = 1.64139083\nIteration 21, loss = 1.61554423\nIteration 22, loss = 1.61738598\nIteration 23, loss = 1.64962129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24, loss = 1.58051544\nIteration 25, loss = 1.59110506\nIteration 26, loss = 1.60636942\nIteration 27, loss = 1.60093289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28, loss = 1.63202977\nIteration 29, loss = 1.58916147\nIteration 30, loss = 1.57312170\nIteration 31, loss = 1.58331950\nIteration 32, loss = 1.58518138\nIteration 33, loss = 1.55054783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34, loss = 1.53598479\nIteration 35, loss = 1.54301174\nIteration 36, loss = 1.56744005\nIteration 37, loss = 1.59909353\nIteration 38, loss = 1.50943193\nIteration 39, loss = 1.54696607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40, loss = 1.57121144\nIteration 41, loss = 1.53016516\nIteration 42, loss = 1.52495729\nIteration 43, loss = 1.60304463\nIteration 44, loss = 1.51923775\nIteration 45, loss = 1.57610010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 46, loss = 1.50175879\nIteration 47, loss = 1.55344684\nIteration 48, loss = 1.52688559\nIteration 49, loss = 1.50126745\nIteration 50, loss = 1.49934593\nIteration 1, loss = 2.34274244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 2.07139158\nIteration 3, loss = 1.99829488\nIteration 4, loss = 1.92447278\nIteration 5, loss = 1.90893065\nIteration 6, loss = 1.86245890\nIteration 7, loss = 1.85331971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 1.83857525\nIteration 9, loss = 1.80399185\nIteration 10, loss = 1.79422954\nIteration 11, loss = 1.78167085\nIteration 12, loss = 1.84176808\nIteration 13, loss = 1.78254921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 1.81051624\nIteration 15, loss = 1.72840573\nIteration 16, loss = 1.74693940\nIteration 17, loss = 1.72409310\nIteration 18, loss = 1.69673739\nIteration 19, loss = 1.70776551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, loss = 1.68900063\nIteration 21, loss = 1.67460100\nIteration 22, loss = 1.66317396\nIteration 23, loss = 1.67959897\nIteration 24, loss = 1.62937847\nIteration 25, loss = 1.66378308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26, loss = 1.60496717\nIteration 27, loss = 1.66483256\nIteration 28, loss = 1.62302035\nIteration 29, loss = 1.62924357\nIteration 30, loss = 1.65198976\nIteration 31, loss = 1.60397101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32, loss = 1.61622436\nIteration 33, loss = 1.61569588\nIteration 34, loss = 1.62391128\nIteration 35, loss = 1.59223288\nIteration 36, loss = 1.61015994\nIteration 37, loss = 1.62519734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38, loss = 1.59876434\nIteration 39, loss = 1.63626386\nIteration 40, loss = 1.58861687\nIteration 41, loss = 1.59413404\nIteration 42, loss = 1.65131713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43, loss = 1.66090375\nIteration 44, loss = 1.58690741\nIteration 45, loss = 1.60809781\nIteration 46, loss = 1.59848656\nIteration 47, loss = 1.69224910\nIteration 48, loss = 1.56950623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 49, loss = 1.58559552\nIteration 50, loss = 1.57031506\nIteration 1, loss = 2.44328684\nIteration 2, loss = 2.29533606\nIteration 3, loss = 2.09136296\nIteration 4, loss = 2.02607031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 2.00948585\nIteration 6, loss = 1.99855648\nIteration 7, loss = 1.96568577\nIteration 8, loss = 1.95249413\nIteration 9, loss = 1.87407759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.88054043\nIteration 11, loss = 1.82057660\nIteration 12, loss = 1.77544036\nIteration 13, loss = 1.75353825\nIteration 14, loss = 1.71175075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15, loss = 1.73250476\nIteration 16, loss = 1.72579002\nIteration 17, loss = 1.71205707\nIteration 18, loss = 1.64909341\nIteration 19, loss = 1.63133731\nIteration 20, loss = 1.61893353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21, loss = 1.61786806\nIteration 22, loss = 1.61402758\nIteration 23, loss = 1.59451423\nIteration 24, loss = 1.62304805\nIteration 25, loss = 1.61466514\nIteration 26, loss = 1.62683174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, loss = 1.61398680\nIteration 28, loss = 1.61379128\nIteration 29, loss = 1.55745222\nIteration 30, loss = 1.60847411\nIteration 31, loss = 1.60584890\nIteration 32, loss = 1.58778017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33, loss = 1.58590606\nIteration 34, loss = 1.63229280\nIteration 35, loss = 1.61429473\nIteration 36, loss = 1.58089700\nIteration 37, loss = 1.57688049\nIteration 38, loss = 1.59924292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39, loss = 1.56713157\nIteration 40, loss = 1.60813631\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.35110678\nIteration 2, loss = 2.31572119\nIteration 3, loss = 2.31563606\nIteration 4, loss = 2.31723993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 2.31893187\nIteration 6, loss = 2.31766428\nIteration 7, loss = 2.31458235\nIteration 8, loss = 2.31824280\nIteration 9, loss = 2.31809328\nIteration 10, loss = 2.31779043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 2.31628393\nIteration 12, loss = 2.31849384\nIteration 13, loss = 2.31781567\nIteration 14, loss = 2.31941289\nIteration 15, loss = 2.31561699\nIteration 16, loss = 2.31596307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, loss = 2.32092775\nIteration 18, loss = 2.31700920\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.34785634\nIteration 2, loss = 2.31691026\nIteration 3, loss = 2.31569894\nIteration 4, loss = 2.31422791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 2.31861135\nIteration 6, loss = 2.31917230\nIteration 7, loss = 2.31617953\nIteration 8, loss = 2.31709171\nIteration 9, loss = 2.31882304\nIteration 10, loss = 2.31283816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 2.31489015\nIteration 12, loss = 2.31968938\nIteration 13, loss = 2.31719132\nIteration 14, loss = 2.31653678\nIteration 15, loss = 2.32202494\nIteration 16, loss = 2.31950141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, loss = 2.31385457\nIteration 18, loss = 2.31854488\nIteration 19, loss = 2.31827880\nIteration 20, loss = 2.31741785\nIteration 21, loss = 2.31923141\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.40499104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 2.31925425\nIteration 3, loss = 2.31646351\nIteration 4, loss = 2.31803392\nIteration 5, loss = 2.31721639\nIteration 6, loss = 2.31642317\nIteration 7, loss = 2.31492006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 2.32036882\nIteration 9, loss = 2.31450163\nIteration 10, loss = 2.32128175\nIteration 11, loss = 2.31502443\nIteration 12, loss = 2.31843899\nIteration 13, loss = 2.31787784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 2.31303474\nIteration 15, loss = 2.31608895\nIteration 16, loss = 2.32022585\nIteration 17, loss = 2.31899259\nIteration 18, loss = 2.31724697\nIteration 19, loss = 2.31965117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, loss = 2.31905389\nIteration 21, loss = 2.31886172\nIteration 22, loss = 2.32044709\nIteration 23, loss = 2.31867130\nIteration 24, loss = 2.31549176\nIteration 25, loss = 2.31980220\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.38551316\nIteration 2, loss = 2.34073279\nIteration 3, loss = 2.34108722\nIteration 4, loss = 2.33654213\nIteration 5, loss = 2.34683267\nIteration 6, loss = 2.33896592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 2.33939316\nIteration 8, loss = 2.34314443\nIteration 9, loss = 2.34506352\nIteration 10, loss = 2.34317775\nIteration 11, loss = 2.34255028\nIteration 12, loss = 2.34901656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 2.33827280\nIteration 14, loss = 2.34697886\nIteration 15, loss = 2.34273730\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.37081728\nIteration 2, loss = 2.34825895\nIteration 3, loss = 2.34368703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 2.33218797\nIteration 5, loss = 2.34395500\nIteration 6, loss = 2.34734308\nIteration 7, loss = 2.34282073\nIteration 8, loss = 2.34652737\nIteration 9, loss = 2.35020156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 2.33688274\nIteration 11, loss = 2.33522447\nIteration 12, loss = 2.34534280\nIteration 13, loss = 2.34394567\nIteration 14, loss = 2.33931867\nIteration 15, loss = 2.35099246\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.42419320\nIteration 2, loss = 2.35166783\nIteration 3, loss = 2.35283074\nIteration 4, loss = 2.34484894\nIteration 5, loss = 2.34226749\nIteration 6, loss = 2.34134573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 2.33332892\nIteration 8, loss = 2.34672047\nIteration 9, loss = 2.33668191\nIteration 10, loss = 2.35574020\nIteration 11, loss = 2.32146818\nIteration 12, loss = 2.35045490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 2.34507752\nIteration 14, loss = 2.33552331\nIteration 15, loss = 2.33600160\nIteration 16, loss = 2.35181519\nIteration 17, loss = 2.35027438\nIteration 18, loss = 2.34206495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 2.35103458\nIteration 20, loss = 2.34725197\nIteration 21, loss = 2.34899708\nIteration 22, loss = 2.35210090\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.29836114\nIteration 2, loss = 1.41434563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.10070164\nIteration 4, loss = 0.89822332\nIteration 5, loss = 0.63431152\nIteration 6, loss = 0.49458769\nIteration 7, loss = 0.39402018\nIteration 8, loss = 0.35352007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.27116305\nIteration 10, loss = 0.23326244\nIteration 11, loss = 0.20340515\nIteration 12, loss = 0.18065928\nIteration 13, loss = 0.14024142\nIteration 14, loss = 0.14283388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15, loss = 0.15649830\nIteration 16, loss = 0.11213039\nIteration 17, loss = 0.09001500\nIteration 18, loss = 0.09313240\nIteration 19, loss = 0.07745311\nIteration 20, loss = 0.07866991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21, loss = 0.11242623\nIteration 22, loss = 0.07944476\nIteration 23, loss = 0.07072518\nIteration 24, loss = 0.06868913\nIteration 25, loss = 0.09561986\nIteration 26, loss = 0.08362910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, loss = 0.06935913\nIteration 28, loss = 0.04894391\nIteration 29, loss = 0.04596222\nIteration 30, loss = 0.03383965\nIteration 31, loss = 0.02910539\nIteration 32, loss = 0.03325123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33, loss = 0.05940845\nIteration 34, loss = 0.03357732\nIteration 35, loss = 0.03192335\nIteration 36, loss = 0.03030105\nIteration 37, loss = 0.02590358\nIteration 38, loss = 0.06484677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39, loss = 0.04118325\nIteration 40, loss = 0.02338773\nIteration 41, loss = 0.02117811\nIteration 42, loss = 0.02032093\nIteration 43, loss = 0.01768102\nIteration 44, loss = 0.01514963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45, loss = 0.01667037\nIteration 46, loss = 0.01385015\nIteration 47, loss = 0.01313999\nIteration 48, loss = 0.14783432\nIteration 49, loss = 0.06740836\nIteration 50, loss = 0.04539712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.25546250\nIteration 2, loss = 1.43120256\nIteration 3, loss = 1.03794912\nIteration 4, loss = 0.73733318\nIteration 5, loss = 0.55738300\nIteration 6, loss = 0.45547358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.37355702\nIteration 8, loss = 0.29746476\nIteration 9, loss = 0.26069576\nIteration 10, loss = 0.21913202\nIteration 11, loss = 0.19355977\nIteration 12, loss = 0.16941090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 0.17911359\nIteration 14, loss = 0.14914312\nIteration 15, loss = 0.16428884\nIteration 16, loss = 0.14766858\nIteration 17, loss = 0.12312583\nIteration 18, loss = 0.11180732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 0.09722987\nIteration 20, loss = 0.10262768\nIteration 21, loss = 0.12467503\nIteration 22, loss = 0.07238386\nIteration 23, loss = 0.11135677\nIteration 24, loss = 0.14986313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25, loss = 0.07980081\nIteration 26, loss = 0.07924836\nIteration 27, loss = 0.07165472\nIteration 28, loss = 0.07298904\nIteration 29, loss = 0.06128746\nIteration 30, loss = 0.06672090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31, loss = 0.04765028\nIteration 32, loss = 0.06666554\nIteration 33, loss = 0.06273519\nIteration 34, loss = 0.06059279\nIteration 35, loss = 0.04209991\nIteration 36, loss = 0.02511443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 37, loss = 0.02067323\nIteration 38, loss = 0.02378399\nIteration 39, loss = 0.03216940\nIteration 40, loss = 0.04590271\nIteration 41, loss = 0.10204149\nIteration 42, loss = 0.03609893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43, loss = 0.02137278\nIteration 44, loss = 0.01432175\nIteration 45, loss = 0.02209948\nIteration 46, loss = 0.01984424\nIteration 47, loss = 0.01945572\nIteration 48, loss = 0.02119314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 49, loss = 0.05821363\nIteration 50, loss = 0.01453070\nIteration 1, loss = 2.28054983\nIteration 2, loss = 1.44050883\nIteration 3, loss = 1.02337944\nIteration 4, loss = 0.68642516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.53426628\nIteration 6, loss = 0.43767574\nIteration 7, loss = 0.35221837\nIteration 8, loss = 0.30387940\nIteration 9, loss = 0.26927489\nIteration 10, loss = 0.21577026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.18629309\nIteration 12, loss = 0.17448058\nIteration 13, loss = 0.16784444\nIteration 14, loss = 0.16187386\nIteration 15, loss = 0.14389256\nIteration 16, loss = 0.13660787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, loss = 0.13354450\nIteration 18, loss = 0.12067117\nIteration 19, loss = 0.11543156\nIteration 20, loss = 0.14111948\nIteration 21, loss = 0.08644585\nIteration 22, loss = 0.08293564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23, loss = 0.09766805\nIteration 24, loss = 0.07753975\nIteration 25, loss = 0.08783505\nIteration 26, loss = 0.06752997\nIteration 27, loss = 0.07328395\nIteration 28, loss = 0.06220264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29, loss = 0.06832957\nIteration 30, loss = 0.05317226\nIteration 31, loss = 0.09828437\nIteration 32, loss = 0.07391847\nIteration 33, loss = 0.06848328\nIteration 34, loss = 0.04001863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 35, loss = 0.03584483\nIteration 36, loss = 0.03130647\nIteration 37, loss = 0.02978807\nIteration 38, loss = 0.03708777\nIteration 39, loss = 0.03545982\nIteration 40, loss = 0.09037956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 41, loss = 0.05354588\nIteration 42, loss = 0.04828019\nIteration 43, loss = 0.04305727\nIteration 44, loss = 0.02770674\nIteration 45, loss = 0.02003353\nIteration 46, loss = 0.01960642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 47, loss = 0.01385895\nIteration 48, loss = 0.01224520\nIteration 49, loss = 0.02156001\nIteration 50, loss = 0.07233366\nIteration 1, loss = 1.90158735\nIteration 2, loss = 1.43345565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.30958772\nIteration 4, loss = 1.16687985\nIteration 5, loss = 1.11137228\nIteration 6, loss = 1.07452755\nIteration 7, loss = 1.03194919\nIteration 8, loss = 1.07997211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 1.13505026\nIteration 10, loss = 0.91700994\nIteration 11, loss = 0.88752102\nIteration 12, loss = 0.87976718\nIteration 13, loss = 0.92519330\nIteration 14, loss = 0.96239024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15, loss = 0.84393692\nIteration 16, loss = 0.82360715\nIteration 17, loss = 0.76294155\nIteration 18, loss = 0.75678533\nIteration 19, loss = 0.79553760\nIteration 20, loss = 0.73868595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21, loss = 0.75494070\nIteration 22, loss = 0.70798098\nIteration 23, loss = 0.70405776\nIteration 24, loss = 0.67221931\nIteration 25, loss = 0.64063880\nIteration 26, loss = 0.59897955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, loss = 0.58458327\nIteration 28, loss = 0.67793252\nIteration 29, loss = 0.64576524\nIteration 30, loss = 0.55129409\nIteration 31, loss = 0.64110716\nIteration 32, loss = 0.57903957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33, loss = 0.57987647\nIteration 34, loss = 0.59429630\nIteration 35, loss = 0.53560959\nIteration 36, loss = 0.60015036\nIteration 37, loss = 0.53899917\nIteration 38, loss = 0.51544271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39, loss = 0.51808127\nIteration 40, loss = 0.57562414\nIteration 41, loss = 0.45959573\nIteration 42, loss = 0.52893264\nIteration 43, loss = 0.54834398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44, loss = 0.52145628\nIteration 45, loss = 0.51616249\nIteration 46, loss = 0.49204566\nIteration 47, loss = 0.41597286\nIteration 48, loss = 0.51541661\nIteration 49, loss = 0.48655301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50, loss = 0.48720412\nIteration 1, loss = 2.12915186\nIteration 2, loss = 1.72923307\nIteration 3, loss = 1.50766850\nIteration 4, loss = 1.25877391\nIteration 5, loss = 1.10953537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.05333098\nIteration 7, loss = 1.04204195\nIteration 8, loss = 0.90282613\nIteration 9, loss = 0.93660328\nIteration 10, loss = 0.83053523\nIteration 11, loss = 0.76433419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.72776735\nIteration 13, loss = 0.73261960\nIteration 14, loss = 0.70002452\nIteration 15, loss = 0.73713486\nIteration 16, loss = 0.77999162\nIteration 17, loss = 0.63386886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18, loss = 0.67050208\nIteration 19, loss = 0.63498677\nIteration 20, loss = 0.65498597\nIteration 21, loss = 0.59379290\nIteration 22, loss = 0.62689112\nIteration 23, loss = 0.62833320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24, loss = 0.72210047\nIteration 25, loss = 0.62121747\nIteration 26, loss = 0.63196274\nIteration 27, loss = 0.59646020\nIteration 28, loss = 0.57601839\nIteration 29, loss = 0.62329664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, loss = 0.60043542\nIteration 31, loss = 0.55563649\nIteration 32, loss = 0.54806043\nIteration 33, loss = 0.63797617\nIteration 34, loss = 0.82749671\nIteration 35, loss = 0.62290518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 36, loss = 0.60808980\nIteration 37, loss = 0.52403225\nIteration 38, loss = 0.55223270\nIteration 39, loss = 0.66721632\nIteration 40, loss = 0.59848863\nIteration 41, loss = 0.54359250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 42, loss = 0.63041404\nIteration 43, loss = 0.66363455\nIteration 44, loss = 0.54723499\nIteration 45, loss = 0.53433955\nIteration 46, loss = 0.60819630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 47, loss = 0.55100651\nIteration 48, loss = 0.52249874\nIteration 49, loss = 0.57421522\nIteration 50, loss = 0.53533374\nIteration 1, loss = 1.92067631\nIteration 2, loss = 1.38790214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.26259782\nIteration 4, loss = 1.06046849\nIteration 5, loss = 0.92481184\nIteration 6, loss = 0.89017451\nIteration 7, loss = 0.75540299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.77794506\nIteration 9, loss = 0.72916336\nIteration 10, loss = 0.72420508\nIteration 11, loss = 0.70872660\nIteration 12, loss = 0.62201787\nIteration 13, loss = 0.58798105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 0.56826384\nIteration 15, loss = 0.61835984\nIteration 16, loss = 0.61399018\nIteration 17, loss = 0.47697435\nIteration 18, loss = 0.56989776\nIteration 19, loss = 0.53409563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, loss = 0.51670915\nIteration 21, loss = 0.44947142\nIteration 22, loss = 0.42496823\nIteration 23, loss = 0.52793502\nIteration 24, loss = 0.38943564\nIteration 25, loss = 0.40960045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26, loss = 0.33997813\nIteration 27, loss = 0.35449638\nIteration 28, loss = 0.36175175\nIteration 29, loss = 0.38895547\nIteration 30, loss = 0.36714142\nIteration 31, loss = 0.34732796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32, loss = 0.47320623\nIteration 33, loss = 0.45325633\nIteration 34, loss = 0.28079252\nIteration 35, loss = 0.31947726\nIteration 36, loss = 0.40580471\nIteration 37, loss = 0.36014129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38, loss = 0.24536345\nIteration 39, loss = 0.30069638\nIteration 40, loss = 0.29952647\nIteration 41, loss = 0.33425545\nIteration 42, loss = 0.26895194\nIteration 43, loss = 0.40280665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44, loss = 0.33723019\nIteration 45, loss = 0.30998089\nIteration 46, loss = 0.27668337\nIteration 47, loss = 0.27142381\nIteration 48, loss = 0.40889768\nIteration 49, loss = 0.23196325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50, loss = 0.25695352\nIteration 1, loss = 2.16640685\nIteration 2, loss = 2.05297409\nIteration 3, loss = 2.13199947\nIteration 4, loss = 1.97290248\nIteration 5, loss = 1.93419718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 2.07736487\nIteration 7, loss = 1.99671932\nIteration 8, loss = 2.18574592\nIteration 9, loss = 2.03801275\nIteration 10, loss = 2.02209544\nIteration 11, loss = 1.99866557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 2.00883847\nIteration 13, loss = 2.01969126\nIteration 14, loss = 2.00579912\nIteration 15, loss = 2.06570770\nIteration 16, loss = 2.01503980\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.42029717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 2.31653698\nIteration 3, loss = 2.31738308\nIteration 4, loss = 2.31670355\nIteration 5, loss = 2.32251136\nIteration 6, loss = 2.31890068\nIteration 7, loss = 2.31881610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 2.31668034\nIteration 9, loss = 2.31541870\nIteration 10, loss = 2.31793770\nIteration 11, loss = 2.31601514\nIteration 12, loss = 2.31517579\nIteration 13, loss = 2.31784772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 2.31893218\nIteration 15, loss = 2.31697802\nIteration 16, loss = 2.31682821\nIteration 17, loss = 2.32026804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18, loss = 2.31727063\nIteration 19, loss = 2.31531877\nIteration 20, loss = 2.31823761\nIteration 21, loss = 2.31920999\nIteration 22, loss = 2.31796642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23, loss = 2.31756047\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.19358870\nIteration 2, loss = 1.90646999\nIteration 3, loss = 2.07071394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 2.00850747\nIteration 5, loss = 2.03423808\nIteration 6, loss = 2.21759073\nIteration 7, loss = 2.04555660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 2.06855415\nIteration 9, loss = 2.04554077\nIteration 10, loss = 2.03872482\nIteration 11, loss = 2.02309078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 2.03086489\nIteration 13, loss = 2.01535785\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.52644311\nIteration 2, loss = 2.35053891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 2.34862662\nIteration 4, loss = 2.34036102\nIteration 5, loss = 2.34940052\nIteration 6, loss = 2.34075892\nIteration 7, loss = 2.34134987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 2.34472357\nIteration 9, loss = 2.35275146\nIteration 10, loss = 2.35020955\nIteration 11, loss = 2.34149496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 2.34012317\nIteration 13, loss = 2.35063256\nIteration 14, loss = 2.34858438\nIteration 15, loss = 2.35234624\nIteration 16, loss = 2.33840283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, loss = 2.33471523\nIteration 18, loss = 2.34358970\nIteration 19, loss = 2.35196941\nIteration 20, loss = 2.35489489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21, loss = 2.35896750\nIteration 22, loss = 2.34817282\nIteration 23, loss = 2.35186648\nIteration 24, loss = 2.34324293\nIteration 25, loss = 2.33755263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26, loss = 2.34795687\nIteration 27, loss = 2.34528247\nIteration 28, loss = 2.34097904\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.54964214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 2.34252031\nIteration 3, loss = 2.34682097\nIteration 4, loss = 2.34711527\nIteration 5, loss = 2.34842450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 2.35248605\nIteration 7, loss = 2.35255185\nIteration 8, loss = 2.34561832\nIteration 9, loss = 2.34320384\nIteration 10, loss = 2.34486718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 2.33876220\nIteration 12, loss = 2.33713066\nIteration 13, loss = 2.33846908\nIteration 14, loss = 2.34982749\nIteration 15, loss = 2.34402782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 2.33859544\nIteration 17, loss = 2.35197436\nIteration 18, loss = 2.35023075\nIteration 19, loss = 2.34202853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, loss = 2.34982320\nIteration 21, loss = 2.35461167\nIteration 22, loss = 2.34157950\nIteration 23, loss = 2.34559291\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.60192901\nIteration 2, loss = 2.32757910\nIteration 3, loss = 2.35487423\nIteration 4, loss = 2.33619128\nIteration 5, loss = 2.35615456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 2.34506485\nIteration 7, loss = 2.34373895\nIteration 8, loss = 2.34592613\nIteration 9, loss = 2.34159247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 2.34381607\nIteration 11, loss = 2.34948102\nIteration 12, loss = 2.35704477\nIteration 13, loss = 2.34136400\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.41929840\nIteration 2, loss = 0.71936523\nIteration 3, loss = 0.38805610\nIteration 4, loss = 0.25356172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.18947095\nIteration 6, loss = 0.11849419\nIteration 7, loss = 0.10303331\nIteration 8, loss = 0.10336048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.06708743\nIteration 10, loss = 0.05742002\nIteration 11, loss = 0.03546670\nIteration 12, loss = 0.03725911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 0.02155343\nIteration 14, loss = 0.02400946\nIteration 15, loss = 0.02126650\nIteration 16, loss = 0.01885998\nIteration 17, loss = 0.01443666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18, loss = 0.00784321\nIteration 19, loss = 0.00794064\nIteration 20, loss = 0.00770674\nIteration 21, loss = 0.00520936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22, loss = 0.00458325\nIteration 23, loss = 0.00986273\nIteration 24, loss = 0.19646975\nIteration 25, loss = 0.13876023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26, loss = 0.06080241\nIteration 27, loss = 0.03102024\nIteration 28, loss = 0.00657541\nIteration 29, loss = 0.00369006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, loss = 0.00280940\nIteration 31, loss = 0.00206932\nIteration 32, loss = 0.00169453\nIteration 33, loss = 0.00155076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34, loss = 0.00142218\nIteration 35, loss = 0.00129598\nIteration 36, loss = 0.00117467\nIteration 37, loss = 0.00117589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38, loss = 0.00111414\nIteration 39, loss = 0.00109415\nIteration 40, loss = 0.00092646\nIteration 41, loss = 0.00081199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 42, loss = 0.00076688\nIteration 43, loss = 0.00079231\nIteration 44, loss = 0.00072742\nIteration 45, loss = 0.00066710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 46, loss = 0.00065387\nIteration 47, loss = 0.00060850\nIteration 48, loss = 0.00057555\nIteration 49, loss = 0.00054130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50, loss = 0.00053273\nIteration 1, loss = 2.44850235\nIteration 2, loss = 0.68181000\nIteration 3, loss = 0.37583489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.22869216\nIteration 5, loss = 0.18271953\nIteration 6, loss = 0.13711124\nIteration 7, loss = 0.10533702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.07735675\nIteration 9, loss = 0.06539605\nIteration 10, loss = 0.05120125\nIteration 11, loss = 0.06335080\nIteration 12, loss = 0.05960652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 0.04351854\nIteration 14, loss = 0.02060691\nIteration 15, loss = 0.02921159\nIteration 16, loss = 0.01764751\nIteration 17, loss = 0.02673033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18, loss = 0.04475032\nIteration 19, loss = 0.01544711\nIteration 20, loss = 0.01606162\nIteration 21, loss = 0.01221870\nIteration 22, loss = 0.00560759\nIteration 23, loss = 0.00408927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24, loss = 0.00357633\nIteration 25, loss = 0.00309970\nIteration 26, loss = 0.00263174\nIteration 27, loss = 0.00248898\nIteration 28, loss = 0.00218453\nIteration 29, loss = 0.00196697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, loss = 0.00174623\nIteration 31, loss = 0.00172705\nIteration 32, loss = 0.00148824\nIteration 33, loss = 0.00162170\nIteration 34, loss = 0.00131132\nIteration 35, loss = 0.00118016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 36, loss = 0.00109615\nIteration 37, loss = 0.00106391\nIteration 38, loss = 0.00092544\nIteration 39, loss = 0.00089554\nIteration 40, loss = 0.00100370\nIteration 41, loss = 0.00078061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 42, loss = 0.00064898\nIteration 43, loss = 0.00062496\nIteration 44, loss = 0.00057376\nIteration 45, loss = 0.00052063\nIteration 46, loss = 0.00059907\nIteration 47, loss = 0.24384307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 48, loss = 0.14142604\nIteration 49, loss = 0.07947813\nIteration 50, loss = 0.03053167\nIteration 1, loss = 2.44702955\nIteration 2, loss = 0.74746896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.38470677\nIteration 4, loss = 0.28111788\nIteration 5, loss = 0.18002108\nIteration 6, loss = 0.12240854\nIteration 7, loss = 0.08663419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.06446385\nIteration 9, loss = 0.06184956\nIteration 10, loss = 0.04971280\nIteration 11, loss = 0.03328768\nIteration 12, loss = 0.03695198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 0.02842162\nIteration 14, loss = 0.02399420\nIteration 15, loss = 0.01375555\nIteration 16, loss = 0.01796803\nIteration 17, loss = 0.01288641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18, loss = 0.01000002\nIteration 19, loss = 0.00688029\nIteration 20, loss = 0.00513158\nIteration 21, loss = 0.00468687\nIteration 22, loss = 0.00474488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23, loss = 0.00426636\nIteration 24, loss = 0.00409919\nIteration 25, loss = 0.00328120\nIteration 26, loss = 0.00263745\nIteration 27, loss = 0.00248978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28, loss = 0.00307934\nIteration 29, loss = 0.00274332\nIteration 30, loss = 0.00176277\nIteration 31, loss = 0.00191437\nIteration 32, loss = 0.00138772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33, loss = 0.00128414\nIteration 34, loss = 0.00114322\nIteration 35, loss = 0.00138797\nIteration 36, loss = 0.00126381\nIteration 37, loss = 0.00098722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38, loss = 0.00079058\nIteration 39, loss = 0.00072666\nIteration 40, loss = 0.00066497\nIteration 41, loss = 0.00065749\nIteration 42, loss = 0.00059383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43, loss = 0.00056376\nIteration 44, loss = 0.00051111\nIteration 45, loss = 0.00047085\nIteration 46, loss = 0.00042936\nIteration 47, loss = 0.00040066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 48, loss = 0.00040324\nIteration 49, loss = 0.00037023\nIteration 50, loss = 0.00032471\nIteration 1, loss = 1.90782913\nIteration 2, loss = 0.67994707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.33784032\nIteration 4, loss = 0.23288827\nIteration 5, loss = 0.35860530\nIteration 6, loss = 0.19512373\nIteration 7, loss = 0.27897806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.32979539\nIteration 9, loss = 0.24652198\nIteration 10, loss = 0.14283779\nIteration 11, loss = 0.08815841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.36397404\nIteration 13, loss = 0.27368656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 0.12239584\nIteration 15, loss = 0.07695437\nIteration 16, loss = 0.18885375\nIteration 17, loss = 0.16561520\nIteration 18, loss = 0.12716823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 0.10767171\nIteration 20, loss = 0.20293388\nIteration 21, loss = 0.12578121\nIteration 22, loss = 0.22708857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23, loss = 0.22506898\nIteration 24, loss = 0.13024547\nIteration 25, loss = 0.13963598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26, loss = 0.03928238\nIteration 27, loss = 0.05058019\nIteration 28, loss = 0.02262948\nIteration 29, loss = 0.01391017\nIteration 30, loss = 0.01230707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31, loss = 0.01081044\nIteration 32, loss = 0.01612404\nIteration 33, loss = 0.26819199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34, loss = 0.35954896\nIteration 35, loss = 0.30072482\nIteration 36, loss = 0.10839994\nIteration 37, loss = 0.05992417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38, loss = 0.14012045\nIteration 39, loss = 0.23154844\nIteration 40, loss = 0.07780566\nIteration 41, loss = 0.23200609\nIteration 42, loss = 0.13798681\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.87747268\nIteration 2, loss = 1.00522741\nIteration 3, loss = 0.69369510\nIteration 4, loss = 0.55555056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.46546813\nIteration 6, loss = 0.42942517\nIteration 7, loss = 0.37305246\nIteration 8, loss = 0.41700571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.34058702\nIteration 10, loss = 0.33631844\nIteration 11, loss = 0.43931117\nIteration 12, loss = 0.28137687\nIteration 13, loss = 0.32619502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 0.28652683\nIteration 15, loss = 0.28752615\nIteration 16, loss = 0.22304087\nIteration 17, loss = 0.26316102\nIteration 18, loss = 0.23210953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 0.22408005\nIteration 20, loss = 0.21429193\nIteration 21, loss = 0.34054018\nIteration 22, loss = 0.23138289\nIteration 23, loss = 0.28781791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24, loss = 0.19886212\nIteration 25, loss = 0.29366984\nIteration 26, loss = 0.28162637\nIteration 27, loss = 0.29990481\nIteration 28, loss = 0.18485362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29, loss = 0.10882863\nIteration 30, loss = 0.17480758\nIteration 31, loss = 0.09165709\nIteration 32, loss = 0.12996835\nIteration 33, loss = 0.08622540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34, loss = 0.23702832\nIteration 35, loss = 0.30879678\nIteration 36, loss = 0.25102573\nIteration 37, loss = 0.13525580\nIteration 38, loss = 0.14731296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39, loss = 0.10003903\nIteration 40, loss = 0.26532485\nIteration 41, loss = 0.14592245\nIteration 42, loss = 0.15539137\nIteration 43, loss = 0.28550711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44, loss = 0.27103438\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 1.87492838\nIteration 2, loss = 0.83499700\nIteration 3, loss = 0.65839630\nIteration 4, loss = 0.54608857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.44189629\nIteration 6, loss = 0.34714696\nIteration 7, loss = 0.25052331\nIteration 8, loss = 0.28366017\nIteration 9, loss = 0.33916764\nIteration 10, loss = 0.35359611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.25259667\nIteration 12, loss = 0.17832685\nIteration 13, loss = 0.15683507\nIteration 14, loss = 0.24380410\nIteration 15, loss = 0.32683303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 0.26789095\nIteration 17, loss = 0.24252064\nIteration 18, loss = 0.15280170\nIteration 19, loss = 0.17041989\nIteration 20, loss = 0.22712821\nIteration 21, loss = 0.29884304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22, loss = 0.31523056\nIteration 23, loss = 0.18368625\nIteration 24, loss = 0.16622816\nIteration 25, loss = 0.21436828\nIteration 26, loss = 0.33967550\nIteration 27, loss = 0.17608014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28, loss = 0.10138872\nIteration 29, loss = 0.17578898\nIteration 30, loss = 0.11368263\nIteration 31, loss = 0.19803945\nIteration 32, loss = 0.27441165\nIteration 33, loss = 0.21461689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34, loss = 0.10092231\nIteration 35, loss = 0.13387742\nIteration 36, loss = 0.09267695\nIteration 37, loss = 0.10543720\nIteration 38, loss = 0.15042920\nIteration 39, loss = 0.36255854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40, loss = 0.07272983\nIteration 41, loss = 0.06129953\nIteration 42, loss = 0.08283445\nIteration 43, loss = 0.22857072\nIteration 44, loss = 0.17127741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45, loss = 0.07877028\nIteration 46, loss = 0.11640546\nIteration 47, loss = 0.18949069\nIteration 48, loss = 0.60469215\nIteration 49, loss = 0.15321941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50, loss = 0.11493734\nIteration 1, loss = 2.09138032\nIteration 2, loss = 1.64387901\nIteration 3, loss = 1.48619679\nIteration 4, loss = 1.79026002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 1.78718385\nIteration 6, loss = 1.74227863\nIteration 7, loss = 1.83638155\nIteration 8, loss = 1.82078356\nIteration 9, loss = 2.04231834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 2.02734003\nIteration 11, loss = 2.00168809\nIteration 12, loss = 1.99508348\nIteration 13, loss = 1.99528333\nIteration 14, loss = 1.99707341\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.33359740\nIteration 2, loss = 1.94081011\nIteration 3, loss = 2.14539990\nIteration 4, loss = 2.27890532\nIteration 5, loss = 2.32124660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 2.31754382\nIteration 7, loss = 2.31517982\nIteration 8, loss = 2.31729046\nIteration 9, loss = 2.31600846\nIteration 10, loss = 2.31494016\nIteration 11, loss = 2.31650843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 2.31567088\nIteration 13, loss = 2.31782034\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.35942725\nIteration 2, loss = 2.00642344\nIteration 3, loss = 2.00845093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 2.01001568\nIteration 5, loss = 2.18085255\nIteration 6, loss = 2.04980004\nIteration 7, loss = 2.08354566\nIteration 8, loss = 2.06739569\nIteration 9, loss = 2.06450999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 2.02320944\nIteration 11, loss = 1.99758271\nIteration 12, loss = 1.98577188\nIteration 13, loss = 2.02845907\nIteration 14, loss = 2.04517712\nIteration 15, loss = 2.04498548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 1.99125066\nIteration 17, loss = 1.94710711\nIteration 18, loss = 2.05944515\nIteration 19, loss = 1.99999669\nIteration 20, loss = 2.07204795\nIteration 21, loss = 1.99657450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22, loss = 1.98329428\nIteration 23, loss = 2.00861447\nIteration 24, loss = 1.96597100\nIteration 25, loss = 2.00695927\nIteration 26, loss = 2.05456726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, loss = 2.00333787\nIteration 28, loss = 1.94137846\nIteration 29, loss = 1.99575252\nIteration 30, loss = 2.04768040\nIteration 31, loss = 2.03374441\nIteration 32, loss = 1.99000212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33, loss = 1.92683940\nIteration 34, loss = 1.93840697\nIteration 35, loss = 2.03841565\nIteration 36, loss = 2.01281963\nIteration 37, loss = 2.00453435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38, loss = 1.99683954\nIteration 39, loss = 1.98645496\nIteration 40, loss = 1.98320108\nIteration 41, loss = 1.98956145\nIteration 42, loss = 1.98220679\nIteration 43, loss = 1.99701756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44, loss = 1.99357049\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.48433301\nIteration 2, loss = 2.33854620\nIteration 3, loss = 2.34679144\nIteration 4, loss = 2.35051272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 2.33828735\nIteration 6, loss = 2.33911482\nIteration 7, loss = 2.35628694\nIteration 8, loss = 2.35062438\nIteration 9, loss = 2.35040579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 2.34290175\nIteration 11, loss = 2.35553824\nIteration 12, loss = 2.34522934\nIteration 13, loss = 2.35274773\nIteration 14, loss = 2.35110675\nIteration 15, loss = 2.34613167\nIteration 16, loss = 2.33888674\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.70233837\nIteration 2, loss = 2.34892614\nIteration 3, loss = 2.34435128\nIteration 4, loss = 2.33727675\nIteration 5, loss = 2.34879750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 2.34624450\nIteration 7, loss = 2.33532774\nIteration 8, loss = 2.34342252\nIteration 9, loss = 2.33268247\nIteration 10, loss = 2.33660747\nIteration 11, loss = 2.34498719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 2.33522396\nIteration 13, loss = 2.34929200\nIteration 14, loss = 2.33685188\nIteration 15, loss = 2.35398958\nIteration 16, loss = 2.34742390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, loss = 2.34724398\nIteration 18, loss = 2.34305250\nIteration 19, loss = 2.33858269\nIteration 20, loss = 2.35010968\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.66510620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 2.33690551\nIteration 3, loss = 2.34786461\nIteration 4, loss = 2.33853210\nIteration 5, loss = 2.34981404\nIteration 6, loss = 2.34296893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 2.34497836\nIteration 8, loss = 2.34527890\nIteration 9, loss = 2.35872411\nIteration 10, loss = 2.35478803\nIteration 11, loss = 2.34306170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 2.33891524\nIteration 13, loss = 2.35818221\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.05617635\nIteration 2, loss = 0.43625545\nIteration 3, loss = 0.22761496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.15296331\nIteration 5, loss = 0.10858903\nIteration 6, loss = 0.09461200\nIteration 7, loss = 0.05525989\nIteration 8, loss = 0.04192083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.02594163\nIteration 10, loss = 0.01876201\nIteration 11, loss = 0.01304702\nIteration 12, loss = 0.01116536\nIteration 13, loss = 0.00745143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 0.00510834\nIteration 15, loss = 0.00370279\nIteration 16, loss = 0.00823448\nIteration 17, loss = 0.00328828\nIteration 18, loss = 0.00255664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 0.00198104\nIteration 20, loss = 0.00207518\nIteration 21, loss = 0.00182162\nIteration 22, loss = 0.00159068\nIteration 23, loss = 0.00178364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24, loss = 0.00133281\nIteration 25, loss = 0.00134874\nIteration 26, loss = 0.00127984\nIteration 27, loss = 0.00102853\nIteration 28, loss = 0.00097345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29, loss = 0.00088334\nIteration 30, loss = 0.00093488\nIteration 31, loss = 0.00093140\nIteration 32, loss = 0.00073339\nIteration 33, loss = 0.00064024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34, loss = 0.00060443\nIteration 35, loss = 0.00052093\nIteration 36, loss = 0.00054876\nIteration 37, loss = 0.00050368\nIteration 38, loss = 0.00053170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39, loss = 0.41568859\nIteration 40, loss = 0.18255339\nIteration 41, loss = 0.07682101\nIteration 42, loss = 0.01655899\nIteration 43, loss = 0.00552558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44, loss = 0.00118618\nIteration 45, loss = 0.00082774\nIteration 46, loss = 0.00070106\nIteration 47, loss = 0.00063182\nIteration 48, loss = 0.00056261\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.30958090\nIteration 2, loss = 0.52947819\nIteration 3, loss = 0.26791108\nIteration 4, loss = 0.17359416\nIteration 5, loss = 0.12643475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.09490505\nIteration 7, loss = 0.07220499\nIteration 8, loss = 0.03101742\nIteration 9, loss = 0.02272126\nIteration 10, loss = 0.01618917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.00885582\nIteration 12, loss = 0.00684572\nIteration 13, loss = 0.00518569\nIteration 14, loss = 0.00416326\nIteration 15, loss = 0.00374370\nIteration 16, loss = 0.00343176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, loss = 0.00299822\nIteration 18, loss = 0.00266543\nIteration 19, loss = 0.00241574\nIteration 20, loss = 0.00207946\nIteration 21, loss = 0.00184876\nIteration 22, loss = 0.00190754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23, loss = 0.00158918\nIteration 24, loss = 0.00151507\nIteration 25, loss = 0.00128918\nIteration 26, loss = 0.00120435\nIteration 27, loss = 0.00110549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28, loss = 0.00103809\nIteration 29, loss = 0.00091435\nIteration 30, loss = 0.00082985\nIteration 31, loss = 0.00079426\nIteration 32, loss = 0.00071917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33, loss = 0.00067407\nIteration 34, loss = 0.00058637\nIteration 35, loss = 0.00058550\nIteration 36, loss = 0.00055886\nIteration 37, loss = 0.00048439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38, loss = 0.00044630\nIteration 39, loss = 0.00043066\nIteration 40, loss = 0.00042817\nIteration 41, loss = 0.00037521\nIteration 42, loss = 0.00037065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43, loss = 0.00031317\nIteration 44, loss = 0.00031710\nIteration 45, loss = 0.00028437\nIteration 46, loss = 0.00026085\nIteration 47, loss = 0.00025672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 48, loss = 0.00023430\nIteration 49, loss = 0.00022428\nIteration 50, loss = 0.00022090\nIteration 1, loss = 2.16518245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 0.46630527\nIteration 3, loss = 0.22441627\nIteration 4, loss = 0.17437318\nIteration 5, loss = 0.10295458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.08445598\nIteration 7, loss = 0.05715754\nIteration 8, loss = 0.05857823\nIteration 9, loss = 0.04722592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.15193898\nIteration 11, loss = 0.10508113\nIteration 12, loss = 0.02406489\nIteration 13, loss = 0.01573277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 0.02311830\nIteration 15, loss = 0.01029952\nIteration 16, loss = 0.00558883\nIteration 17, loss = 0.00283115\nIteration 18, loss = 0.00251104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 0.00195483\nIteration 20, loss = 0.00168299\nIteration 21, loss = 0.00160936\nIteration 22, loss = 0.00147066\nIteration 23, loss = 0.00141941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24, loss = 0.00124275\nIteration 25, loss = 0.00118178\nIteration 26, loss = 0.00110002\nIteration 27, loss = 0.00101787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28, loss = 0.00098613\nIteration 29, loss = 0.00088063\nIteration 30, loss = 0.00082063\nIteration 31, loss = 0.00074769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32, loss = 0.00078254\nIteration 33, loss = 0.00070877\nIteration 34, loss = 0.00064530\nIteration 35, loss = 0.00059330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 36, loss = 0.00055189\nIteration 37, loss = 0.00051812\nIteration 38, loss = 0.00048732\nIteration 39, loss = 0.00047350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40, loss = 0.00042901\nIteration 41, loss = 0.00041032\nIteration 42, loss = 0.00038754\nIteration 43, loss = 0.00035454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44, loss = 0.00034834\nIteration 45, loss = 0.00033842\nIteration 46, loss = 0.00030607\nIteration 47, loss = 0.00031289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 48, loss = 0.00028266\nIteration 49, loss = 0.00025954\nIteration 50, loss = 0.00026341\nIteration 1, loss = 1.48810189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 0.37259343\nIteration 3, loss = 0.27925778\nIteration 4, loss = 0.23303987\nIteration 5, loss = 0.23475732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.25382848\nIteration 7, loss = 0.17180796\nIteration 8, loss = 0.10074615\nIteration 9, loss = 0.23594484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.23671387\nIteration 11, loss = 0.07571600\nIteration 12, loss = 0.11157134\nIteration 13, loss = 0.08417687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 0.06698614\nIteration 15, loss = 0.07862608\nIteration 16, loss = 0.22250843\nIteration 17, loss = 0.40410732\nIteration 18, loss = 0.13815940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 0.31163335\nIteration 20, loss = 0.26503745\nIteration 21, loss = 0.17748832\nIteration 22, loss = 0.15686857\nIteration 23, loss = 0.11728697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24, loss = 0.07212296\nIteration 25, loss = 0.05233341\nIteration 26, loss = 0.04415129\nIteration 27, loss = 0.06265419\nIteration 28, loss = 0.05320252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29, loss = 0.12458438\nIteration 30, loss = 0.35841082\nIteration 31, loss = 0.20351948\nIteration 32, loss = 0.16241572\nIteration 33, loss = 0.10767684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34, loss = 0.37153996\nIteration 35, loss = 0.10816160\nIteration 36, loss = 0.09561049\nIteration 37, loss = 0.07645817\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 1.53499195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 0.42363650\nIteration 3, loss = 0.34348180\nIteration 4, loss = 0.35309255\nIteration 5, loss = 0.31655938\nIteration 6, loss = 0.27569577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.17907953\nIteration 8, loss = 0.15525887\nIteration 9, loss = 0.28308723\nIteration 10, loss = 0.29969814\nIteration 11, loss = 0.17689498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.06951054\nIteration 13, loss = 0.16183974\nIteration 14, loss = 0.33080699\nIteration 15, loss = 0.12971482\nIteration 16, loss = 0.19528083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, loss = 0.35338826\nIteration 18, loss = 0.22090449\nIteration 19, loss = 0.06066543\nIteration 20, loss = 0.15454874\nIteration 21, loss = 0.17082993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22, loss = 0.17643648\nIteration 23, loss = 0.29898407\nIteration 24, loss = 0.13421656\nIteration 25, loss = 0.15165523\nIteration 26, loss = 0.05000509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, loss = 0.02119686\nIteration 28, loss = 0.06110825\nIteration 29, loss = 0.01093867\nIteration 30, loss = 0.00834379\nIteration 31, loss = 0.00746305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32, loss = 0.00556073\nIteration 33, loss = 0.00758486\nIteration 34, loss = 0.00497854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 35, loss = 0.06501919\nIteration 36, loss = 0.57334303\nIteration 37, loss = 0.92865596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38, loss = 0.22214601\nIteration 39, loss = 0.14773673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40, loss = 0.19531285\nIteration 41, loss = 0.23398337\nIteration 42, loss = 0.17000138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43, loss = 0.31526367\nIteration 44, loss = 0.15734190\nIteration 45, loss = 0.05840491\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.71385218\nIteration 2, loss = 0.46576418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.29110354\nIteration 4, loss = 0.24107105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.17013267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.35621921\nIteration 7, loss = 0.10428533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.16422756\nIteration 9, loss = 0.24509810\nIteration 10, loss = 0.28002680\nIteration 11, loss = 0.12887776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.26628926\nIteration 13, loss = 0.23850281\nIteration 14, loss = 0.28565623\nIteration 15, loss = 0.13751254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 0.26689047\nIteration 17, loss = 0.26248031\nIteration 18, loss = 0.16493268\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 1.81999732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.29304975\nIteration 3, loss = 1.18659420\nIteration 4, loss = 0.93489784\nIteration 5, loss = 1.22929431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.04246304\nIteration 7, loss = 1.09643880\nIteration 8, loss = 1.22808535\nIteration 9, loss = 1.06321490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.32251338\nIteration 11, loss = 1.27409793\nIteration 12, loss = 1.14597273\nIteration 13, loss = 1.21845856\nIteration 14, loss = 1.04299930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15, loss = 1.11493851\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.14911545\nIteration 2, loss = 1.55918049\nIteration 3, loss = 1.57112306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.61947864\nIteration 5, loss = 1.41771731\nIteration 6, loss = 1.48329918\nIteration 7, loss = 1.44761208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 1.48304543\nIteration 9, loss = 1.44453348\nIteration 10, loss = 1.43369114\nIteration 11, loss = 1.47487299\nIteration 12, loss = 1.52939345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 1.52086930\nIteration 14, loss = 1.45641369\nIteration 15, loss = 1.45464056\nIteration 16, loss = 1.41468421"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nIteration 17, loss = 1.57816915\nIteration 18, loss = 1.54888584\nIteration 19, loss = 1.48674261\nIteration 20, loss = 1.46294205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21, loss = 1.43386925\nIteration 22, loss = 1.45323746\nIteration 23, loss = 1.47096430\nIteration 24, loss = 1.44782625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25, loss = 1.51939578\nIteration 26, loss = 1.49724124\nIteration 27, loss = 1.44993697\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.36906371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.36831914\nIteration 3, loss = 1.45110748\nIteration 4, loss = 1.39180162\nIteration 5, loss = 1.23479480\nIteration 6, loss = 1.57661404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.52441362\nIteration 8, loss = 1.50551209\nIteration 9, loss = 1.46581296\nIteration 10, loss = 1.54572938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 1.67698829\nIteration 12, loss = 1.43866327\nIteration 13, loss = 1.53679784\nIteration 14, loss = 1.48660855\nIteration 15, loss = 1.44265199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 1.50892838\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.65372532\nIteration 2, loss = 2.34649985\nIteration 3, loss = 2.35046369\nIteration 4, loss = 2.33787395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 2.36425620\nIteration 6, loss = 2.34890902\nIteration 7, loss = 2.35234784\nIteration 8, loss = 2.34372550\nIteration 9, loss = 2.35928528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 2.35982142\nIteration 11, loss = 2.33990728\nIteration 12, loss = 2.34670132\nIteration 13, loss = 2.34755023\nIteration 14, loss = 2.33933811\nIteration 15, loss = 2.34140831\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.85073446\nIteration 2, loss = 2.33303088\nIteration 3, loss = 2.34625553\nIteration 4, loss = 2.34566564\nIteration 5, loss = 2.33661808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 2.34713331\nIteration 7, loss = 2.33755056\nIteration 8, loss = 2.33637165\nIteration 9, loss = 2.34326465\nIteration 10, loss = 2.34518299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 2.33940877\nIteration 12, loss = 2.35094690\nIteration 13, loss = 2.34375951\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.85987034\nIteration 2, loss = 2.34492239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 2.34266786\nIteration 4, loss = 2.35962735\nIteration 5, loss = 2.34420182\nIteration 6, loss = 2.34299778\nIteration 7, loss = 2.32348512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 2.35169751\nIteration 9, loss = 2.34774322\nIteration 10, loss = 2.33444864\nIteration 11, loss = 2.34515179\nIteration 12, loss = 2.34861139\nIteration 13, loss = 2.34420387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 2.33895762\nIteration 15, loss = 2.34555197\nIteration 16, loss = 2.34936101\nIteration 17, loss = 2.35017967\nIteration 18, loss = 2.34861161\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.59830143\nIteration 2, loss = 1.96328957\nIteration 3, loss = 1.66079268\nIteration 4, loss = 1.44037392\nIteration 5, loss = 1.28975814\nIteration 6, loss = 1.15919066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.09642032\nIteration 8, loss = 0.97968845\nIteration 9, loss = 0.87495012\nIteration 10, loss = 0.81425470\nIteration 11, loss = 0.76052803\nIteration 12, loss = 0.69775293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 0.67197134\nIteration 14, loss = 0.64860153\nIteration 15, loss = 0.59036761\nIteration 16, loss = 0.55962839\nIteration 17, loss = 0.54340327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18, loss = 0.50704373\nIteration 19, loss = 0.50174960\nIteration 20, loss = 0.48824436\nIteration 21, loss = 0.44583541\nIteration 22, loss = 0.44029338\nIteration 23, loss = 0.41097120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24, loss = 0.40466422\nIteration 25, loss = 0.40919360\nIteration 26, loss = 0.38545532\nIteration 27, loss = 0.38124905\nIteration 28, loss = 0.34945305\nIteration 29, loss = 0.39112858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, loss = 0.36683963\nIteration 31, loss = 0.36377063\nIteration 32, loss = 0.33541586\nIteration 33, loss = 0.32983548\nIteration 34, loss = 0.35213536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 35, loss = 0.31638431\nIteration 36, loss = 0.30588997\nIteration 37, loss = 0.34621795\nIteration 38, loss = 0.29828125\nIteration 39, loss = 0.28430612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40, loss = 0.28846371\nIteration 41, loss = 0.29330332\nIteration 42, loss = 0.29906890\nIteration 43, loss = 0.31295173\nIteration 44, loss = 0.26525003\nIteration 45, loss = 0.28271423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 46, loss = 0.27804686\nIteration 47, loss = 0.28701585\nIteration 48, loss = 0.28017998\nIteration 49, loss = 0.27387883\nIteration 50, loss = 0.25086239\nIteration 1, loss = 2.58337001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.84636567\nIteration 3, loss = 1.63270040\nIteration 4, loss = 1.48769379\nIteration 5, loss = 1.37855175\nIteration 6, loss = 1.24950029\nIteration 7, loss = 1.10364461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.96453156\nIteration 9, loss = 0.86053572\nIteration 10, loss = 0.74803950\nIteration 11, loss = 0.67304833\nIteration 12, loss = 0.63678122\nIteration 13, loss = 0.59669470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 0.54810404\nIteration 15, loss = 0.55712919\nIteration 16, loss = 0.52292658\nIteration 17, loss = 0.49155122\nIteration 18, loss = 0.47879658\nIteration 19, loss = 0.47345707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, loss = 0.42730693\nIteration 21, loss = 0.42616289\nIteration 22, loss = 0.40681854\nIteration 23, loss = 0.40275021\nIteration 24, loss = 0.37288605\nIteration 25, loss = 0.37258478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26, loss = 0.36823466\nIteration 27, loss = 0.36847654\nIteration 28, loss = 0.35064140\nIteration 29, loss = 0.32581486\nIteration 30, loss = 0.33179621\nIteration 31, loss = 0.34026160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32, loss = 0.32760287\nIteration 33, loss = 0.31935175\nIteration 34, loss = 0.31652392\nIteration 35, loss = 0.35484587\nIteration 36, loss = 0.33916693\nIteration 37, loss = 0.30876473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38, loss = 0.32822439\nIteration 39, loss = 0.30281058\nIteration 40, loss = 0.30216314\nIteration 41, loss = 0.30415957\nIteration 42, loss = 0.28330181\nIteration 43, loss = 0.30626783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44, loss = 0.30905266\nIteration 45, loss = 0.26989424\nIteration 46, loss = 0.26073965\nIteration 47, loss = 0.27630957\nIteration 48, loss = 0.27951298\nIteration 49, loss = 0.27573893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50, loss = 0.29009398\nIteration 1, loss = 2.73549157\nIteration 2, loss = 2.14565082\nIteration 3, loss = 1.99235153\nIteration 4, loss = 1.79401824\nIteration 5, loss = 1.68062034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.58638906\nIteration 7, loss = 1.52058311\nIteration 8, loss = 1.45668356\nIteration 9, loss = 1.40639482\nIteration 10, loss = 1.35819729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 1.29592945\nIteration 12, loss = 1.23892444\nIteration 13, loss = 1.15353933\nIteration 14, loss = 1.10817901\nIteration 15, loss = 1.07379264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 1.06148334\nIteration 17, loss = 1.05830509\nIteration 18, loss = 1.01377655\nIteration 19, loss = 0.99058802\nIteration 20, loss = 0.99737295\nIteration 21, loss = 0.97103338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22, loss = 0.95446344\nIteration 23, loss = 0.92709406\nIteration 24, loss = 0.91054695\nIteration 25, loss = 0.92294464\nIteration 26, loss = 0.89034691\nIteration 27, loss = 0.88194400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28, loss = 0.87853588\nIteration 29, loss = 0.87483719\nIteration 30, loss = 0.86773819\nIteration 31, loss = 0.84261189\nIteration 32, loss = 0.87476794\nIteration 33, loss = 0.85492594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34, loss = 0.83544742\nIteration 35, loss = 0.82454694\nIteration 36, loss = 0.80550652\nIteration 37, loss = 0.79833270\nIteration 38, loss = 0.84231338\nIteration 39, loss = 0.79663134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40, loss = 0.76851857\nIteration 41, loss = 0.78380823\nIteration 42, loss = 0.78643893\nIteration 43, loss = 0.77642212\nIteration 44, loss = 0.75409304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45, loss = 0.77594159\nIteration 46, loss = 0.77413955\nIteration 47, loss = 0.80173279\nIteration 48, loss = 0.74808524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 49, loss = 0.77465276\nIteration 50, loss = 0.73778178\nIteration 1, loss = 2.27837500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 2.04193522\nIteration 3, loss = 1.96073611\nIteration 4, loss = 1.93288713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 1.89115282\nIteration 6, loss = 1.86078938\nIteration 7, loss = 1.89485071\nIteration 8, loss = 1.84591455\nIteration 9, loss = 1.83376663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.80726848\nIteration 11, loss = 1.80535073\nIteration 12, loss = 1.70717240\nIteration 13, loss = 1.75467327\nIteration 14, loss = 1.70565257\nIteration 15, loss = 1.64861854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 1.64005228\nIteration 17, loss = 1.66631893\nIteration 18, loss = 1.61192363\nIteration 19, loss = 1.62713425\nIteration 20, loss = 1.61671072\nIteration 21, loss = 1.61392506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22, loss = 1.61398842\nIteration 23, loss = 1.63109041\nIteration 24, loss = 1.59214862\nIteration 25, loss = 1.60767800\nIteration 26, loss = 1.59473168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, loss = 1.57604866\nIteration 28, loss = 1.61838259\nIteration 29, loss = 1.57817060\nIteration 30, loss = 1.57303904\nIteration 31, loss = 1.58426130\nIteration 32, loss = 1.59767874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33, loss = 1.54874257\nIteration 34, loss = 1.54820133\nIteration 35, loss = 1.56968915\nIteration 36, loss = 1.60420858\nIteration 37, loss = 1.60248626\nIteration 38, loss = 1.52440810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39, loss = 1.53700779\nIteration 40, loss = 1.55660996\nIteration 41, loss = 1.54992238\nIteration 42, loss = 1.53228886\nIteration 43, loss = 1.54181569\nIteration 44, loss = 1.52009138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45, loss = 1.56882502\nIteration 46, loss = 1.50095936\nIteration 47, loss = 1.54411394\nIteration 48, loss = 1.51593991\nIteration 49, loss = 1.49560437\nIteration 50, loss = 1.52454413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.35199328\nIteration 2, loss = 2.07255698\nIteration 3, loss = 1.95386573\nIteration 4, loss = 1.90448613\nIteration 5, loss = 1.88015632\nIteration 6, loss = 1.89997379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.86705122\nIteration 8, loss = 1.85651017\nIteration 9, loss = 1.83716652\nIteration 10, loss = 1.82737810\nIteration 11, loss = 1.78441513\nIteration 12, loss = 1.77993889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 1.76949654\nIteration 14, loss = 1.79786447\nIteration 15, loss = 1.76175515\nIteration 16, loss = 1.79221573\nIteration 17, loss = 1.76526748\nIteration 18, loss = 1.73772506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 1.72752468\nIteration 20, loss = 1.71410216\nIteration 21, loss = 1.77168697\nIteration 22, loss = 1.70424444\nIteration 23, loss = 1.69749782\nIteration 24, loss = 1.71123667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25, loss = 1.73724937\nIteration 26, loss = 1.72887627\nIteration 27, loss = 1.69583561\nIteration 28, loss = 1.66888746\nIteration 29, loss = 1.65037498\nIteration 30, loss = 1.66637098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31, loss = 1.63895118\nIteration 32, loss = 1.66546873\nIteration 33, loss = 1.62944750\nIteration 34, loss = 1.69812564\nIteration 35, loss = 1.62176220\nIteration 36, loss = 1.62094325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 37, loss = 1.64623880\nIteration 38, loss = 1.61401568\nIteration 39, loss = 1.63413098\nIteration 40, loss = 1.61106542\nIteration 41, loss = 1.63219019\nIteration 42, loss = 1.60005484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43, loss = 1.63705152\nIteration 44, loss = 1.57668129\nIteration 45, loss = 1.62115863\nIteration 46, loss = 1.59154042\nIteration 47, loss = 1.64099998\nIteration 48, loss = 1.57658154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 49, loss = 1.58514415\nIteration 50, loss = 1.58591764\nIteration 1, loss = 2.36670110\nIteration 2, loss = 2.07538743\nIteration 3, loss = 2.04436976\nIteration 4, loss = 1.98421281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 1.99460947\nIteration 6, loss = 1.94020163\nIteration 7, loss = 1.95278940\nIteration 8, loss = 1.90379719\nIteration 9, loss = 1.89954693\nIteration 10, loss = 1.89664375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 1.84881962\nIteration 12, loss = 1.81678500\nIteration 13, loss = 1.75704106\nIteration 14, loss = 1.74724811\nIteration 15, loss = 1.74756769\nIteration 16, loss = 1.76968920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, loss = 1.68769478\nIteration 18, loss = 1.68130787\nIteration 19, loss = 1.68515997\nIteration 20, loss = 1.66822987\nIteration 21, loss = 1.64089800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22, loss = 1.65968423\nIteration 23, loss = 1.61304575\nIteration 24, loss = 1.61788408\nIteration 25, loss = 1.66547338\nIteration 26, loss = 1.62051097\nIteration 27, loss = 1.60245036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28, loss = 1.58339635\nIteration 29, loss = 1.57498235\nIteration 30, loss = 1.62243611\nIteration 31, loss = 1.63133256\nIteration 32, loss = 1.56309693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33, loss = 1.58333051\nIteration 34, loss = 1.64214781\nIteration 35, loss = 1.61196119\nIteration 36, loss = 1.58586230\nIteration 37, loss = 1.62086206\nIteration 38, loss = 1.60245723\nIteration 39, loss = 1.59124594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40, loss = 1.57833953\nIteration 41, loss = 1.55961141\nIteration 42, loss = 1.57772288\nIteration 43, loss = 1.58891033\nIteration 44, loss = 1.60678321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45, loss = 1.56825263\nIteration 46, loss = 1.58677633\nIteration 47, loss = 1.55709537\nIteration 48, loss = 1.61004365\nIteration 49, loss = 1.57850479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50, loss = 1.59578665\nIteration 1, loss = 2.36315195\nIteration 2, loss = 2.31588687\nIteration 3, loss = 2.31577247\nIteration 4, loss = 2.31737420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 2.31906005\nIteration 6, loss = 2.31779321\nIteration 7, loss = 2.31470859\nIteration 8, loss = 2.31836684\nIteration 9, loss = 2.31821448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 2.31791005\nIteration 11, loss = 2.31639945\nIteration 12, loss = 2.31860644\nIteration 13, loss = 2.31792746\nIteration 14, loss = 2.31952099\nIteration 15, loss = 2.31572360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 2.31606773\nIteration 17, loss = 2.32103050\nIteration 18, loss = 2.31710913\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.35225561\nIteration 2, loss = 2.30353207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 2.31591864\nIteration 4, loss = 2.31446197\nIteration 5, loss = 2.31883737\nIteration 6, loss = 2.31939219\nIteration 7, loss = 2.31639682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 2.31730611\nIteration 9, loss = 2.31903283\nIteration 10, loss = 2.31304588\nIteration 11, loss = 2.31509482\nIteration 12, loss = 2.31989082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 2.31739062\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.40165435\nIteration 2, loss = 2.31942003\nIteration 3, loss = 2.31661664\nIteration 4, loss = 2.31817430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 2.31734607\nIteration 6, loss = 2.31655528\nIteration 7, loss = 2.31504741\nIteration 8, loss = 2.32049041\nIteration 9, loss = 2.31462210\nIteration 10, loss = 2.32140343\nIteration 11, loss = 2.31514197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 2.31855398\nIteration 13, loss = 2.31799191\nIteration 14, loss = 2.31314626\nIteration 15, loss = 2.31619981\nIteration 16, loss = 2.32033361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, loss = 2.31909861\nIteration 18, loss = 2.31735015\nIteration 19, loss = 2.31975266\nIteration 20, loss = 2.31915294\nIteration 21, loss = 2.31895861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22, loss = 2.32054174\nIteration 23, loss = 2.31876351\nIteration 24, loss = 2.31558152\nIteration 25, loss = 2.31988959\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.42590326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 2.34186788\nIteration 3, loss = 2.34217126\nIteration 4, loss = 2.33758409\nIteration 5, loss = 2.34782260\nIteration 6, loss = 2.33992287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 2.34031063\nIteration 8, loss = 2.34402607\nIteration 9, loss = 2.34590684\nIteration 10, loss = 2.34398592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 2.34332403\nIteration 12, loss = 2.34975565\nIteration 13, loss = 2.33897776\nIteration 14, loss = 2.34765027\nIteration 15, loss = 2.34337575\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.37544541\nIteration 2, loss = 2.34898144\nIteration 3, loss = 2.34442317\nIteration 4, loss = 2.33292624\nIteration 5, loss = 2.34464694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 2.34800303\nIteration 7, loss = 2.34346644\nIteration 8, loss = 2.34714878\nIteration 9, loss = 2.35079557\nIteration 10, loss = 2.33744307\nIteration 11, loss = 2.33576056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 2.34585398\nIteration 13, loss = 2.34442521\nIteration 14, loss = 2.33977674\nIteration 15, loss = 2.35142389\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.43476221\nIteration 2, loss = 2.35237872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 2.35363219\nIteration 4, loss = 2.34568903\nIteration 5, loss = 2.34307880\nIteration 6, loss = 2.34216020\nIteration 7, loss = 2.33410702\nIteration 8, loss = 2.34749738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 2.33743844\nIteration 10, loss = 2.35647532\nIteration 11, loss = 2.32218362\nIteration 12, loss = 2.35114039\nIteration 13, loss = 2.34574086\nIteration 14, loss = 2.33616888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15, loss = 2.33661904\nIteration 16, loss = 2.35240807\nIteration 17, loss = 2.35084713\nIteration 18, loss = 2.34261578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 2.35156049\nIteration 20, loss = 2.34775315\nIteration 21, loss = 2.34947536\nIteration 22, loss = 2.35255430\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.29764859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.41465942\nIteration 3, loss = 1.10224313\nIteration 4, loss = 0.95237421\nIteration 5, loss = 0.78842839\nIteration 6, loss = 0.65500561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.54053136\nIteration 8, loss = 0.45503111\nIteration 9, loss = 0.35894628\nIteration 10, loss = 0.30793247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.25057481\nIteration 12, loss = 0.19770644\nIteration 13, loss = 0.16191866\nIteration 14, loss = 0.15640696\nIteration 15, loss = 0.13544798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 0.11564101\nIteration 17, loss = 0.11142997\nIteration 18, loss = 0.08974423\nIteration 19, loss = 0.07857777\nIteration 20, loss = 0.07325163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21, loss = 0.09184740\nIteration 22, loss = 0.07936163\nIteration 23, loss = 0.08501916\nIteration 24, loss = 0.04876904\nIteration 25, loss = 0.04298425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26, loss = 0.02760638\nIteration 27, loss = 0.03254354\nIteration 28, loss = 0.05180872\nIteration 29, loss = 0.03004789\nIteration 30, loss = 0.03785914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31, loss = 0.07450015\nIteration 32, loss = 0.03700185\nIteration 33, loss = 0.04759500\nIteration 34, loss = 0.02611865\nIteration 35, loss = 0.01650322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 36, loss = 0.01127167\nIteration 37, loss = 0.00824513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38, loss = 0.00649599\nIteration 39, loss = 0.00735920\nIteration 40, loss = 0.00606827\nIteration 41, loss = 0.00486504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 42, loss = 0.00514693\nIteration 43, loss = 0.00419010\nIteration 44, loss = 0.00399936\nIteration 45, loss = 0.00373993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 46, loss = 0.00366421\nIteration 47, loss = 0.00370843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 48, loss = 0.00337045\nIteration 49, loss = 0.00341451\nIteration 50, loss = 0.00446814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.24661443\nIteration 2, loss = 1.42092715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.05042679\nIteration 4, loss = 0.76167581\nIteration 5, loss = 0.57551469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.46268823\nIteration 7, loss = 0.38308709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.30281621\nIteration 9, loss = 0.26429476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.22659138\nIteration 11, loss = 0.19535463\nIteration 12, loss = 0.16326331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 0.18907138\nIteration 14, loss = 0.16457124\nIteration 15, loss = 0.16469188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 0.14488990\nIteration 17, loss = 0.13043906\nIteration 18, loss = 0.11463752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 0.10228160\nIteration 20, loss = 0.10856534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21, loss = 0.10453597\nIteration 22, loss = 0.07189136\nIteration 23, loss = 0.09036508\nIteration 24, loss = 0.13588108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25, loss = 0.07578763\nIteration 26, loss = 0.08954882\nIteration 27, loss = 0.06582144\nIteration 28, loss = 0.06739009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29, loss = 0.05599890\nIteration 30, loss = 0.04777437\nIteration 31, loss = 0.03978342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32, loss = 0.04864563\nIteration 33, loss = 0.06906334\nIteration 34, loss = 0.03630012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 35, loss = 0.05154847\nIteration 36, loss = 0.05544606\nIteration 37, loss = 0.02641584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38, loss = 0.02675064\nIteration 39, loss = 0.04645588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40, loss = 0.03048086\nIteration 41, loss = 0.04158025\nIteration 42, loss = 0.07763079\nIteration 43, loss = 0.03823739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44, loss = 0.03479247\nIteration 45, loss = 0.02880193\nIteration 46, loss = 0.02197859\nIteration 47, loss = 0.01820414\nIteration 48, loss = 0.01795519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 49, loss = 0.01627441\nIteration 50, loss = 0.01144612\nIteration 1, loss = 2.26122604\nIteration 2, loss = 1.40716808\nIteration 3, loss = 1.01957391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.69331984\nIteration 5, loss = 0.55382837\nIteration 6, loss = 0.44078733\nIteration 7, loss = 0.35423003\nIteration 8, loss = 0.29892673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.27754189\nIteration 10, loss = 0.20991058\nIteration 11, loss = 0.18605243\nIteration 12, loss = 0.18194626\nIteration 13, loss = 0.16566275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 0.15609487\nIteration 15, loss = 0.14399873\nIteration 16, loss = 0.13502818\nIteration 17, loss = 0.13070647\nIteration 18, loss = 0.11313677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 0.10653630\nIteration 20, loss = 0.11851661\nIteration 21, loss = 0.08311608\nIteration 22, loss = 0.07634802\nIteration 23, loss = 0.10625991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24, loss = 0.08631640\nIteration 25, loss = 0.10028046\nIteration 26, loss = 0.06074876\nIteration 27, loss = 0.06710367\nIteration 28, loss = 0.06502636\nIteration 29, loss = 0.06551960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, loss = 0.05752702\nIteration 31, loss = 0.06914832\nIteration 32, loss = 0.05914236\nIteration 33, loss = 0.04313314\nIteration 34, loss = 0.04126549\nIteration 35, loss = 0.06548184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 36, loss = 0.05805756\nIteration 37, loss = 0.04707773\nIteration 38, loss = 0.03840804\nIteration 39, loss = 0.03919691\nIteration 40, loss = 0.05905416\nIteration 41, loss = 0.07802439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 42, loss = 0.02399114\nIteration 43, loss = 0.01876328\nIteration 44, loss = 0.02380504\nIteration 45, loss = 0.03126598\nIteration 46, loss = 0.07179775\nIteration 47, loss = 0.03188933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 48, loss = 0.06713779\nIteration 49, loss = 0.05164643\nIteration 50, loss = 0.01951848\nIteration 1, loss = 1.90828490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.43511211\nIteration 3, loss = 1.27736076\nIteration 4, loss = 1.16585989\nIteration 5, loss = 1.10437848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.23056016\nIteration 7, loss = 1.03731872\nIteration 8, loss = 1.09125611\nIteration 9, loss = 0.97237740\nIteration 10, loss = 0.85854388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.84617937\nIteration 12, loss = 0.90580676\nIteration 13, loss = 0.85071028\nIteration 14, loss = 0.76964830\nIteration 15, loss = 0.73414580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 0.69660514\nIteration 17, loss = 0.80491132\nIteration 18, loss = 0.76023773\nIteration 19, loss = 0.76292270\nIteration 20, loss = 0.78458492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21, loss = 0.69993918\nIteration 22, loss = 0.74500025\nIteration 23, loss = 0.71040868\nIteration 24, loss = 0.71059848\nIteration 25, loss = 0.66919152\nIteration 26, loss = 0.61353466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, loss = 0.62342110\nIteration 28, loss = 0.70579911\nIteration 29, loss = 0.61396975\nIteration 30, loss = 0.63478436\nIteration 31, loss = 0.63011608\nIteration 32, loss = 0.62373957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33, loss = 0.60748255\nIteration 34, loss = 0.63559275\nIteration 35, loss = 0.76994515\nIteration 36, loss = 0.68543471\nIteration 37, loss = 0.57368284\nIteration 38, loss = 0.56024133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39, loss = 0.61750569\nIteration 40, loss = 0.63097774\nIteration 41, loss = 0.64536917\nIteration 42, loss = 0.53057364\nIteration 43, loss = 0.52812597\nIteration 44, loss = 0.58195448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45, loss = 0.49396655\nIteration 46, loss = 0.51691611\nIteration 47, loss = 0.49565697\nIteration 48, loss = 0.54382349\nIteration 49, loss = 0.58450686\nIteration 50, loss = 0.57406908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.19535858\nIteration 2, loss = 1.68634146\nIteration 3, loss = 1.33591467\nIteration 4, loss = 1.14986626\nIteration 5, loss = 1.08050664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.90549728\nIteration 7, loss = 0.86843642\nIteration 8, loss = 0.89253922\nIteration 9, loss = 0.84221309\nIteration 10, loss = 0.75972306\nIteration 11, loss = 0.68692285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.70689310\nIteration 13, loss = 0.66186691\nIteration 14, loss = 0.70018845\nIteration 15, loss = 0.65379330\nIteration 16, loss = 0.66104497\nIteration 17, loss = 0.67033201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18, loss = 0.72344330\nIteration 19, loss = 0.64357741\nIteration 20, loss = 0.61854268\nIteration 21, loss = 0.62051257\nIteration 22, loss = 0.62946620\nIteration 23, loss = 0.64286271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24, loss = 0.60486045\nIteration 25, loss = 0.60729347\nIteration 26, loss = 0.68454514\nIteration 27, loss = 0.59278418\nIteration 28, loss = 0.57303496\nIteration 29, loss = 0.59691173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, loss = 0.61635460\nIteration 31, loss = 0.54218114\nIteration 32, loss = 0.55219910\nIteration 33, loss = 0.63966136\nIteration 34, loss = 0.61481548\nIteration 35, loss = 0.56291215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 36, loss = 0.56100327\nIteration 37, loss = 0.56286863\nIteration 38, loss = 0.54921900\nIteration 39, loss = 0.52187104\nIteration 40, loss = 0.52065177\nIteration 41, loss = 0.48165515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 42, loss = 0.56668508\nIteration 43, loss = 0.54203260\nIteration 44, loss = 0.53933342\nIteration 45, loss = 0.64296767\nIteration 46, loss = 0.52549907\nIteration 47, loss = 0.60075293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 48, loss = 0.62797679\nIteration 49, loss = 0.54935776\nIteration 50, loss = 0.52176876\nIteration 1, loss = 1.91475399\nIteration 2, loss = 1.34579848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.19451224\nIteration 4, loss = 1.09366093\nIteration 5, loss = 0.95633924\nIteration 6, loss = 0.94411909\nIteration 7, loss = 0.83807477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.79260948\nIteration 9, loss = 0.67479384\nIteration 10, loss = 0.70792550\nIteration 11, loss = 0.67367043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.63232773\nIteration 13, loss = 0.65407304\nIteration 14, loss = 0.61816420\nIteration 15, loss = 0.69017992\nIteration 16, loss = 0.63189520\nIteration 17, loss = 0.60903619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18, loss = 0.57218593\nIteration 19, loss = 0.64413614\nIteration 20, loss = 0.63917002\nIteration 21, loss = 0.66338427\nIteration 22, loss = 0.54540500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23, loss = 0.48233940\nIteration 24, loss = 0.52108736\nIteration 25, loss = 0.55927386\nIteration 26, loss = 0.53141219\nIteration 27, loss = 0.52839196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28, loss = 0.53210999\nIteration 29, loss = 0.57868521\nIteration 30, loss = 0.49392777\nIteration 31, loss = 0.46486489\nIteration 32, loss = 0.45448452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33, loss = 0.47377110\nIteration 34, loss = 0.51848531\nIteration 35, loss = 0.49810599\nIteration 36, loss = 0.43815313\nIteration 37, loss = 0.48264621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38, loss = 0.41568389\nIteration 39, loss = 0.65003454\nIteration 40, loss = 0.51531746\nIteration 41, loss = 0.39154637\nIteration 42, loss = 0.42561639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43, loss = 0.43467091\nIteration 44, loss = 0.41281347\nIteration 45, loss = 0.57887341\nIteration 46, loss = 0.47342079\nIteration 47, loss = 0.37179260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 48, loss = 0.31340473\nIteration 49, loss = 0.31335793\nIteration 50, loss = 0.38360144\nIteration 1, loss = 2.45633345\nIteration 2, loss = 2.32188290\nIteration 3, loss = 2.31767248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 2.31419737\nIteration 5, loss = 2.31829490\nIteration 6, loss = 2.31742705\nIteration 7, loss = 2.31955846\nIteration 8, loss = 2.31570535\nIteration 9, loss = 2.31691693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 2.32035640\nIteration 11, loss = 2.31568339\nIteration 12, loss = 2.31955303\nIteration 13, loss = 2.31833001\nIteration 14, loss = 2.31883780\nIteration 15, loss = 2.32087041\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.42091502\nIteration 2, loss = 2.31689632\nIteration 3, loss = 2.31773383\nIteration 4, loss = 2.31703853\nIteration 5, loss = 2.32283719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 2.31921784\nIteration 7, loss = 2.31912474\nIteration 8, loss = 2.31698140\nIteration 9, loss = 2.31571137\nIteration 10, loss = 2.31822340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 2.31629386\nIteration 12, loss = 2.31544727\nIteration 13, loss = 2.31811292\nIteration 14, loss = 2.31919070\nIteration 15, loss = 2.31722976\nIteration 16, loss = 2.31707320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, loss = 2.32050632\nIteration 18, loss = 2.31750219\nIteration 19, loss = 2.31554376\nIteration 20, loss = 2.31845578\nIteration 21, loss = 2.31942142\nIteration 22, loss = 2.31817113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23, loss = 2.31775843\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.21493958\nIteration 2, loss = 1.97690602\nIteration 3, loss = 2.00893015\nIteration 4, loss = 2.00219248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 2.13933196\nIteration 6, loss = 2.36293540\nIteration 7, loss = 2.31574244\nIteration 8, loss = 2.31967322\nIteration 9, loss = 2.31636024\nIteration 10, loss = 2.31748741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 2.31906649\nIteration 12, loss = 2.32109401\nIteration 13, loss = 2.31625562\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.53389382\nIteration 2, loss = 2.35231311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 2.35036023\nIteration 4, loss = 2.34202452\nIteration 5, loss = 2.35099483\nIteration 6, loss = 2.34230066\nIteration 7, loss = 2.34281874\nIteration 8, loss = 2.34611999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 2.35407819\nIteration 10, loss = 2.35147753\nIteration 11, loss = 2.34269665\nIteration 12, loss = 2.34126865\nIteration 13, loss = 2.35171609\nIteration 14, loss = 2.34960931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15, loss = 2.35331496\nIteration 16, loss = 2.33931634\nIteration 17, loss = 2.33557535\nIteration 18, loss = 2.34439652\nIteration 19, loss = 2.35272351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, loss = 2.35559851\nIteration 21, loss = 2.35962132\nIteration 22, loss = 2.34877912\nIteration 23, loss = 2.35242533\nIteration 24, loss = 2.34375631\nIteration 25, loss = 2.33802161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26, loss = 2.34838321\nIteration 27, loss = 2.34566775\nIteration 28, loss = 2.34132487\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.55676583\nIteration 2, loss = 2.34444383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 2.34867747\nIteration 4, loss = 2.34889332\nIteration 5, loss = 2.35013184\nIteration 6, loss = 2.35412749\nIteration 7, loss = 2.35413695\nIteration 8, loss = 2.34714060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 2.34466896\nIteration 10, loss = 2.34627298\nIteration 11, loss = 2.34011205\nIteration 12, loss = 2.33842559\nIteration 13, loss = 2.33971020\nIteration 14, loss = 2.35101528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15, loss = 2.34516417\nIteration 16, loss = 2.33968118\nIteration 17, loss = 2.35301079\nIteration 18, loss = 2.35121879\nIteration 19, loss = 2.34296918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, loss = 2.35071736\nIteration 21, loss = 2.35546086\nIteration 22, loss = 2.34238437\nIteration 23, loss = 2.34635409\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.60041329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 2.32935643\nIteration 3, loss = 2.35660550\nIteration 4, loss = 2.33786710\nIteration 5, loss = 2.35778479\nIteration 6, loss = 2.34665081\nIteration 7, loss = 2.34528352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 2.34741310\nIteration 9, loss = 2.34304337\nIteration 10, loss = 2.34520262\nIteration 11, loss = 2.35081542\nIteration 12, loss = 2.35832903\nIteration 13, loss = 2.34260289\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.41655604\nIteration 2, loss = 0.70282986\nIteration 3, loss = 0.38127703\nIteration 4, loss = 0.25444418\nIteration 5, loss = 0.18487207\nIteration 6, loss = 0.11775206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.10111706\nIteration 8, loss = 0.09916305\nIteration 9, loss = 0.06908754\nIteration 10, loss = 0.06140660\nIteration 11, loss = 0.03457479\nIteration 12, loss = 0.03538462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 0.02714350\nIteration 14, loss = 0.02799539\nIteration 15, loss = 0.06525284\nIteration 16, loss = 0.02594850\nIteration 17, loss = 0.01335512\nIteration 18, loss = 0.00881750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 0.00759059\nIteration 20, loss = 0.00759768\nIteration 21, loss = 0.00542744\nIteration 22, loss = 0.00488006\nIteration 23, loss = 0.00784048\nIteration 24, loss = 0.05885208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25, loss = 0.11329940\nIteration 26, loss = 0.11726400\nIteration 27, loss = 0.04437205\nIteration 28, loss = 0.00660715\nIteration 29, loss = 0.00325414\nIteration 30, loss = 0.00262402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31, loss = 0.00234908\nIteration 32, loss = 0.00221036\nIteration 33, loss = 0.00218907\nIteration 34, loss = 0.00195182\nIteration 35, loss = 0.00185223\nIteration 36, loss = 0.00173277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 37, loss = 0.00186036\nIteration 38, loss = 0.00179676\nIteration 39, loss = 0.00185047\nIteration 40, loss = 0.00157997\nIteration 41, loss = 0.00139651\nIteration 42, loss = 0.00136136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43, loss = 0.00137773\nIteration 44, loss = 0.00133064\nIteration 45, loss = 0.00126823\nIteration 46, loss = 0.00125711\nIteration 47, loss = 0.00120098\nIteration 48, loss = 0.00118658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 49, loss = 0.00114798\nIteration 50, loss = 0.00115437\nIteration 1, loss = 2.45924381\nIteration 2, loss = 0.69125483\nIteration 3, loss = 0.38270123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.22811031\nIteration 5, loss = 0.17494969\nIteration 6, loss = 0.13016239\nIteration 7, loss = 0.10419940\nIteration 8, loss = 0.08545278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.06147556\nIteration 10, loss = 0.04259245\nIteration 11, loss = 0.05363305\nIteration 12, loss = 0.05017373\nIteration 13, loss = 0.03553101\nIteration 14, loss = 0.02262120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15, loss = 0.02592850\nIteration 16, loss = 0.02325249\nIteration 17, loss = 0.02716618\nIteration 18, loss = 0.01302562\nIteration 19, loss = 0.00661391\nIteration 20, loss = 0.00626302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21, loss = 0.00600941\nIteration 22, loss = 0.00452226\nIteration 23, loss = 0.00386055\nIteration 24, loss = 0.00359502\nIteration 25, loss = 0.00387658\nIteration 26, loss = 0.00313205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, loss = 0.00291534\nIteration 28, loss = 0.00287203\nIteration 29, loss = 0.00235077\nIteration 30, loss = 0.00223116\nIteration 31, loss = 0.00273552\nIteration 32, loss = 0.00207961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33, loss = 0.00214381\nIteration 34, loss = 0.00183696\nIteration 35, loss = 0.00183630\nIteration 36, loss = 0.00158519\nIteration 37, loss = 0.00168212\nIteration 38, loss = 0.00144066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39, loss = 0.00137801\nIteration 40, loss = 0.00147760\nIteration 41, loss = 0.00133797\nIteration 42, loss = 0.00125320\nIteration 43, loss = 0.00119036\nIteration 44, loss = 0.00111339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45, loss = 0.00107709\nIteration 46, loss = 0.00107393\nIteration 47, loss = 0.00134413\nIteration 48, loss = 0.67074820\nIteration 49, loss = 0.15785070\nIteration 50, loss = 0.05736353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.44202081\nIteration 2, loss = 0.75030265\nIteration 3, loss = 0.38266510\nIteration 4, loss = 0.28033575\nIteration 5, loss = 0.18245602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.13423131\nIteration 7, loss = 0.08573289\nIteration 8, loss = 0.08056985\nIteration 9, loss = 0.06828508\nIteration 10, loss = 0.04704914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.03601833\nIteration 12, loss = 0.03840447\nIteration 13, loss = 0.03741485\nIteration 14, loss = 0.02415704\nIteration 15, loss = 0.01865532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 0.01326147\nIteration 17, loss = 0.01133505\nIteration 18, loss = 0.00977782\nIteration 19, loss = 0.00733115\nIteration 20, loss = 0.00629396\nIteration 21, loss = 0.00543729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22, loss = 0.00526273\nIteration 23, loss = 0.00486661\nIteration 24, loss = 0.00458082\nIteration 25, loss = 0.00468253\nIteration 26, loss = 0.00366622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, loss = 0.00335265\nIteration 28, loss = 0.00266433\nIteration 29, loss = 0.00270864\nIteration 30, loss = 0.00218557\nIteration 31, loss = 0.00262057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32, loss = 0.00220619\nIteration 33, loss = 0.00179571\nIteration 34, loss = 0.00169963\nIteration 35, loss = 0.00170117\nIteration 36, loss = 0.00152867\nIteration 37, loss = 0.00139895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38, loss = 0.00138282\nIteration 39, loss = 0.00133863\nIteration 40, loss = 0.00124402\nIteration 41, loss = 0.00119195\nIteration 42, loss = 0.00116260\nIteration 43, loss = 0.00110488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44, loss = 0.00666695\nIteration 45, loss = 0.66775784\nIteration 46, loss = 0.12520547\nIteration 47, loss = 0.12299004\nIteration 48, loss = 0.02008522\nIteration 49, loss = 0.01610476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50, loss = 0.01478266\nIteration 1, loss = 1.87807093\nIteration 2, loss = 0.70258481\nIteration 3, loss = 0.42113975\nIteration 4, loss = 0.46481117\nIteration 5, loss = 0.37657534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.29745578\nIteration 7, loss = 0.25117716\nIteration 8, loss = 0.20789843\nIteration 9, loss = 0.18411901\nIteration 10, loss = 0.43150416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.18295148\nIteration 12, loss = 0.16221583\nIteration 13, loss = 0.24180291\nIteration 14, loss = 0.23222882\nIteration 15, loss = 0.13904951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 0.38879664\nIteration 17, loss = 0.09717063\nIteration 18, loss = 0.29645620\nIteration 19, loss = 0.11783793\nIteration 20, loss = 0.15312630\nIteration 21, loss = 0.06528780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22, loss = 0.02495774\nIteration 23, loss = 0.05616285\nIteration 24, loss = 0.13484962\nIteration 25, loss = 0.52873427\nIteration 26, loss = 0.10921711\nIteration 27, loss = 0.09082360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28, loss = 0.32342137\nIteration 29, loss = 0.07507615\nIteration 30, loss = 0.01027053\nIteration 31, loss = 0.00419749\nIteration 32, loss = 0.00320041\nIteration 33, loss = 0.00306795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34, loss = 0.00296132\nIteration 35, loss = 0.00289685\nIteration 36, loss = 0.00284430\nIteration 37, loss = 0.00279902\nIteration 38, loss = 0.00275273\nIteration 39, loss = 0.00271234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40, loss = 0.00267192\nIteration 41, loss = 0.00264817\nIteration 42, loss = 0.00262092\nIteration 43, loss = 0.00259602\nIteration 44, loss = 0.00256324\nIteration 45, loss = 0.00253917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 46, loss = 0.00251330\nIteration 47, loss = 0.00249286\nIteration 48, loss = 0.00246136\nIteration 49, loss = 0.00244061\nIteration 50, loss = 0.00241655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.99966346\nIteration 2, loss = 1.12901566\nIteration 3, loss = 0.90360564\nIteration 4, loss = 0.68002899\nIteration 5, loss = 0.56941438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.45794727\nIteration 7, loss = 0.44571099\nIteration 8, loss = 0.33687689\nIteration 9, loss = 0.37406790\nIteration 10, loss = 0.38418657\nIteration 11, loss = 0.35851120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.34811747\nIteration 13, loss = 0.38050193\nIteration 14, loss = 0.41627203\nIteration 15, loss = 0.32356277\nIteration 16, loss = 0.24925852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, loss = 0.24193840\nIteration 18, loss = 0.25376053\nIteration 19, loss = 0.26355707\nIteration 20, loss = 0.21624448\nIteration 21, loss = 0.27008907\nIteration 22, loss = 0.19531396\nIteration 23, loss = 0.32208241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24, loss = 0.33877178\nIteration 25, loss = 0.23485746\nIteration 26, loss = 0.28162511\nIteration 27, loss = 0.20790692\nIteration 28, loss = 0.23423716\nIteration 29, loss = 0.29410149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, loss = 0.22087436\nIteration 31, loss = 0.20963272\nIteration 32, loss = 0.21250340\nIteration 33, loss = 0.20916908\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 1.91561846\nIteration 2, loss = 0.86929956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.64297197\nIteration 4, loss = 0.54707983\nIteration 5, loss = 0.47881725\nIteration 6, loss = 0.39358675\nIteration 7, loss = 0.32808037\nIteration 8, loss = 0.25374292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.28610417\nIteration 10, loss = 0.22878197\nIteration 11, loss = 0.27168861\nIteration 12, loss = 0.25254887\nIteration 13, loss = 0.39051151\nIteration 14, loss = 0.20373596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15, loss = 0.16801511\nIteration 16, loss = 0.32081589\nIteration 17, loss = 0.37656748\nIteration 18, loss = 0.23273329\nIteration 19, loss = 0.10811428\nIteration 20, loss = 0.11724451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21, loss = 0.12836760\nIteration 22, loss = 0.12356523\nIteration 23, loss = 0.13887607\nIteration 24, loss = 0.19563331\nIteration 25, loss = 0.18621726\nIteration 26, loss = 0.11033321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, loss = 0.15478789\nIteration 28, loss = 0.15280757\nIteration 29, loss = 0.05907317\nIteration 30, loss = 0.08513897\nIteration 31, loss = 0.15581483\nIteration 32, loss = 0.46300019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33, loss = 0.17660091\nIteration 34, loss = 0.16802190\nIteration 35, loss = 0.18543881\nIteration 36, loss = 0.08499699\nIteration 37, loss = 0.08438067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38, loss = 0.06253754\nIteration 39, loss = 0.11883827\nIteration 40, loss = 0.13208013\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.46149593\nIteration 2, loss = 2.07597676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 2.28657048\nIteration 4, loss = 2.32303636\nIteration 5, loss = 2.31596717\nIteration 6, loss = 2.31841857\nIteration 7, loss = 2.32153043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 2.31875788\nIteration 9, loss = 2.31881765\nIteration 10, loss = 2.31841511\nIteration 11, loss = 2.31825599\nIteration 12, loss = 2.31986873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 2.31875457\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.30176338\nIteration 2, loss = 2.07212665\nIteration 3, loss = 2.01127462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.92312132\nIteration 5, loss = 2.01936802\nIteration 6, loss = 2.10712835\nIteration 7, loss = 2.01199047\nIteration 8, loss = 2.23310413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 2.34903450\nIteration 10, loss = 2.31652831\nIteration 11, loss = 2.31798646\nIteration 12, loss = 2.31705537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 2.31921886\nIteration 14, loss = 2.31833954\nIteration 15, loss = 2.32182161\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.18278514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.57470914\nIteration 3, loss = 1.41110855\nIteration 4, loss = 1.58978391\nIteration 5, loss = 1.72738436\nIteration 6, loss = 1.47058245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.28679694\nIteration 8, loss = 1.37729467\nIteration 9, loss = 1.24177928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.33955896\nIteration 11, loss = 1.34549328\nIteration 12, loss = 1.47528873\nIteration 13, loss = 1.48146950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 1.77462258\nIteration 15, loss = 1.48022693\nIteration 16, loss = 1.44456253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, loss = 1.36047666\nIteration 18, loss = 1.34292761\nIteration 19, loss = 1.46092385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, loss = 1.55103227\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.50859448\nIteration 2, loss = 2.34089742\nIteration 3, loss = 2.34907971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 2.35283914\nIteration 5, loss = 2.34048409\nIteration 6, loss = 2.34118115\nIteration 7, loss = 2.35823519\nIteration 8, loss = 2.35260948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 2.35224337\nIteration 10, loss = 2.34461685\nIteration 11, loss = 2.35718004\nIteration 12, loss = 2.34679573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 2.35575064\nIteration 14, loss = 2.35383313\nIteration 15, loss = 2.34812984\nIteration 16, loss = 2.34048402\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.66296638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 2.35120191\nIteration 3, loss = 2.34649369\nIteration 4, loss = 2.33940903\nIteration 5, loss = 2.35084423\nIteration 6, loss = 2.34818312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 2.33718498\nIteration 8, loss = 2.34518104\nIteration 9, loss = 2.33435322\nIteration 10, loss = 2.33818880\nIteration 11, loss = 2.34648542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 2.33663642\nIteration 13, loss = 2.35061741\nIteration 14, loss = 2.33810689\nIteration 15, loss = 2.35517487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 2.34853232\nIteration 17, loss = 2.34828499\nIteration 18, loss = 2.34402706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 2.33949042\nIteration 20, loss = 2.35096068\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.63369526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 2.33942477\nIteration 3, loss = 2.35089463\nIteration 4, loss = 2.34109506\nIteration 5, loss = 2.35222022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 2.34522636\nIteration 7, loss = 2.34716322\nIteration 8, loss = 2.34737858\nIteration 9, loss = 2.36070505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 2.35670766\nIteration 11, loss = 2.34488754\nIteration 12, loss = 2.34065643\nIteration 13, loss = 2.35986766\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.07282988\nIteration 2, loss = 0.43730157\nIteration 3, loss = 0.22026474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.15938376\nIteration 5, loss = 0.11785410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.09102182\nIteration 7, loss = 0.06046915\nIteration 8, loss = 0.04727117\nIteration 9, loss = 0.02671318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.01771407\nIteration 11, loss = 0.01114363\nIteration 12, loss = 0.00755562\nIteration 13, loss = 0.00948739\nIteration 14, loss = 0.01806603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15, loss = 0.02656145\nIteration 16, loss = 0.07363552\nIteration 17, loss = 0.17872410\nIteration 18, loss = 0.04742655\nIteration 19, loss = 0.00798746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, loss = 0.00334398\nIteration 21, loss = 0.00232019\nIteration 22, loss = 0.00199465\nIteration 23, loss = 0.00191330\nIteration 24, loss = 0.00173887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25, loss = 0.00166498\nIteration 26, loss = 0.00160918\nIteration 27, loss = 0.00149454\nIteration 28, loss = 0.00146051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29, loss = 0.00139724\nIteration 30, loss = 0.00135503\nIteration 31, loss = 0.00130759\nIteration 32, loss = 0.00127356\nIteration 33, loss = 0.00123901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34, loss = 0.00119134\nIteration 35, loss = 0.00113907\nIteration 36, loss = 0.00115960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 37, loss = 0.00111057\nIteration 38, loss = 0.00108417\nIteration 39, loss = 0.00105936\nIteration 40, loss = 0.00104331\nIteration 41, loss = 0.00101591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 42, loss = 0.00100052\nIteration 43, loss = 0.00098173\nIteration 44, loss = 0.00096313\nIteration 45, loss = 0.00094587\nIteration 46, loss = 0.00092842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 47, loss = 0.00091096\nIteration 48, loss = 0.00089645\nIteration 49, loss = 0.00088175\nIteration 50, loss = 0.00086899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.29656062\nIteration 2, loss = 0.52627519\nIteration 3, loss = 0.27648145\nIteration 4, loss = 0.19130974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.12196149\nIteration 6, loss = 0.08769443\nIteration 7, loss = 0.08448348\nIteration 8, loss = 0.03741910\nIteration 9, loss = 0.03168305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.03241678\nIteration 11, loss = 0.02307975\nIteration 12, loss = 0.01318335\nIteration 13, loss = 0.02914635\nIteration 14, loss = 0.05434991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15, loss = 0.01993258\nIteration 16, loss = 0.03316042\nIteration 17, loss = 0.14521904\nIteration 18, loss = 0.09865747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 0.08346088\nIteration 20, loss = 0.02838579\nIteration 21, loss = 0.01716100\nIteration 22, loss = 0.00879485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23, loss = 0.00177361\nIteration 24, loss = 0.00149138\nIteration 25, loss = 0.00139730\nIteration 26, loss = 0.00133558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, loss = 0.00128641\nIteration 28, loss = 0.00126186\nIteration 29, loss = 0.00123261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, loss = 0.00120170\nIteration 31, loss = 0.00118016\nIteration 32, loss = 0.00116110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33, loss = 0.00113603\nIteration 34, loss = 0.00111781\nIteration 35, loss = 0.00111018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 36, loss = 0.00108430\nIteration 37, loss = 0.00106752\nIteration 38, loss = 0.00104449\nIteration 39, loss = 0.00103823\nIteration 40, loss = 0.00102334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 41, loss = 0.00100524\nIteration 42, loss = 0.00099569\nIteration 43, loss = 0.00098330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44, loss = 0.00097557\nIteration 45, loss = 0.00096230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 46, loss = 0.00094141\nIteration 47, loss = 0.00093800\nIteration 48, loss = 0.00092276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 49, loss = 0.00091435\nIteration 50, loss = 0.00090372\nIteration 1, loss = 2.16116333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 0.46973941\nIteration 3, loss = 0.21198943\nIteration 4, loss = 0.16682161\nIteration 5, loss = 0.11275330\nIteration 6, loss = 0.08702769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.04964239\nIteration 8, loss = 0.05113341\nIteration 9, loss = 0.05250122\nIteration 10, loss = 0.05369279\nIteration 11, loss = 0.03925442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.04667829\nIteration 13, loss = 0.05056688\nIteration 14, loss = 0.01987197\nIteration 15, loss = 0.00555489\nIteration 16, loss = 0.00312202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, loss = 0.00271940\nIteration 18, loss = 0.00252087\nIteration 19, loss = 0.00234358\nIteration 20, loss = 0.00215200\nIteration 21, loss = 0.00206706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22, loss = 0.00197750\nIteration 23, loss = 0.00193835\nIteration 24, loss = 0.00175097\nIteration 25, loss = 0.00169608\nIteration 26, loss = 0.00163364\nIteration 27, loss = 0.00154889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28, loss = 0.00153001\nIteration 29, loss = 0.00143221\nIteration 30, loss = 0.00137007\nIteration 31, loss = 0.00128031\nIteration 32, loss = 0.00134730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33, loss = 0.00125636\nIteration 34, loss = 0.00118958\nIteration 35, loss = 0.00117844\nIteration 36, loss = 0.00114325\nIteration 37, loss = 0.00109658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38, loss = 0.00106852\nIteration 39, loss = 0.00105707\nIteration 40, loss = 0.00101186\nIteration 41, loss = 0.00099225\nIteration 42, loss = 0.00097882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43, loss = 0.00094859\nIteration 44, loss = 0.00094285\nIteration 45, loss = 0.00092349\nIteration 46, loss = 0.00090894\nIteration 47, loss = 0.00091595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 48, loss = 0.00087747\nIteration 49, loss = 0.00086144\nIteration 50, loss = 0.00086247\nIteration 1, loss = 1.60095089\nIteration 2, loss = 0.49259674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.31231544\nIteration 4, loss = 0.20792549\nIteration 5, loss = 0.22943599\nIteration 6, loss = 0.25893951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.25087914\nIteration 8, loss = 0.11983374\nIteration 9, loss = 0.15326727\nIteration 10, loss = 0.17842291\nIteration 11, loss = 0.08433466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.29757352\nIteration 13, loss = 0.27579875\nIteration 14, loss = 0.11882373\nIteration 15, loss = 0.13067920\nIteration 16, loss = 0.08287248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, loss = 0.18613795\nIteration 18, loss = 0.09436534\nIteration 19, loss = 0.13033257\nIteration 20, loss = 0.24509029\nIteration 21, loss = 0.11133034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22, loss = 0.08864096\nIteration 23, loss = 0.02603623\nIteration 24, loss = 0.01335213\nIteration 25, loss = 0.01724695\nIteration 26, loss = 0.25151916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, loss = 0.15098242\nIteration 28, loss = 0.11837586\nIteration 29, loss = 0.29565553\nIteration 30, loss = 0.35554397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31, loss = 0.12524702\nIteration 32, loss = 0.07848927\nIteration 33, loss = 0.03243573\nIteration 34, loss = 0.03062724\nIteration 35, loss = 0.09333403\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.55097238\nIteration 2, loss = 0.43971389\nIteration 3, loss = 0.36137838\nIteration 4, loss = 0.31350583\nIteration 5, loss = 0.21613106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.26749235\nIteration 7, loss = 0.17963591\nIteration 8, loss = 0.17888912\nIteration 9, loss = 0.26510542\nIteration 10, loss = 0.24738390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.15375172\nIteration 12, loss = 0.08716271\nIteration 13, loss = 0.11353191\nIteration 14, loss = 0.31530715\nIteration 15, loss = 0.24957274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 0.22907613\nIteration 17, loss = 0.22454015\nIteration 18, loss = 0.11870014\nIteration 19, loss = 0.18119038\nIteration 20, loss = 0.09951376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21, loss = 0.10380767\nIteration 22, loss = 0.03247287\nIteration 23, loss = 0.01996232\nIteration 24, loss = 0.00889846\nIteration 25, loss = 0.01208601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26, loss = 0.41888599\nIteration 27, loss = 0.42689292\nIteration 28, loss = 0.20635912\nIteration 29, loss = 0.15001198\nIteration 30, loss = 0.08138743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31, loss = 0.04444767\nIteration 32, loss = 0.03744423\nIteration 33, loss = 0.05465030\nIteration 34, loss = 0.07074638\nIteration 35, loss = 0.14481185\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.68046707\nIteration 2, loss = 0.45403698\nIteration 3, loss = 0.29219594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.34280074\nIteration 5, loss = 0.26965336\nIteration 6, loss = 0.20587835\nIteration 7, loss = 0.20065693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.33592245\nIteration 9, loss = 0.22374645\nIteration 10, loss = 0.17653386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.13654689\nIteration 12, loss = 0.10061445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 0.17546251\nIteration 14, loss = 0.14377140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15, loss = 0.31613204\nIteration 16, loss = 0.20776039\nIteration 17, loss = 0.37742047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18, loss = 0.30155857\nIteration 19, loss = 0.14614259\nIteration 20, loss = 0.12323201\nIteration 21, loss = 0.03959386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22, loss = 0.02867306\nIteration 23, loss = 0.05121525\nIteration 24, loss = 0.07937097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25, loss = 0.10351589\nIteration 26, loss = 0.17807525\nIteration 27, loss = 0.08965359\nIteration 28, loss = 0.32173126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29, loss = 0.20571315\nIteration 30, loss = 0.15645467\nIteration 31, loss = 0.19596928\nIteration 32, loss = 0.29441038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33, loss = 0.07765213\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 1.89132615\nIteration 2, loss = 1.27934911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.44071300\nIteration 4, loss = 1.35396248\nIteration 5, loss = 1.37375734\nIteration 6, loss = 1.36390852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.43151713\nIteration 8, loss = 1.36440646\nIteration 9, loss = 1.35277666\nIteration 10, loss = 1.33983913\nIteration 11, loss = 1.29666026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 1.18145648\nIteration 13, loss = 1.19587033\nIteration 14, loss = 1.27125729\nIteration 15, loss = 1.22602031\nIteration 16, loss = 1.32021229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, loss = 1.32242347\nIteration 18, loss = 1.34387283\nIteration 19, loss = 1.28532308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, loss = 1.31020139\nIteration 21, loss = 1.27717959\nIteration 22, loss = 1.28494884\nIteration 23, loss = 1.22592454\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.07881296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.63932476\nIteration 3, loss = 1.52929121\nIteration 4, loss = 1.69314331\nIteration 5, loss = 2.02401678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 2.03858830\nIteration 7, loss = 2.04002339\nIteration 8, loss = 2.01231930\nIteration 9, loss = 2.00000888\nIteration 10, loss = 1.99414769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 1.99034538\nIteration 12, loss = 2.16730696\nIteration 13, loss = 2.04070096\nIteration 14, loss = 2.03300563\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.49612843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.71547028\nIteration 3, loss = 1.73313501\nIteration 4, loss = 1.64929247\nIteration 5, loss = 1.36084556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.38220580\nIteration 7, loss = 1.47856800\nIteration 8, loss = 1.41928456\nIteration 9, loss = 1.57965006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.46664308\nIteration 11, loss = 1.44968081\nIteration 12, loss = 1.32317705\nIteration 13, loss = 1.31090370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 1.35383811\nIteration 15, loss = 1.43106100\nIteration 16, loss = 1.34390331\nIteration 17, loss = 1.30794403\nIteration 18, loss = 1.33858729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 1.32811958\nIteration 20, loss = 1.38822873\nIteration 21, loss = 1.38891905\nIteration 22, loss = 1.45930646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23, loss = 1.63473983\nIteration 24, loss = 1.50714650\nIteration 25, loss = 1.40030793\nIteration 26, loss = 1.47055101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, loss = 1.44681913\nIteration 28, loss = 1.38686684\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.78209843\nIteration 2, loss = 2.35084044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 2.35471470\nIteration 4, loss = 2.34201382\nIteration 5, loss = 2.36819877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 2.35271933\nIteration 7, loss = 2.35600701\nIteration 8, loss = 2.34721369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 2.36261838\nIteration 10, loss = 2.36299799\nIteration 11, loss = 2.34295330\nIteration 12, loss = 2.34960402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 2.35032194\nIteration 14, loss = 2.34197566\nIteration 15, loss = 2.34391670\nIteration 16, loss = 2.34443784\nIteration 17, loss = 2.34064676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18, loss = 2.35203767\nIteration 19, loss = 2.34151032\nIteration 20, loss = 2.35622309\nIteration 21, loss = 2.34348255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22, loss = 2.35386752\nIteration 23, loss = 2.34784261\nIteration 24, loss = 2.35182155\nIteration 25, loss = 2.34092834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26, loss = 2.35184223\nIteration 27, loss = 2.33769772\nIteration 28, loss = 2.35232204\nIteration 29, loss = 2.34345074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, loss = 2.34881470\nIteration 31, loss = 2.34282204\nIteration 32, loss = 2.33760689\nIteration 33, loss = 2.34720213\nIteration 34, loss = 2.34101095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 35, loss = 2.34981645\nIteration 36, loss = 2.35371388\nIteration 37, loss = 2.34616520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38, loss = 2.33827844\nIteration 39, loss = 2.35050338\nIteration 40, loss = 2.34109511\nIteration 41, loss = 2.35066048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 42, loss = 2.34477594\nIteration 43, loss = 2.35706595\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.95413976\nIteration 2, loss = 2.33735327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 2.35051398\nIteration 4, loss = 2.34959571\nIteration 5, loss = 2.34057086\nIteration 6, loss = 2.35078047\nIteration 7, loss = 2.34106863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 2.33974818\nIteration 9, loss = 2.34655748\nIteration 10, loss = 2.34829579\nIteration 11, loss = 2.34240103\nIteration 12, loss = 2.35381703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 2.34648058\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 3.06377512\nIteration 2, loss = 2.34826721\nIteration 3, loss = 2.34623018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 2.36310860\nIteration 5, loss = 2.34768246\nIteration 6, loss = 2.34627635\nIteration 7, loss = 2.32669881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 2.35476962\nIteration 9, loss = 2.35065833\nIteration 10, loss = 2.33719920\nIteration 11, loss = 2.34780427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 2.35115622\nIteration 13, loss = 2.34662406\nIteration 14, loss = 2.34125350\nIteration 15, loss = 2.34773105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 2.35143641\nIteration 17, loss = 2.35215021\nIteration 18, loss = 2.35047100\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.59786582\nIteration 2, loss = 1.96280610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.64362686\nIteration 4, loss = 1.41697042\nIteration 5, loss = 1.24269253\nIteration 6, loss = 1.12181393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.06219039\nIteration 8, loss = 0.92949587\nIteration 9, loss = 0.83241067\nIteration 10, loss = 0.77556174"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nIteration 11, loss = 0.73283258\nIteration 12, loss = 0.67866824\nIteration 13, loss = 0.66183121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 0.64149213\nIteration 15, loss = 0.59134487\nIteration 16, loss = 0.56816207\nIteration 17, loss = 0.54298602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18, loss = 0.50991984\nIteration 19, loss = 0.49561463\nIteration 20, loss = 0.48637385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21, loss = 0.45936330\nIteration 22, loss = 0.44067929\nIteration 23, loss = 0.41277665\nIteration 24, loss = 0.40969026\nIteration 25, loss = 0.40620422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26, loss = 0.38897272\nIteration 27, loss = 0.39195643\nIteration 28, loss = 0.36131434\nIteration 29, loss = 0.40230567\nIteration 30, loss = 0.35737529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31, loss = 0.36302245\nIteration 32, loss = 0.34580379\nIteration 33, loss = 0.34139158\nIteration 34, loss = 0.35608882\nIteration 35, loss = 0.32034333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 36, loss = 0.31328371\nIteration 37, loss = 0.32490395\nIteration 38, loss = 0.29938635\nIteration 39, loss = 0.30653750\nIteration 40, loss = 0.31982282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 41, loss = 0.30249122\nIteration 42, loss = 0.29094016\nIteration 43, loss = 0.30667524\nIteration 44, loss = 0.27440480\nIteration 45, loss = 0.31168003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 46, loss = 0.27739767\nIteration 47, loss = 0.28417876\nIteration 48, loss = 0.28530743\nIteration 49, loss = 0.28127046\nIteration 50, loss = 0.26886157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.58046930\nIteration 2, loss = 1.85487416\nIteration 3, loss = 1.62173577\nIteration 4, loss = 1.47682377\nIteration 5, loss = 1.34806230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.19658263\nIteration 7, loss = 1.06500561\nIteration 8, loss = 0.93278668\nIteration 9, loss = 0.81999487\nIteration 10, loss = 0.72398883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.64972289\nIteration 12, loss = 0.61029455\nIteration 13, loss = 0.58735157\nIteration 14, loss = 0.54037666\nIteration 15, loss = 0.54066658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 0.49052046\nIteration 17, loss = 0.45477465\nIteration 18, loss = 0.46857024\nIteration 1, loss = 2.73749583\nIteration 2, loss = 2.14192292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.99343458\nIteration 4, loss = 1.77160457\nIteration 5, loss = 1.68712024\nIteration 6, loss = 1.61109459\nIteration 7, loss = 1.53186292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 1.47358505\nIteration 9, loss = 1.42291226\nIteration 10, loss = 1.37689686\nIteration 11, loss = 1.33362324\nIteration 12, loss = 1.27201420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 1.19215076\nIteration 14, loss = 1.14742938\nIteration 15, loss = 1.13215462\nIteration 16, loss = 1.11045686\nIteration 17, loss = 1.09823357\nIteration 18, loss = 1.05226062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 1.02461595\nIteration 20, loss = 1.02729918\nIteration 21, loss = 0.98887318\nIteration 22, loss = 0.97996658\nIteration 23, loss = 0.97454239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24, loss = 0.93667955\nIteration 25, loss = 0.95068500\nIteration 26, loss = 0.93648596\nIteration 27, loss = 0.90798898\nIteration 28, loss = 0.90044735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29, loss = 0.88664319\nIteration 30, loss = 0.87096367\nIteration 31, loss = 0.88140375\nIteration 32, loss = 0.87703113\nIteration 33, loss = 0.86849751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34, loss = 0.87028768\nIteration 35, loss = 0.84790770\nIteration 36, loss = 0.84547061\nIteration 37, loss = 0.82086951\nIteration 38, loss = 0.87282005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39, loss = 0.83060678\nIteration 40, loss = 0.80089028\nIteration 41, loss = 0.81077655\nIteration 42, loss = 0.82586263\nIteration 43, loss = 0.80297803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44, loss = 0.78835053\nIteration 45, loss = 0.79743091\nIteration 46, loss = 0.80070375\nIteration 47, loss = 0.81931525\nIteration 48, loss = 0.78143172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 49, loss = 0.78546330\nIteration 50, loss = 0.77255793\nIteration 1, loss = 2.28183303\nIteration 2, loss = 2.04020758\nIteration 3, loss = 1.95959399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.93299750\nIteration 5, loss = 1.89862888\nIteration 6, loss = 1.86157279\nIteration 7, loss = 1.86991286\nIteration 8, loss = 1.83608492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 1.84725998\nIteration 10, loss = 1.76167348\nIteration 11, loss = 1.75181491\nIteration 12, loss = 1.69647848\nIteration 13, loss = 1.73373222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 1.64985280\nIteration 15, loss = 1.66234789\nIteration 16, loss = 1.63700960\nIteration 17, loss = 1.68381571\nIteration 18, loss = 1.63327844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 1.60695448\nIteration 20, loss = 1.63988390\nIteration 21, loss = 1.58781554\nIteration 22, loss = 1.63444018\nIteration 23, loss = 1.63689078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24, loss = 1.58596634\nIteration 25, loss = 1.58209510\nIteration 26, loss = 1.58710243\nIteration 27, loss = 1.59477084\nIteration 28, loss = 1.62424822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29, loss = 1.63173523\nIteration 30, loss = 1.56117209\nIteration 31, loss = 1.57750299\nIteration 32, loss = 1.58330803\nIteration 33, loss = 1.56316308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34, loss = 1.56129390\nIteration 35, loss = 1.60235664\nIteration 36, loss = 1.58821779\nIteration 37, loss = 1.58633479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38, loss = 1.53612194\nIteration 39, loss = 1.52703970\nIteration 40, loss = 1.55484265\nIteration 41, loss = 1.56068430\nIteration 42, loss = 1.54527815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43, loss = 1.60821565\nIteration 44, loss = 1.54970973\nIteration 45, loss = 1.59313878\nIteration 46, loss = 1.52851290\nIteration 47, loss = 1.57079647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 48, loss = 1.53640586\nIteration 49, loss = 1.50191349\nIteration 50, loss = 1.51676281\nIteration 1, loss = 2.34996969\nIteration 2, loss = 2.07239166\nIteration 3, loss = 1.95450421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.90699811\nIteration 5, loss = 1.90578723\nIteration 6, loss = 1.88032426\nIteration 7, loss = 1.86887676\nIteration 8, loss = 1.87926883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 1.85312512\nIteration 10, loss = 1.82163243\nIteration 11, loss = 1.83403464\nIteration 12, loss = 1.84201821\nIteration 13, loss = 1.78010702\nIteration 14, loss = 1.80096535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15, loss = 1.75715734\nIteration 16, loss = 1.78000659\nIteration 17, loss = 1.74258207\nIteration 18, loss = 1.73481387\nIteration 19, loss = 1.71955452\nIteration 20, loss = 1.69804894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21, loss = 1.72383711\nIteration 22, loss = 1.73477404\nIteration 23, loss = 1.72735662\nIteration 24, loss = 1.66854821\nIteration 25, loss = 1.69837829\nIteration 26, loss = 1.69534068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, loss = 1.67928156\nIteration 28, loss = 1.65985814\nIteration 29, loss = 1.63937979\nIteration 30, loss = 1.67223873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31, loss = 1.63691592\nIteration 32, loss = 1.65926456\nIteration 33, loss = 1.63281940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34, loss = 1.63288523\nIteration 35, loss = 1.60747887\nIteration 36, loss = 1.63868680\nIteration 37, loss = 1.63202401\nIteration 38, loss = 1.59561347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39, loss = 1.63823319\nIteration 40, loss = 1.60409474\nIteration 41, loss = 1.60870963\nIteration 42, loss = 1.58806250\nIteration 43, loss = 1.67733457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44, loss = 1.58874046\nIteration 45, loss = 1.61177795\nIteration 46, loss = 1.59069254\nIteration 47, loss = 1.61940451\nIteration 48, loss = 1.59117750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 49, loss = 1.60776450\nIteration 50, loss = 1.58167038\nIteration 1, loss = 2.36752638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.89595663\nIteration 3, loss = 1.78107602\nIteration 4, loss = 1.63320818\nIteration 5, loss = 1.54365396\nIteration 6, loss = 1.46967388\nIteration 7, loss = 1.39423233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.36431317\nIteration 2, loss = 2.31726782\nIteration 3, loss = 2.31704343\nIteration 4, loss = 2.31855374\nIteration 5, loss = 2.32016175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 2.31882554\nIteration 7, loss = 2.31567404\nIteration 8, loss = 2.31926868\nIteration 9, loss = 2.31905564\nIteration 10, loss = 2.31869158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 2.31712278\nIteration 12, loss = 2.31927313\nIteration 13, loss = 2.31853862\nIteration 14, loss = 2.32007877\nIteration 15, loss = 2.31622915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 2.31652336\nIteration 17, loss = 2.32143849\nIteration 18, loss = 2.31747167\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.35875655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 2.31845912\nIteration 3, loss = 2.31713679\nIteration 4, loss = 2.31558101\nIteration 1, loss = 2.40033719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n  warnings.warn(\"Training interrupted by user.\")\n/Users/yanis/venv/ApprentissageArtificiel/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 2.32063772\nIteration 3, loss = 2.31776911\nIteration 1, loss = 2.44792772\nIteration 2, loss = 2.34957506\nIteration 3, loss = 2.34868491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 2.34320786\nIteration 5, loss = 2.35262699\nIteration 6, loss = 2.34401763\nIteration 7, loss = 2.34375012\nIteration 8, loss = 2.34690318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 2.34828818\nIteration 10, loss = 2.34591658\nIteration 11, loss = 2.34488148\nIteration 12, loss = 2.35098930\nIteration 13, loss = 2.33993300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 2.34836262\nIteration 15, loss = 2.34388373\nIteration 16, loss = 2.33486289\nIteration 17, loss = 2.35506264\nIteration 18, loss = 2.34585555\nIteration 19, loss = 2.34574827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, loss = 2.34135736\nIteration 21, loss = 2.34852393\nIteration 22, loss = 2.35056038\nIteration 23, loss = 2.35728748\nIteration 24, loss = 2.34344623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25, loss = 2.39296952\nIteration 26, loss = 2.37753754\nIteration 27, loss = 2.38815546\nTraining loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\nIteration 1, loss = 2.45337439\nIteration 2, loss = 2.35620474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 2.35068680\nIteration 4, loss = 2.33839512\nIteration 5, loss = 2.34933601\nIteration 6, loss = 2.35198493\nIteration 7, loss = 2.34681566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 2.34993863\nIteration 9, loss = 2.35308437\nIteration 10, loss = 2.33931022\nIteration 11, loss = 2.33725407\nIteration 12, loss = 2.34702876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 2.34532573\nIteration 14, loss = 2.34044740\nIteration 15, loss = 2.35190551\nIteration 16, loss = 2.34977858\nIteration 17, loss = 2.33532065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18, loss = 2.35295098\nIteration 19, loss = 2.34207832\nIteration 20, loss = 2.34628823\nIteration 21, loss = 2.35469895\nIteration 22, loss = 2.34500480\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "digits = load_digits()\n",
    "n_samples = len(digits.images)\n",
    "print(\"Number_of-examples = \", n_samples)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"\\n Plot of first example\")\n",
    "plt.gray() \n",
    "plt.matshow(digits.images[0]) \n",
    "print(\"CLOSE PLOT WINDOW TO CONTINUE\")\n",
    "plt.ioff()\n",
    "plt.show()\n",
    "\n",
    "# Flatten the images, to turn data in a (samples, feature) matrix:\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "X = data\n",
    "y = digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100, ), activation='relu', solver='adam', \n",
    "                    alpha=0.0001, batch_size=4, learning_rate='constant', learning_rate_init=0.01, \n",
    "                    power_t=0.5, max_iter=9, shuffle=True, random_state=11, tol=0.00001, \n",
    "                    verbose=True, warm_start=False, momentum=0.8, nesterovs_momentum=True, \n",
    "                    early_stopping=False, validation_fraction=0.1, \n",
    "                    beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "print(clf)\n",
    "\n",
    "param_grid = [\n",
    "  {'hidden_layer_sizes': [(5,), (10,), (15,), (25,)], \n",
    "   'learning_rate_init':[0.003, 0.01, 0.03, 0.1],\n",
    "   'alpha': [0.00001, 0.0001, 0.001, 0.01]}\n",
    " ]\n",
    "\n",
    "#print(param_grid)\n",
    "\n",
    "# Cross-validation grid-search\n",
    "for score in scores:\n",
    "    clf = GridSearchCV( MLPClassifier(activation='relu', alpha=1e-07, batch_size=4, beta_1=0.9,\n",
    "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(10,), learning_rate='constant',\n",
    "       learning_rate_init=0.005, max_iter=50, momentum=0.8,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=11, shuffle=True,\n",
    "       solver='adam', tol=1e-05, validation_fraction=0.3, verbose=2,\n",
    "       warm_start=False), \n",
    "       param_grid, cv=3,scoring='%s_macro' % score)\n",
    "# Train the MLP classifier on training dataset\n",
    "clf.fit(X_train, y_train)\n",
    "print (clf.best_params_)\n",
    "print (clf.best_score_)\n",
    "'''\n",
    "# Evaluate acuracy on test data\n",
    "score = clf.score(X_test,y_test)\n",
    "print(\"Acuracy (on test set) = \", score)\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
